{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.which(\"ffmpeg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "1t_MmbnQxz3f"
   },
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install neo\n",
    "# !pip install matplotlib_scalebar\n",
    "# !pip install ffmpeg\n",
    "# !pip install wheel==0.38.4\n",
    "# !pip3 install setuptools==65.5.0\n",
    "# !pip install stable_baselines3\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "9904b001"
   },
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32160,
     "status": "ok",
     "timestamp": 1684945803461,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "78d7921b",
    "outputId": "68f69138-fbc7-40e8-db4e-f3bea17f3a31"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    " \n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information\n",
    "from pattern_discovery import pattern_by_trials, make_ff_dataframe, pattern_by_trials, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from reinforcement_learning.base_classes import env_utils, base_env, more_envs, rl_base_class, rl_base_utils\n",
    "from reinforcement_learning.agents.rnn import gru_utils, lstm_utils, lstm_utils, lstm_class, gru_class\n",
    "from reinforcement_learning.agents.feedforward import interpret_neural_network, sb3_class, sb3_utils\n",
    "from reinforcement_learning.agents.rnn import rnn_env\n",
    "from reinforcement_learning.collect_data import collect_agent_data, process_agent_data\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.results_plotter import plot_results\n",
    "from stable_baselines3.common.callbacks import StopTrainingOnNoModelImprovement\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from IPython.display import HTML\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import random\n",
    "from importlib import reload\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement, StopTrainingOnRewardThreshold\n",
    "import gc\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "matplotlib.rcParams[\"animation.ffmpeg_path\"] = shutil.which(\"ffmpeg\")\n",
    "matplotlib.rcParams[\"animation.writer\"] = \"ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## See animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_folder =\"multiff_analysis/RL_models/sb3_stored_models/all_agents/ff5_mem3_drop_fill_lr3e-4_nenvs1_job180258_16/ft/dv0p5_jerk0p9_stop7_194518_8\"\n",
    "\n",
    "# overall_folder =\"multiff_analysis/RL_models/sb3_stored_models/all_agents/ff4_mem2_drop_fill_lr3e-4_nenvs1_job194758_20/ft/dv0p700000_jerk0p500000_stop7p000000\"\n",
    "overall_folder =\"multiff_analysis/RL_models/sb3_stored_models/all_agents/ff3_mem2_rank_keep_visible_and_memory_job201354_10\"\n",
    "\n",
    "rl = sb3_class.SB3forMultifirefly(overall_folder=overall_folder)\n",
    "\n",
    "\n",
    "rl.streamline_making_animation(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 30], n_steps=600, video_dir=None,\n",
    "                                  data_exists_ok=False,\n",
    "                                  display_inline=False,\n",
    "                                  save_video=False,\n",
    "                                  plot_time_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# # Convert animation to HTML\n",
    "# html_str = rl.anim.to_jshtml()\n",
    "# video_path_name = os.path.join(base_path, 'derived_agent_animation', f'{agent_name}_C_{num_caught_ff}.html')\n",
    "# os.makedirs(os.path.dirname(video_path_name), exist_ok=True)\n",
    "# with open(video_path_name, 'w') as f:\n",
    "#     f.write(html_str)\n",
    "#     print(f\"Animation saved to {video_path_name}\")\n",
    "\n",
    "num_caught_ff = len(rl.ff_caught_T_sorted)\n",
    "agent_name = os.path.basename(overall_folder)\n",
    "video_path_name = os.path.join('multiff_analysis/RL_models/agent_animation', f'{agent_name}_C_{num_caught_ff}.html')\n",
    "html_str = rl.anim.to_jshtml()\n",
    "os.makedirs(os.path.dirname(video_path_name), exist_ok=True)\n",
    "with open(video_path_name, 'w') as f:\n",
    "    f.write(html_str)\n",
    "    print(f\"Animation saved to {video_path_name}\")\n",
    "    \n",
    "print(rl.monkey_information['speed'].values[:30])\n",
    "    \n",
    "from IPython.display import HTML\n",
    "HTML(rl.anim.to_jshtml())  # or HTML(your_instance.anim.to_jshtml())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Streamline training agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Use class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/quick_test\"\n",
    "rl = sb3_class.SB3forMultifirefly(\n",
    "    model_folder_name=model_folder_name)\n",
    "rl.streamline_everything(currentTrial_for_animation = 10, num_trials_for_animation = 5,\n",
    "                              best_model_in_curriculum_exists_ok=True,\n",
    "                              best_model_postcurriculum_exists_ok=True,\n",
    "                              to_load_latest_agent=True,\n",
    "                              to_train_agent=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(collect_agent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.collect_data(exists_ok=False, save_data=False, n_steps=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(animation_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.set_animation_parameters(duration=[30, 48],k=1)\n",
    "rl.call_animation_function()\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(rl.video_path_name, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.env_for_data_collection.ff_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.ff_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.ff_dataframe['pose_unreliable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rl.ff_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['visible'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Train independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/regular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/temp_10_11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/oct_12_6\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "\n",
    "env_kwargs = {}\n",
    "env = sb3_env.EnvForSB3(**env_kwargs)\n",
    "env = Monitor(env, model_folder_name)\n",
    "\n",
    "# For direct training\n",
    "rl_agent = SAC(\"MlpPolicy\", \n",
    "            env,\n",
    "            gamma=0.998,\n",
    "            learning_rate=0.0015,\n",
    "            batch_size=1024,\n",
    "            target_update_interval=50,\n",
    "            buffer_size=1000000,\n",
    "            learning_starts=10000,\n",
    "            train_freq=10,\n",
    "            ent_coef='auto',\n",
    "            policy_kwargs=dict(activation_fn=nn.Tanh, net_arch=[128, 128])\n",
    "            )\n",
    "\n",
    "\n",
    "callback = sb3_utils.SaveOnBestTrainingRewardCallback(check_freq=20000, model_folder_name=model_folder_name)\n",
    "#timesteps = 50000000\n",
    "timesteps = 200000\n",
    "rl_agent.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "plot_results([model_folder_name], timesteps, results_plotter.X_TIMESTEPS, \"env.MultiFF\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "b254917d"
   },
   "source": [
    "# Streamline loading agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "bd105957"
   },
   "source": [
    "## Make files for logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "e447c5f9"
   },
   "source": [
    "(Only have to do once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "nuE-aO1digZv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def ensure_csv(folder: str, filename: str, columns: list[str]) -> None:\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        pd.DataFrame(columns=columns).to_csv(filepath, index=False)\n",
    "\n",
    "common_cols = ['dv_cost_factor', 'dw_cost_factor', 'w_cost_factor',\n",
    "               'v_noise_std', 'w_noise_std', 'ffr_noise_scale', 'num_obs_ff', 'max_in_memory_time']\n",
    "\n",
    "ensure_csv(overall_folder, 'family_of_agents_log.csv',\n",
    "           common_cols + ['finished_training', 'year', 'month', 'date',\n",
    "                          'training_time', 'successful_training'])\n",
    "\n",
    "ensure_csv(overall_folder, 'parameters_record.csv',\n",
    "           common_cols + ['working'])\n",
    "\n",
    "ensure_csv(overall_folder, 'pattern_frequencies_record.csv',\n",
    "           common_cols + ['two_in_a_row', 'three_in_a_row', 'four_in_a_row', 'one_in_a_row',\n",
    "                          'multiple_in_a_row', 'multiple_in_a_row_all', 'visible_before_last_one',\n",
    "                          'disappear_latest', 'ignore_sudden_flash', 'retry_capture',\n",
    "                          'retry_switch', 'cluster_around_target',\n",
    "                          'waste_cluster_around_target', 'ff_capture_rate', 'stop_success_rate'])\n",
    "\n",
    "feature_cols = common_cols + ['t', 't_last_vis', 'd_last_vis', 'abs_angle_last_vis',\n",
    "                              'hitting_arena_edge', 'num_stops', 'num_stops_since_last_vis',\n",
    "                              'num_stops_near_target', 'num_alive_ff_around_target', 'n_ff_in_a_row']\n",
    "\n",
    "ensure_csv(overall_folder, 'feature_means_record.csv', feature_cols)\n",
    "ensure_csv(overall_folder, 'feature_medians_record.csv', feature_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "0f22ab42"
   },
   "source": [
    "Make daily backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "d245d8ed"
   },
   "outputs": [],
   "source": [
    "# back_up_path = overall_folder + 'family_of_agents_log_' + str(time_package.localtime().tm_mon) + '_' + str(time_package.localtime().tm_mday) + '.csv'\n",
    "# if not exists(back_up_path):\n",
    "#     family_of_agents_log = pd.read_csv(overall_folder + 'family_of_agents_log.csv').drop([\"Unnamed: 0\"], axis=1)\n",
    "#     family_of_agents_log.to_csv(back_up_path)\n",
    "#     print('A back up of family_of_agents_log is stored in', back_up_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "1558f19f"
   },
   "source": [
    "## Get monkey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31188,
     "status": "ok",
     "timestamp": 1684945834636,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "c86c2e1f",
    "outputId": "250ac96e-7813-4618-a219-2dab7c7e9556"
   },
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0220\"\n",
    "data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=raw_data_folder_path)\n",
    "data_item.retrieve_or_make_monkey_data()\n",
    "data_item.make_or_retrieve_ff_dataframe(exists_ok=True)\n",
    "data_item.find_patterns()\n",
    "data_item.make_or_retrieve_all_trial_patterns(exists_ok=True)\n",
    "data_item.make_or_retrieve_pattern_frequencies(exists_ok=True)\n",
    "data_item.make_or_retrieve_all_trial_features(exists_ok=True)\n",
    "data_item.make_or_retrieve_feature_statistics(exists_ok=True)\n",
    "data_item.make_info_of_monkey()\n",
    "\n",
    "all_trial_patterns_m = data_item.all_trial_patterns\n",
    "pattern_frequencies_m = data_item.pattern_frequencies\n",
    "all_trial_features_m = data_item.all_trial_features\n",
    "feature_statistics_m = data_item.feature_statistics\n",
    "info_of_monkey = data_item.info_of_monkey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Run the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/SB3_stored_models/all_agents/gen_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = sb3_class.SB3forMultifirefly(overall_folder=overall_folder, add_date_to_model_folder_name=False)\n",
    "#rl.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "rl.streamline_everything(currentTrial_for_animation = 10, num_trials_for_animation = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.lstm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps = 10000000        \n",
    "# stop_train_callback = sb3_utils.StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=20, verbose=1, model_folder_name=rl.model_folder_name,                                                   overall_folder=rl.overall_folder, agent_id=rl.agent_id)\n",
    "# callback = EvalCallback(rl.env, eval_freq=12000, callback_after_eval=stop_train_callback, verbose=1, best_model_save_path=rl.model_folder_name, n_eval_episodes=3)\n",
    "# rl.rl_agent.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "# rl.successful_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Collect data (experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.collect_data(exists_ok=True, save_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'overall_folder': overall_folder, \n",
    "            #   'v_noise_std': 0, \n",
    "            #   \"w_noise_std\": 0,\n",
    "            #   'ffr_noise_scale': 0, \n",
    "            #   'num_obs_ff': 2, \n",
    "            #   'max_in_memory_time': 2.5, \n",
    "            #   'add_date_to_model_folder_name': False,\n",
    "            #   \n",
    "            #   'dv_cost_factor': 10,\n",
    "            #   'dw_cost_factor': 10,\n",
    "              }\n",
    "\n",
    "# alternatively...\n",
    "rl = sb3_class.SB3forMultifirefly(**env_kwargs)\n",
    "rl.make_env()\n",
    "rl.make_agent()\n",
    "rl.load_agent(load_replay_buffer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## call_animation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.set_animation_parameters(currentTrial=10, num_trials=5, k=1)\n",
    "rl.call_animation_function()\n",
    "# rl.combine_6_plots_for_neural_network()\n",
    "# rl.calculate_pattern_frequencies_and_feature_statistics()\n",
    "# rl.plot_side_by_side()\n",
    "# plot_statistics.plot_pattern_frequencies(rl.combd_pattern_frequencies, compare_monkey_and_agent=True, data_folder_name=rl.model_folder_name)\n",
    "# #plot_statistics.plot_feature_statistics_for_monkey_and_agent(rl.combd_feature_statistics, data_folder_name = rl.model_folder_name)\n",
    "# plot_statistics.plot_feature_histograms_for_monkey_and_agent(rl.all_trial_features_valid, rl.all_trial_features_valid, data_folder_name = rl.model_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# Sweep results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## curriculum training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "log_dir = 'multiff_analysis/jobs/sb3/logs/run_curriculum/201354'\n",
    "files = [f for f in glob.glob(os.path.join(log_dir, '*.csv'))]\n",
    "\n",
    "\n",
    "if len(files) == 0:\n",
    "    raise ValueError(f\"No files found in {log_dir}\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"File {f} is empty\")\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    df = df.dropna(subset=['timestamp'])\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"File {f} has no valid timestamps\")\n",
    "        \n",
    "\n",
    "    df = df.sort_values('stage')\n",
    "    last_stage = df.iloc[-1]\n",
    "\n",
    "    train_time = (df['timestamp'].iloc[-1] - df['timestamp'].iloc[0]).total_seconds() / 60  # minutes\n",
    "\n",
    "    # Extract run ID (last part of overall_folder)\n",
    "    run_id = os.path.basename(str(last_stage['overall_folder']))\n",
    "\n",
    "    records.append({\n",
    "        'file': os.path.basename(f),\n",
    "        'run_id': run_id,  # ← added here\n",
    "        'agent_type': last_stage['agent_type'],\n",
    "        'lr': last_stage['param_lr'],\n",
    "        'num_obs_ff': last_stage['param_num_obs_ff'],\n",
    "        'max_in_memory_time': last_stage['param_max_in_memory_time'],\n",
    "        'strategy': last_stage['param_identity_slot_strategy'],\n",
    "        'n_envs': last_stage['param_n_envs'],\n",
    "        'angular_terminal_vel': last_stage['param_angular_terminal_vel'],\n",
    "        #'final_stage': last_stage['stage'],\n",
    "        'best_reward_last': last_stage['best_avg_reward'],\n",
    "        'reward_threshold': last_stage['reward_threshold'],\n",
    "        'flash_on_interval': last_stage['flash_on_interval'],\n",
    "        'train_time_min': train_time,\n",
    "        'finished_curriculum': last_stage['finished_curriculum'],\n",
    "        'overall_folder': last_stage['overall_folder']\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(records)\n",
    "summary = summary.sort_values('best_reward_last', ascending=False)\n",
    "\n",
    "print(summary[['run_id', 'num_obs_ff', 'strategy', 'best_reward_last', 'train_time_min', 'max_in_memory_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary[summary['finished_curriculum'] == True].copy()\n",
    "# summary.loc[summary['finished_curriculum'] == False, 'train_time_min'] = max(summary['train_time_min'] + 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# --- Setup ---\n",
    "strategies = summary['strategy'].unique()\n",
    "palette = sns.color_palette('tab10', len(strategies))\n",
    "color_map = dict(zip(strategies, palette))\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# --- Marker size scaling ---\n",
    "min_size, max_size = 50, 300  # scatter point area (points^2)\n",
    "summary['marker_size'] = np.interp(\n",
    "    summary['max_in_memory_time'],\n",
    "    (summary['max_in_memory_time'].min(), summary['max_in_memory_time'].max()),\n",
    "    (min_size, max_size)\n",
    ")\n",
    "\n",
    "# --- Scatter plot ---\n",
    "for strat in strategies:\n",
    "    subset = summary[summary['strategy'] == strat]\n",
    "    plt.scatter(\n",
    "        subset['train_time_min'],\n",
    "        subset['best_reward_last'],\n",
    "        label=strat,\n",
    "        color=color_map[strat],\n",
    "        alpha=0.8,\n",
    "        edgecolor='black',\n",
    "        s=subset['marker_size']\n",
    "    )\n",
    "\n",
    "# --- Text annotations (num_obs_ff) ---\n",
    "# Label all if few points, or just a representative subset if large\n",
    "if len(summary) <= 100:\n",
    "    annotated = summary\n",
    "else:\n",
    "    annotated = summary.nlargest(15, 'best_reward_last')  # top 15 for readability\n",
    "\n",
    "for _, row in annotated.iterrows():\n",
    "    plt.text(row['train_time_min'] + 0.5,\n",
    "             row['best_reward_last'] + 3,\n",
    "             str(row['num_obs_ff']),\n",
    "             fontsize=10,\n",
    "             alpha=0.8)\n",
    "\n",
    "# --- Legends ---\n",
    "# Color legend (strategy)\n",
    "color_handles = [\n",
    "    Line2D([0], [0], marker='o', color='w',\n",
    "           markerfacecolor=color_map[strat], markeredgecolor='black',\n",
    "           label=strat, markersize=10)\n",
    "    for strat in strategies\n",
    "]\n",
    "\n",
    "# Size legend (max_in_memory_time)\n",
    "size_values = np.linspace(summary['max_in_memory_time'].min(),\n",
    "                          summary['max_in_memory_time'].max(), 3)\n",
    "size_handles = [\n",
    "    Line2D([0], [0], marker='o', color='w',\n",
    "           markerfacecolor='gray', markeredgecolor='black',\n",
    "           label=f'{val:.1f} s',\n",
    "           markersize=np.sqrt(np.interp(val,\n",
    "                                        (summary['max_in_memory_time'].min(),\n",
    "                                         summary['max_in_memory_time'].max()),\n",
    "                                        (min_size, max_size))) / 2)\n",
    "    for val in size_values\n",
    "]\n",
    "\n",
    "first_legend = plt.legend(handles=color_handles, title='Strategy',\n",
    "                          loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "second_legend = plt.legend(handles=size_handles, title='Max In-Memory Time',\n",
    "                           loc='lower left', bbox_to_anchor=(1.02, 0))\n",
    "plt.gca().add_artist(first_legend)\n",
    "\n",
    "# --- Aesthetics ---\n",
    "plt.xlabel('Training Time (minutes)')\n",
    "plt.ylabel('Best Avg Reward (Last Stage)')\n",
    "plt.title('Reward vs. Training Time by Strategy')\n",
    "plt.tight_layout()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(data=summary, x='strategy', y='best_reward_last', hue='num_obs_ff', palette='muted')\n",
    "plt.ylabel('Best Avg Reward')\n",
    "plt.title('Final Performance by Strategy and num_obs_ff')\n",
    "plt.legend(title='num_obs_ff')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    data=summary,\n",
    "    x='strategy',\n",
    "    y='train_time_min',\n",
    "    hue='num_obs_ff',\n",
    "    palette='muted'\n",
    ")\n",
    "plt.ylabel('Training Time (minutes)')\n",
    "plt.xlabel('Identity Slot Strategy')\n",
    "plt.title('Total Training Time by Strategy and num_obs_ff')\n",
    "plt.legend(title='num_obs_ff')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## just to collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# base_path = \"multiff_analysis/RL_models/sb3_stored_models/all_agents/ff4_mem2_drop_fill_lr3e-4_nenvs1_job194758_20/ft\"\n",
    "base_path = \"multiff_analysis/RL_models/sb3_stored_models/all_agents\"\n",
    "\n",
    "dirs = [p for p in Path(base_path).iterdir()]\n",
    "#dirs = [p for p in Path(base_path).iterdir() if (p.is_dir() and '175295' in p.name)]\n",
    "dirs.sort(key=lambda p: p.name)\n",
    "\n",
    "_cost_results = pd.DataFrame()\n",
    "for agent_dir in dirs:\n",
    "    agent_name = os.path.basename(agent_dir)\n",
    "    print('==============================================')\n",
    "    print(agent_name)\n",
    "    \n",
    "    rl = sb3_class.SB3forMultifirefly(overall_folder=str(agent_dir))\n",
    "\n",
    "    rl.collect_data(n_steps=500, exists_ok=False)\n",
    "    \n",
    "    num_caught_ff = len(rl.ff_caught_T_sorted)\n",
    "        \n",
    "    result = {'dv': rl.env_for_data_collection.dv_cost_factor, \n",
    "              'jerk': rl.env_for_data_collection.jerk_cost_factor, \n",
    "              'stop': rl.env_for_data_collection.cost_per_stop, \n",
    "              'num_obs_ff': rl.env_for_data_collection.num_obs_ff,\n",
    "              'max_in_memory_time': rl.env_for_data_collection.max_in_memory_time,\n",
    "              'identity_slot_strategy': rl.env_for_data_collection.identity_slot_strategy,\n",
    "              'identity_slot_base': rl.env_for_data_collection.identity_slot_base,\n",
    "              'new_ff_scope': rl.env_for_data_collection.new_ff_scope,\n",
    "              'num_caught_ff': num_caught_ff,\n",
    "              'num_stops': (rl.monkey_information['monkey_speeddummy']==0).sum(),\n",
    "              'agent_name': agent_name,\n",
    "              }\n",
    "    _cost_results = pd.concat([_cost_results, pd.DataFrame([result])], ignore_index=True)\n",
    "cost_results = _cost_results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_results = cost_results[~cost_results['agent_name'].str.contains('201304', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)   # or any number you want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_results.sort_values(by='num_caught_ff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_results.sort_values(by='num_stops', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "group_vars = ['identity_slot_strategy', 'identity_slot_base', 'new_ff_scope']\n",
    "\n",
    "for var in group_vars:\n",
    "    print('\\n===', var, '===\\n')\n",
    "    display(\n",
    "        cost_results\n",
    "        .groupby(var)[['num_caught_ff', 'num_stops']]\n",
    "        .agg(['mean', 'std', 'count'])\n",
    "        .sort_values(('num_caught_ff', 'mean'), ascending=False)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "strategies = cost_results['identity_slot_strategy'].unique()\n",
    "\n",
    "means = cost_results.groupby('identity_slot_strategy')['num_caught_ff'].mean()\n",
    "stds = cost_results.groupby('identity_slot_strategy')['num_caught_ff'].std()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(strategies, means, yerr=stds)\n",
    "plt.ylabel('num_caught_ff (mean ± std)')\n",
    "plt.title('Performance by identity_slot_strategy')\n",
    "plt.xticks(rotation=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(cost_results['num_obs_ff'], cost_results['num_caught_ff'])\n",
    "plt.xlabel('num_obs_ff')\n",
    "plt.ylabel('num_caught_ff')\n",
    "plt.title('num_caught_ff vs num_obs_ff')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = cost_results['max_in_memory_time'].values\n",
    "y = cost_results['num_caught_ff'].values\n",
    "\n",
    "# jitter amount (tune as needed)\n",
    "x_jitter = x + (np.random.randn(len(x)) * 0.02)\n",
    "y_jitter = y + (np.random.randn(len(y)) * 0.5)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(x_jitter, y_jitter)\n",
    "plt.xlabel('max_in_memory_time')\n",
    "plt.ylabel('num_caught_ff')\n",
    "plt.title('num_caught_ff vs memory time (jittered)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "## heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'num_caught_ff'\n",
    "\n",
    "# cost_results2 = cost_results[cost_results['agent_name'].str.contains('175252', na=False)]\n",
    "cost_results2 = cost_results.copy()\n",
    "\n",
    "df_mean = cost_results2.groupby(['dv', 'jerk', 'stop'], as_index=False)[col].mean()\n",
    "\n",
    "unique_dv = sorted(df_mean['dv'].unique())\n",
    "\n",
    "for dv_value in unique_dv:\n",
    "    df_plot = df_mean[df_mean['dv'] == dv_value].pivot(index='stop', columns='jerk', values=col)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(df_plot, annot=True, cmap='magma', fmt='.0f')\n",
    "    plt.title(f'dv = {dv_value}')\n",
    "    plt.xlabel('jerk')\n",
    "    plt.ylabel('stop')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## Iterate animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "for agent_dir in dirs:\n",
    "    agent_name = os.path.basename(agent_dir)\n",
    "    print('==============================================')\n",
    "    print(agent_name)\n",
    "    \n",
    "    rl = sb3_class.SB3forMultifirefly(overall_folder=str(agent_dir))\n",
    "\n",
    "    rl.streamline_making_animation(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 20], n_steps=250, video_dir=None,\n",
    "                                  data_exists_ok=True, display_inline=False,\n",
    "                                  save_video=False)\n",
    "\n",
    "    num_caught_ff = len(rl.ff_caught_T_sorted)\n",
    "\n",
    "    # Convert animation to HTML\n",
    "    html_str = rl.anim.to_jshtml()\n",
    "\n",
    "    video_path_name = os.path.join(base_path, 'derived_agent_animation', f'{agent_name}_C_{num_caught_ff}.html')\n",
    "    os.makedirs(os.path.dirname(video_path_name), exist_ok=True)\n",
    "    with open(video_path_name, 'w') as f:\n",
    "        f.write(html_str)\n",
    "        print(f\"Animation saved to {video_path_name}\")\n",
    "        \n",
    "    print(rl.monkey_information['speed'].values[:30])\n",
    "        \n",
    "    # from IPython.display import HTML\n",
    "    # HTML(rl.anim.to_jshtml()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67",
   "metadata": {
    "id": "da26c42f"
   },
   "source": [
    "# Loop (for hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## test params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dw_cost_factor in range(30, 100, 10):\n",
    "    params = {\n",
    "        'dv_cost_factor': 10,\n",
    "        'dw_cost_factor': dw_cost_factor,\n",
    "        'w_cost_factor': 10,\n",
    "    }\n",
    "\n",
    "    num_obs_ff = 3\n",
    "    max_in_memory_time = 3\n",
    "    overall_folder = f'multiff_analysis/RL_models/SB3_stored_models/all_agents/env1_test_params/ff{num_obs_ff}/'\n",
    "\n",
    "    env_kwargs = {'num_obs_ff': num_obs_ff,\n",
    "                'max_in_memory_time': max_in_memory_time,\n",
    "                'print_ff_capture_incidents': False\n",
    "                #'reward_per_ff': 120,\n",
    "    }\n",
    "\n",
    "    # check if num_obs_ff is consistent with the name in overall_folder. If not, raise an error\n",
    "    if not f'ff{env_kwargs[\"num_obs_ff\"]}' in overall_folder:\n",
    "        raise ValueError('num_obs_ff is not consistent with the name in overall_folder')\n",
    "\n",
    "    gc.collect()\n",
    "    print(\"Current parameters: \", params)\n",
    "\n",
    "    # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "    rl = sb3_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                        **env_kwargs)\n",
    "\n",
    "    #rl.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "    rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                    best_model_postcurriculum_exists_ok=True, to_load_latest_agent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "## env1 loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#           'dv_cost_factor': 10,\n",
    "#           'dw_cost_factor': 10,\n",
    "#           'w_cost_factor': 10,\n",
    "# }\n",
    "\n",
    "params = {\n",
    "          'dv_cost_factor': 0,\n",
    "          'dw_cost_factor': 0,\n",
    "          'w_cost_factor': 0,\n",
    "}\n",
    "\n",
    "for max_in_memory_time in [3, 2, 1]:\n",
    "    for num_obs_ff in [2, 1, 3, 4, 5]:\n",
    "        overall_folder = f'multiff_analysis/RL_models/SB3_stored_models/all_agents/env1_relu/ff{num_obs_ff}/'\n",
    "\n",
    "        env_kwargs = {'num_obs_ff': num_obs_ff,\n",
    "                    'max_in_memory_time': max_in_memory_time,\n",
    "                    'print_ff_capture_incidents': False\n",
    "                    #'reward_per_ff': 120,\n",
    "        }\n",
    "\n",
    "        # check if num_obs_ff is consistent with the name in overall_folder. If not, raise an error\n",
    "        if not f'ff{env_kwargs[\"num_obs_ff\"]}' in overall_folder:\n",
    "            raise ValueError('num_obs_ff is not consistent with the name in overall_folder')\n",
    "\n",
    "        gc.collect()\n",
    "        print(\"Current parameters: \", params)\n",
    "\n",
    "        # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "        rl = sb3_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                            **env_kwargs)\n",
    "\n",
    "        #rl.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "        rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                        best_model_postcurriculum_exists_ok=True, to_load_latest_agent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "## combos of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample from a range\n",
    "param_combinations = []\n",
    "num_param_combinations = 20\n",
    "for i in range(num_param_combinations):\n",
    "    combo = dict()\n",
    "    #combo[\"time_cost\"] = round(random.uniform(20, 50), 2)\n",
    "    combo[\"dv_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"dw_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"w_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    param_combinations.append(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/SB3_stored_models/all_agents/env1_relu/ff3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'num_obs_ff': 3,\n",
    "              'print_ff_capture_incidents': False\n",
    "              #'reward_per_ff': 120,\n",
    "}\n",
    "\n",
    "for count, params in enumerate(param_combinations):\n",
    "    gc.collect()\n",
    "    print(\"Running\", str(count), \"out of\", len(param_combinations), \"combinations of parameters\")\n",
    "    print(\"Current parameters: \", params)\n",
    "\n",
    "    # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "\n",
    "    rl = sb3_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                     **env_kwargs)\n",
    "\n",
    "    #rl.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "    rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                  best_model_postcurriculum_exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl.load_best_model_postcurriculum()\n",
    "rl.streamline_making_animation(duration=[10, 40])\n",
    "#rl.streamline_loading_and_making_animation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "## env2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample from a range\n",
    "param_combinations = []\n",
    "num_param_combinations = 10\n",
    "for i in range(num_param_combinations):\n",
    "    combo = dict()\n",
    "    #combo[\"time_cost\"] = round(random.uniform(20, 50), 2)\n",
    "    combo[\"dv_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"dw_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"w_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    param_combinations.append(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/SB3_stored_models/all_agents/gen_28_env2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'num_obs_ff': 10,\n",
    "              'make_ff_always_flash_on': False,\n",
    "              'max_in_memory_time': 3,\n",
    "              'linear_terminal_vel': 0.01,\n",
    "              'angular_terminal_vel': 0.01,\n",
    "              'reward_per_ff': 100,\n",
    "              'dt': 0.1,\n",
    "              'add_vel_cost_when_catching_ff_only': False,\n",
    "              #'reward_per_ff': 120,\n",
    "}\n",
    "\n",
    "for count, params in enumerate(param_combinations):\n",
    "    gc.collect()\n",
    "    print(\"Running\", str(count), \"out of\", len(param_combinations), \"combinations of parameters\")\n",
    "    print(\"Current parameters: \", params)\n",
    "\n",
    "    # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "\n",
    "    rl = sb3_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                     **env_kwargs,\n",
    "                                                     use_env2=True)\n",
    "\n",
    "    #rl.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "    rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                  best_model_postcurriculum_exists_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "## remake animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For every folder in slow:\n",
    "# # Extract parameters from the folder name\n",
    "# # Re-make the env\n",
    "# # Load agent\n",
    "# # And then make animation\n",
    "\n",
    "# overall_folder = 'multiff_analysis/RL_models/SB3_stored_models/all_agents/gen_30_env1_4ff'\n",
    "# folders = os.listdir(overall_folder)\n",
    "# for folder in folders:\n",
    "#     if 'time' not in folder:\n",
    "#         continue\n",
    "#     print(\"Currently working on\", folder)\n",
    "#     folder_path = overall_folder + '/' + folder\n",
    "#     params = rl_base_utils.extract_cost_params_from_folder_name(folder)\n",
    "#     rl = sb3_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "#                                                      make_ff_always_flash_on=True)\n",
    "#     #rl.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "#     rl.model_folder_name = folder_path\n",
    "#     rl.make_env()\n",
    "#     rl.make_agent()\n",
    "#     rl.load_agent(load_replay_buffer=False)\n",
    "#     rl.collect_data()\n",
    "#     rl.set_animation_parameters(currentTrial=5, num_trials=5, k=1)\n",
    "#     rl.call_animation_function()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84",
   "metadata": {
    "id": "5409a0bd"
   },
   "source": [
    "# Env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85",
   "metadata": {
    "id": "9703eb0c"
   },
   "source": [
    "## regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "id": "30a34ff5"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {}\n",
    "env = sb3_env.EnvForSB3(**env_kwargs)\n",
    "model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/regular\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "env = Monitor(env, model_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "## make_ff_always_flash_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'make_ff_always_flash_on': True,\n",
    "              'ffr_noise_scale': 0,}\n",
    "env = sb3_env.EnvForSB3(**env_kwargs)\n",
    "model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/regular\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "env = Monitor(env, model_folder_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89",
   "metadata": {
    "id": "83d0be92"
   },
   "source": [
    "## one-ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "id": "08c7fb7e"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {'num_obs_ff': 1}\n",
    "env = sb3_env.EnvForSB3(**env_kwargs)\n",
    "env = Monitor(env, model_folder_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91",
   "metadata": {
    "id": "6d8ef0c3"
   },
   "source": [
    "## with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "id": "70417219"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\"v_noise_std\": 0.1, \n",
    "              \"w_noise_std\": 0.1,\n",
    "              \"ffr_noise_scale\": 4, \n",
    "              \"num_obs_ff\": 2,\n",
    "              \"max_in_memory_time\": 2.5}\n",
    "# model_folder_name =overall_folder + \"/SB3_stored_models/all_agents/v\" +\n",
    "#                        str(v_noise_std) + \"_w_\" + str(w_noise_std) + \"_o_\" + str(ffr_noise_scale) + \\\n",
    "#                        \"_ff_\" + str(num_obs_ff) + \"_m_\" + str(max_in_memory_time)\n",
    "env = env.MultiFF(**env_kwargs)\n",
    "env = Monitor(env, model_folder_name)\n",
    "model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/A0.2_O4_ff2_M3\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93",
   "metadata": {
    "id": "50d88dc9"
   },
   "source": [
    "# Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94",
   "metadata": {
    "id": "ea153406"
   },
   "source": [
    "## make agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "id": "4c411166"
   },
   "outputs": [],
   "source": [
    "# For direct training\n",
    "rl_agent = SAC(\"MlpPolicy\", \n",
    "            env,\n",
    "            gamma=0.995,\n",
    "            learning_rate=0.0015,\n",
    "            batch_size=1024,\n",
    "            target_update_interval=50,\n",
    "            buffer_size=1000000,\n",
    "            learning_starts=10000,\n",
    "            train_freq=10,\n",
    "            ent_coef='auto',\n",
    "            policy_kwargs=dict(activation_fn=nn.Tanh, net_arch=[128, 128])\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96",
   "metadata": {
    "id": "37268cc4"
   },
   "source": [
    "## load agent (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "id": "fd640727"
   },
   "outputs": [],
   "source": [
    "path = os.path.join(model_folder_name, 'best_model.zip')\n",
    "path2 = os.path.join(model_folder_name, 'buffer.pkl')\n",
    "rl_agent = rl_agent.load(path,env=env) \n",
    "rl_agent.load_replay_buffer(path2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98",
   "metadata": {
    "id": "b372808d"
   },
   "source": [
    "## Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"multiff_analysis/RL_models/SB3_stored_models/all_agents/temp_9_29\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "id": "21a908ec"
   },
   "outputs": [],
   "source": [
    "callback = sb3_utils.SaveOnBestTrainingRewardCallback(check_freq=20000, model_folder_name=model_folder_name)\n",
    "#timesteps = 50000000\n",
    "timesteps = 500000\n",
    "rl_agent.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "plot_results([model_folder_name], timesteps, results_plotter.X_TIMESTEPS, \"env.MultiFF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {
    "id": "1919e84e"
   },
   "outputs": [],
   "source": [
    "plot_results([model_folder_name], timesteps, results_plotter.X_TIMESTEPS, \"env.MultiFF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "id": "9c3d27b8"
   },
   "outputs": [],
   "source": [
    "rl_agent.save(os.path.join(model_folder_name, 'best_model'))\n",
    "rl_agent.save_replay_buffer(os.path.join(model_folder_name, 'buffer')) # I added this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {
    "id": "492f1169"
   },
   "outputs": [],
   "source": [
    "stop_train_callback = sb3_utils.StopTrainingOnNoModelImprovement(max_no_improvement_evals=10, min_evals=20, verbose=1)\n",
    "callback = EvalCallback(env, eval_freq=5000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "# timesteps = 50000000\n",
    "timesteps = 5000000\n",
    "rl_agent.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "\n",
    "rl_agent.save(os.path.join(model_folder_name, 'best_model'))\n",
    "rl_agent.save_replay_buffer(os.path.join(model_folder_name, 'buffer')) # I added this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "104",
   "metadata": {
    "id": "d075400f"
   },
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_anim = sb3_class.SB3forMultifirefly(overall_folder='multiff_analysis/RL_models/SB3_stored_models/all_agents/gen_12/', **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_anim.rl_agent = rl_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_anim.streamline_making_animation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "108",
   "metadata": {
    "id": "b056b5cc"
   },
   "source": [
    "# Interpret neural network (only works on 1-ff env rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use combine_6_plots_for_neural_network from rl_base_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "110",
   "metadata": {
    "id": "efeeb570"
   },
   "source": [
    "# Plot statistics (pasted from visualization.ipynb)\n",
    "compare monkey and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function above from rl_base_class:   \n",
    "    # def save_plots_in_data_folders(self):\n",
    "    #     plot_statistics.plot_pattern_frequencies(self.agent_monkey_pattern_frequencies, compare_monkey_and_agent=True, data_folder_name=self.processed_data_folder_path)\n",
    "    #     plot_statistics.plot_feature_statistics(self.agent_monkey_feature_statistics, compare_monkey_and_agent=True, data_folder_name = self.processed_data_folder_path)\n",
    "\n",
    "    #     plot_statistics.plot_feature_histograms_for_monkey_and_agent(self.all_trial_features_valid_m, self.all_trial_features_valid, data_folder_name = self.model_folder_name)\n",
    "    #     print(\"Made new plots\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "112",
   "metadata": {
    "id": "TQMCDI-FqP6s"
   },
   "source": [
    "# Plot side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function plot_side_by_side from rl_base_class:   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "114",
   "metadata": {
    "id": "xIYoWAIyDieu"
   },
   "source": [
    "# Polar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "115",
   "metadata": {
    "id": "aoaz1_ng6QMt"
   },
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {
    "id": "ZrSbMmCJ5uN1"
   },
   "outputs": [],
   "source": [
    "num_trials = 1\n",
    "for currentTrial in range(40,43):\n",
    "    print(currentTrial)\n",
    "    #duration = [ff_caught_T_new[currentTrial-num_trials], ff_caught_T_new[currentTrial]]\n",
    "    duration = [ff_caught_T_new[currentTrial]-1.25, ff_caught_T_new[currentTrial]]\n",
    "\n",
    "\n",
    "    plot_polar.PlotPolar(duration,\n",
    "              monkey_information,\n",
    "              ff_dataframe, \n",
    "              ff_life_sorted,\n",
    "              ff_real_position_sorted,\n",
    "              ff_caught_T_new,\n",
    "              ff_flash_sorted,\n",
    "              rmax = 100,\n",
    "              currentTrial = currentTrial,\n",
    "              num_trials = num_trials,\n",
    "              show_visible_ff = True,\n",
    "              show_visible_target = True,\n",
    "              show_ff_in_memory = True,\n",
    "              show_target_in_memory = True,\n",
    "              show_alive_ff = True\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "117",
   "metadata": {
    "id": "ZLNksPtjduik"
   },
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {
    "id": "79OZSKw1duBP"
   },
   "outputs": [],
   "source": [
    "currentTrial = 10\n",
    "num_trials = 2\n",
    "filename = f\"Trials {currentTrial-num_trials+1}-{currentTrial}\"\n",
    "print(filename)\n",
    "k = 4\n",
    "rmax = 100\n",
    "colors_Reds = plt.get_cmap(\"Reds\")(np.linspace(0,1,101))\n",
    "colors_YlGn = plt.get_cmap(\"YlGn\")(np.linspace(0,1,101))\n",
    "cum_pos_index = np.where((monkey_information['time'] > ff_caught_T_new[currentTrial-num_trials]) & \n",
    "                       (monkey_information['time'] <= ff_caught_T_new[currentTrial]))\n",
    "\n",
    "if len(cum_pos_index) > 0:\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8], polar=True)\n",
    "    ax = plot_behaviors_utils.set_polar_background_for_animation(ax, rmax)\n",
    "\n",
    "    ff_in_time_frame, ff_visible, ff_in_memory = animation_func.subset_ff_dataframe(ff_dataframe, currentTrial, num_trials)\n",
    "    anim_indices = cum_pos_index[0][0:-1:k]\n",
    "    num_frames = anim_indices.size\n",
    "    animate_func = partial(animation_func.animate_polar, ax=ax, anim_indices=anim_indices, rmax=400, ff_in_time_frame=ff_in_time_frame, ff_visible=ff_visible, ff_in_memory=ff_in_memory)\n",
    "    anim = animation.FuncAnimation(fig, animate_func, frames=num_frames, interval=int(250*k), repeat=True) \n",
    "\n",
    "    #gif_dir = '/content/gdrive/My Drive/fireflies_anim/???'\n",
    "    #anim.save(f\"{gif_dir}/{filename}.gif\", writer='pillow', fps=60)\n",
    "else:\n",
    "    print(\"Please try another number for currentTrial, or increase num_trials.\")\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "119",
   "metadata": {
    "id": "r6j1e2uxq5OG"
   },
   "source": [
    "# Test agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {
    "id": "k9-tdbAHq5_U"
   },
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "cum_rewards = 0\n",
    "for step in range(1000):\n",
    "    action, _ = rl_agent.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    cum_rewards += reward\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "    # print(step, ffxy_visible[-1])\n",
    "print(cum_rewards)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "121",
   "metadata": {
    "id": "1Inbx37xwycW"
   },
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "122",
   "metadata": {
    "id": "hfHYXONdz7qJ"
   },
   "source": [
    "## parameters to sample from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {
    "id": "xhBysB7hz_F8"
   },
   "outputs": [],
   "source": [
    "def sample_sac_params(trial):\n",
    "    \"\"\"\n",
    "    Sampler for SAC hyperparams.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial: (optuna.trial)\n",
    "\n",
    "    Return: (dict)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
    "    tau = trial.suggest_float(\"tau\", 1e-6, 1, log=True)\n",
    "    #batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256, 512, 1024])\n",
    "    target_update_interval = trial.suggest_categorical('target_update_interval', [5, 10, 20, 40, 60, 100, 200])\n",
    "    #buffer_size = trial.suggest_categorical('buffer_size', [int(1e5), int(1e6)]) # This actually doesn't matter much here because of limited timesteps\n",
    "    learning_starts = trial.suggest_categorical('learning_starts', [5000, 10000, 15000])\n",
    "    train_freq = trial.suggest_categorical('train_freq', [1, 10, 100, 300])\n",
    "    ## gradient_steps takes too much time\n",
    "    # gradient_steps = trial.suggest_categorical('gradient_steps', [1, 100, 300])\n",
    "    gradient_steps = train_freq\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
    "    net_arch = trial.suggest_categorical('net_arch', [\"small\", \"medium\", \"big\"])\n",
    "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\"])\n",
    "\n",
    "    net_arch = {\n",
    "        'small': [100, 100],\n",
    "        'medium': [128, 128],\n",
    "        'big': [200, 200],\n",
    "    }[net_arch]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
    "\n",
    "    target_entropy = 'auto'\n",
    "    if ent_coef == 'auto':\n",
    "        target_entropy = trial.suggest_categorical('target_entropy', ['auto', -1, -10, -20, -50, -100])\n",
    "\n",
    "\n",
    "    ## Display true values\n",
    "    # trial.set_user_attr(\"gamma_\", gamma)\n",
    "    # trial.set_user_attr(\"n_steps\", n_steps)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'gamma': gamma,\n",
    "        'learning_rate': learning_rate,\n",
    "        'tau': tau,\n",
    "        #'batch_size': batch_size,\n",
    "        'target_update_interval': target_update_interval,\n",
    "        #'buffer_size': buffer_size,\n",
    "        'learning_starts': learning_starts,\n",
    "        'train_freq': train_freq,\n",
    "        'gradient_steps': gradient_steps,\n",
    "        'ent_coef': ent_coef,\n",
    "        'target_entropy': target_entropy,\n",
    "        'policy_kwargs': {\n",
    "            \"net_arch\": net_arch,\n",
    "            \"activation_fn\": activation_fn\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "124",
   "metadata": {
    "id": "iV2OVSz10Bve"
   },
   "source": [
    "## objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {
    "id": "-3YZk9SVxCWh"
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    # Sample hyperparameters\n",
    "    kwargs.update(sample_sac_params(trial))\n",
    "    # Create the RL model\n",
    "    model = SAC(**kwargs)\n",
    "    # Create env used for evaluation\n",
    "    eval_env = env\n",
    "    # Create the callback that will periodically evaluate\n",
    "    # and report the performance\n",
    "    eval_callback = sb3_utils.TrialEvalCallback(\n",
    "      eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=eval_freq, deterministic=True\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "      model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "      # Sometimes, random hyperparams can generate NaN\n",
    "      print(e)\n",
    "      nan_encountered = True\n",
    "    finally:\n",
    "      # Free memory\n",
    "      model.env.close()\n",
    "      eval_env.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed\n",
    "    if nan_encountered:\n",
    "      return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "      raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "126",
   "metadata": {
    "id": "UVyTUNFzHtLP"
   },
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {
    "id": "Dhl9rpZPH0w6"
   },
   "outputs": [],
   "source": [
    "env = sb3_env.EnvForSB3()\n",
    "env.reset()\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": env,\n",
    "}\n",
    "\n",
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "\n",
    "\n",
    "N_TIMESTEPS = 100000\n",
    "eval_freq = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 1\n",
    "\n",
    "\n",
    "\n",
    "# Set pytorch num threads to 1 for faster training\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "# Do not prune before 1/3 of the max budget is used\n",
    "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS//3)\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "128",
   "metadata": {
    "id": "Pj9Wo6ylF0MI"
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {
    "id": "HQmdse_eWe-F"
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq ipdb\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {
    "id": "hkdgF8xfWgS-"
   },
   "outputs": [],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_item.clean_out_cross_boundary_trials()\n",
    "category_item.clean_out_trials_where_target_cluster_was_not_seen_for_a_long_time_before_capture()\n",
    "category_item.make_polar_plot_of_target_last_seen_positions()\n",
    "category_item.make_histograms_of_target_last_seen_attributes()\n",
    "category_item.make_histogram_of_distances_from_previous_targets()\n",
    "category_item.make_polar_plot_of_positions_from_previous_targets()\n",
    "category_item.plot_trajectories(trials=category_item.sort_1_trials[17:18])\n",
    "category_item.plot_distributions_of_visible_ff_and_in_memory_ff()\n",
    "#category_item.make_and_visualize_free_selection_predictions_using_trained_model(trained_model = gnb)\n",
    "# category_item.inspect_special_cases(weird_trials=[98, 180, 212, 649])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1GN5Y_MBqDlaM8t8KZqZZKeERvOau11W_",
     "timestamp": 1681009447473
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
