{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from data_wrangling import specific_utils, process_monkey_information, base_processing_class\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_points, make_ff_dataframe, ff_dataframe_utils, pattern_by_trials, pattern_by_points, cluster_analysis, organize_patterns_and_features, category_class\n",
    "from decision_making_analysis.cluster_replacement import cluster_replacement_utils, plot_cluster_replacement\n",
    "from decision_making_analysis.decision_making import decision_making_utils, plot_decision_making, intended_targets_classes\n",
    "from decision_making_analysis.GUAT import GUAT_helper_class, GUAT_collect_info_class, GUAT_combine_info_class, add_features_GUAT_and_TAFT\n",
    "from decision_making_analysis import free_selection, replacement, trajectory_info\n",
    "from visualization.matplotlib_tools import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from null_behaviors import sample_null_distributions, show_null_trajectory\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class\n",
    "from reinforcement_learning.base_classes import env_utils, base_env, more_envs, rl_base_class, rl_base_utils\n",
    "from reinforcement_learning.agents.rnn import gru_utils, lstm_utils, lstm_utils, lstm_class, gru_class\n",
    "from reinforcement_learning.agents.feedforward import interpret_neural_network, sb3_class, sb3_utils\n",
    "from reinforcement_learning.agents.rnn import rnn_env\n",
    "from reinforcement_learning.collect_data import collect_agent_data, process_agent_data\n",
    "\n",
    "from eye_position_analysis import eye_positions\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import neural_data_modeling\n",
    "from decision_making_analysis.compare_GUAT_and_TAFT import find_GUAT_or_TAFT_trials\n",
    "from reinforcement_learning.agents.feedforward import interpret_neural_network, sb3_class, sb3_utils\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from gymnasium import spaces, Env\n",
    "import torch\n",
    "import optuna\n",
    "from numpy import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from torch.linalg import vector_norm\n",
    "from IPython.display import HTML\n",
    "from functools import partial\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import gc\n",
    "from importlib import reload\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "device_idx = 0\n",
    "# device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "## if using Jupyter Notebook\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model_folder_name = \"multiff_analysis/RL_models/LSTM_stored_models/all_agents/gen_0/LSTM_Aug_1_24\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "PLAYER = \"agent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# streamline everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### oct_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/GRU_stored_models/all_agents/oct_28_4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_folder = 'multiff_analysis/RL_models/GRU_stored_models/all_agents/lr3e-4_numobs3_job132779_8/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/GRU_stored_models/all_agents/lr1e-3_numobs6_mem2_job134201_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/GRU_stored_models/all_agents/lr3e-4_numobs7_mem1_job134933_8/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/GRU_stored_models/all_agents/lr3e-4_numobs6_mem2_job134933_5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_kwargs = {'num_obs_ff': 7,\n",
    "              'add_action_to_obs': True,\n",
    "              'angular_terminal_vel': 0.05,\n",
    "              \"dt\": 0.1,\n",
    "              \"max_in_memory_time\": 2,\n",
    "            }   \n",
    "rl = gru_class.GRUforMultifirefly(overall_folder=overall_folder,\n",
    "                                                **env_kwargs)\n",
    "\n",
    "# rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "#                          best_model_postcurriculum_exists_ok=True)\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(base_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "what seemed to work at last: clamping to avoid NA\n",
    "other changes made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_replay_buffer = False\n",
    "rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                         to_load_latest_agent=True,\n",
    "                         best_model_postcurriculum_exists_ok=True,\n",
    "                         to_train_agent=False,\n",
    "                         load_replay_buffer=False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## see animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.ff_caught_T_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl.make_env(**rl.env_kwargs)\n",
    "# rl.make_agent()\n",
    "# # rl.make_init_env_for_curriculum_training()\n",
    "# rl.load_best_model_postcurriculum()\n",
    "rl.streamline_making_animation(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[0, 20], n_steps=500, video_dir=None,\n",
    "                               data_exists_ok=True)\n",
    "from IPython.display import Video\n",
    "Video(rl.video_path_name, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## manually eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reward = gru_utils.evaluate_gru_agent(\n",
    "    rl.env, rl.rl_agent, 512, 2, deterministic=True)\n",
    "print(\n",
    "    f\"Best average reward: {rl.best_avg_reward}, Current average reward: {avg_reward}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
