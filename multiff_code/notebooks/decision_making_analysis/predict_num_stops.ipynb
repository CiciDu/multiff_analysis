{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if using google drive\n",
    "# %cd /content/drive/MyDrive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from data_wrangling import specific_utils, combine_info_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features, category_class\n",
    "from decision_making_analysis.cluster_replacement import cluster_replacement_utils\n",
    "from decision_making_analysis.decision_making import decision_making_class, decision_making_utils, intended_targets_classes\n",
    "from decision_making_analysis.GUAT import GUAT_collect_info_class, GUAT_combine_info_class, process_GUAT_trials_class\n",
    "from decision_making_analysis.compare_GUAT_and_TAFT import GUAT_vs_TAFT_class, GUAT_vs_TAFT_x_sessions_class, helper_GUAT_vs_TAFT_class\n",
    "from visualization.matplotlib_tools import plot_trials, plot_behaviors_utils\n",
    "from visualization.animation import animation_class\n",
    "from null_behaviors import show_null_trajectory, find_best_arc, curvature_utils, curv_of_traj_utils\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class\n",
    "from visualization.plotly_polar_tools import plotly_utils_polar, plotly_for_ff_polar, plotly_for_trajectory_polar\n",
    "from machine_learning.ml_methods import ml_methods_class\n",
    "from machine_learning.ml_methods.advanced_ml_methods import advanced_regression_utils, advanced_classification_utils, reg_feat_importance\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os, sys, sys\n",
    "from importlib import reload\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.max_rows = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Predict num stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## data from all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_kwargs = helper_GUAT_vs_TAFT_class.gc_kwargs.copy()\n",
    "\n",
    "gc_kwargs_temp = {**gc_kwargs,\n",
    "                    'num_old_ff_per_row': 2,\n",
    "                    'num_new_ff_per_row': 3}\n",
    "\n",
    "gas = GUAT_combine_info_class.GUATCombineInfoAcrossSessions(gc_kwargs_temp, monkey_name='monkey_Schro')\n",
    "gas.retrieve_or_make_combined_info(gc_kwargs_temp, combined_info_exists_ok=True, traj_df_exist_in_GUAT_store_ok=True)\n",
    "gas.unpack_and_reload_combined_info_back_to_self(gas.combined_info, gas.all_traj_feature_names)\n",
    "\n",
    "# shared part with 'data from one session'\n",
    "gas.process_current_and_alternative_ff_info()\n",
    "more_ff_attributes = ['ff_distance', 'ff_angle', 'ff_angle_boundary', 'curv_diff']\n",
    "ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "ff_next_seen_attributes = ['next_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_next_seen', 'angle_from_monkey_now_to_monkey_when_ff_next_seen']\n",
    "gas.find_input_and_output(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "                          ff_attributes=['ff_distance', 'ff_angle', 'ff_angle_boundary', 'time_since_last_vis', 'duration_of_last_vis_period']\n",
    "                          + ff_last_seen_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## data from one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc_kwargs = helper_GUAT_vs_TAFT_class.gc_kwargs.copy()\n",
    "\n",
    "# raw_data_folder_path = 'all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330'\n",
    "# gcc = GUAT_collect_info_class.GUATCollectInfoForSession(raw_data_folder_path=raw_data_folder_path, \n",
    "#                                                         gc_kwargs=gc_kwargs, new_point_index_start=0)\n",
    "# _ = gcc.streamline_process_to_collect_info_from_one_session(GUAT_w_ff_df_exists_ok=True,\n",
    "#                                                             GUAT_info_exists_ok=False)\n",
    "\n",
    "# gas = GUAT_combine_info_class.GUATCombineInfoAcrossSessions(gc_kwargs)\n",
    "# gas.unpack_and_reload_combined_info_back_to_self(gcc.important_info, gcc.all_traj_feature_names)\n",
    "\n",
    "# # shared part with 'data from all sessions'\n",
    "# gas.process_current_and_alternative_ff_info()\n",
    "# more_ff_attributes = ['ff_distance', 'ff_angle', 'curv_diff']\n",
    "# ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "# ff_next_seen_attributes = ['next_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_next_seen', 'angle_from_monkey_now_to_monkey_when_ff_next_seen']\n",
    "# gas.find_input_and_output(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "#                           ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis', 'duration_of_last_vis_period']\n",
    "#                           + ff_last_seen_attributes)\n",
    "# # additional features we can try: 'time_till_next_visible'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### FIRST get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.furnish_with_trajectory_data = True\n",
    "gas.prepare_data_for_machine_learning()\n",
    "y_var_df = pd.DataFrame(gas.num_stops, columns=['num_stops'])\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'].astype(int)\n",
    "\n",
    "\n",
    "# and for classification\n",
    "y_var_df2 = y_var_df.copy()\n",
    "# y_var_df2.loc[y_var_df2['num_stops'] > 2, 'num_stops'] = 2\n",
    "y_var_df2.loc[y_var_df2['num_stops'] > 2, 'num_stops'] = 2\n",
    "y_var_df2['num_stops'] = y_var_df2['num_stops'].astype(int)\n",
    "y_var_df2['num_stops'] = y_var_df2['num_stops'] - 1  # to avoid problem during classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.X_all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.X_all_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gas.X_all_df,\n",
    "                                     y_var_df=y_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_names=['linreg', 'grad_boosting', 'rf']\n",
    "model_names=None\n",
    "\n",
    "ml_inst.use_ml_model_for_regression(ml_inst.x_var_df, ml_inst.y_var_df, model_names=model_names)\n",
    "ml_inst.model_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## advanced regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "df, best = advanced_regression_utils.use_advanced_model_for_regression(\n",
    "    ml_inst.X_train, ml_inst.y_train, ml_inst.X_test, ml_inst.y_test,\n",
    "    use_cv=True, cv_splits=5, verbose=True,\n",
    "    save_dir=\"all_monkey_data/temp_ml_results/pred_num_stops\",\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "# Example: fit your models\n",
    "dt = DecisionTreeRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "gb = GradientBoostingRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "hgb = HistGradientBoostingRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "ada = AdaBoostRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "# Collect in a dict\n",
    "models = {\n",
    "    \"Decision Tree\": dt,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"HistGradientBoosting\": hgb,\n",
    "    \"AdaBoost\": ada,\n",
    "}\n",
    "\n",
    "# Get feature importances for each model\n",
    "for name, model in models.items():\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance = pd.DataFrame({\n",
    "            \"feature\": ml_inst.x_var_df.columns,\n",
    "            \"importance\": importances\n",
    "        }).sort_values(by=\"importance\", ascending=False)\n",
    "        \n",
    "        print(f\"\\n{name} Feature Importances:\")\n",
    "        print(feature_importance.head(10))  # top 10\n",
    "    else:\n",
    "        print(f\"\\n{name} does not expose feature_importances_.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### in the future I can figure out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# models = {\n",
    "#     \"hist_gb\": fitted_hist_gradient_boosting_regressor_or_pipeline,\n",
    "#     \"dt\": fitted_decision_tree_regressor_or_pipeline,\n",
    "#     \"grad_boosting\": fitted_gradient_boosting_regressor_or_pipeline,\n",
    "#     \"boosting\": fitted_adaboost_or_xgboost_or_lightgbm_or_pipeline,\n",
    "# }\n",
    "\n",
    "# # For each model:\n",
    "# for name, mdl in models.items():\n",
    "#     try:\n",
    "#         df_imp = feature_importance_table(mdl, X_valid, y_valid)  # y_valid only needed if fallback\n",
    "#         print(f\"\\n{name} â€” top 10\")\n",
    "#         print(df_imp.head(10))\n",
    "#     except Exception as e:\n",
    "#         print(f\"{name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you forgot to do this first:\n",
    "gas.furnish_with_trajectory_data = True\n",
    "gas.prepare_data_for_machine_learning() \n",
    "y_var_df = pd.DataFrame(gas.num_stops, columns=['num_stops'])\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'].astype(int)\n",
    "\n",
    "\n",
    "# and for classification\n",
    "y_var_df2 = y_var_df.copy()\n",
    "y_var_df2.loc[y_var_df2['num_stops'] > 2, 'num_stops'] = 2\n",
    "y_var_df2['num_stops'] = y_var_df2['num_stops'].astype(int)\n",
    "y_var_df2['num_stops'] = y_var_df2['num_stops'] - 1  # to avoid problem during classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gas.X_all_df,\n",
    "                                     y_var_df=y_var_df2)\n",
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "ml_inst.use_ml_model_for_classification(ml_inst.x_var_df, ml_inst.y_var_df, model_names=model_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## advanced classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning.ml_methods.advanced_ml_methods import advanced_regression_utils, advanced_classification_utils, reg_feat_importance\n",
    "reload(advanced_classification_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "tune = False\n",
    "\n",
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gas.X_all_df,\n",
    "                                     y_var_df=y_var_df2)\n",
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "model, y_pred, model_comparison_df = advanced_classification_utils.use_advanced_model_for_classification(\n",
    "    ml_inst.X_train, ml_inst.y_train, ml_inst.X_test, ml_inst.y_test,\n",
    "    kfold_cv=5,\n",
    "    tune=tune,                # turn tuning on/off\n",
    "    n_iter=30,                # ~3k samples sweet spot\n",
    "    tune_scoring=\"balanced_accuracy\",\n",
    "    checkpoint_dir=\"pred_num_stops/cls_runs\",   # folder to save progress\n",
    "    resume=resume,              # skip finished models on rerun\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# model's feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "statsmodels, logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Can't use it here because we are not predicting 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "\n",
    "# X2 = sm.add_constant(ml_inst.x_var_df)  # add intercept\n",
    "# logit_model = sm.Logit(ml_inst.y_var_df, X2)  # logistic regression\n",
    "# result = logit_model.fit()\n",
    "\n",
    "# print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": ml_inst.x_var_df.columns,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## grad_boosting (so that we can see feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.05, max_depth=7, max_features='sqrt',\n",
    "    min_samples_leaf=2, min_samples_split=7,\n",
    "    n_estimators=500, subsample=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': ml_inst.x_var_df.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 18))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df)\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "# Determine significant features (e.g., importance > 0.01)\n",
    "significant_features = feature_importances_df[feature_importances_df['Importance'] > 0.01]\n",
    "print(\"Significant features:\")\n",
    "print(significant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## sequential selection...? try it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "# model.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "# important = model.coef_[0] != 0\n",
    "# X_new = ml_inst.x_var_df.loc[:, important]\n",
    "# X_new.columns\n",
    "\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction=\"forward\")\n",
    "# X_new = sfs.fit_transform(ml_inst.x_var_df, ml_inst.y_var_df.values.ravel())\n",
    "\n",
    "\n",
    "# # Boolean mask of selected features\n",
    "# mask = sfs.get_support()\n",
    "\n",
    "# # Names of selected features\n",
    "# selected_features = ml_inst.x_var_df.columns[mask]\n",
    "\n",
    "# print(\"Selected features:\")\n",
    "# print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.prepare_data_for_machine_learning()\n",
    "gas.split_data_to_train_and_test(scaling_data=True)\n",
    "\n",
    "#bagging = BaggingClassifier(n_estimators=200, max_features=0.9, bootstrap_features=True, bootstrap=True, random_state=42)\n",
    "#gas.use_machine_learning_model_for_classification(model=bagging) \n",
    "\n",
    "gas.use_machine_learning_model_for_classification(model=None) #MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=1000, activation='relu', solver='adam', random_state=1))\n",
    "\n",
    "gas.get_pred_results_df()  \n",
    "gas.add_additional_info_to_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of cases where the number of stops is 1\n",
    "len(gas.num_stops[gas.num_stops==1])/len(gas.num_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(gas.num_stops)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### plot prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.plot_prediction_results(max_plot_to_make=5, show_reward_boundary=True, use_more_ff_inputs=True, use_more_traj_points=True,\n",
    "                            predict_num_stops=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### show more plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_i = 0\n",
    "max_plot_to_make = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_cases = np.arange(current_i, current_i+max_plot_to_make)\n",
    "gas.plot_prediction_results(selected_cases=selected_cases, \n",
    "                            max_plot_to_make=max_plot_to_make, \n",
    "                            show_reward_boundary=True, \n",
    "                            use_more_ff_inputs=True, \n",
    "                            use_more_traj_points=True,\n",
    "                            predict_num_stops=True)\n",
    "current_i += max_plot_to_make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.use_machine_learning_model_for_classification(model = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=1000))   \n",
    "gas.get_pred_results_df()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### loop through num_ff (as hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop\n",
    "for num_old_ff_per_row in [1, 2, 3]:\n",
    "    for num_new_ff_per_row in [1, 2, 3]:\n",
    "        print('num_old_ff_per_row:', num_old_ff_per_row)\n",
    "        print('num_new_ff_per_row:', num_new_ff_per_row)\n",
    "\n",
    "        gc_kwargs_temp = {**gc_kwargs,\n",
    "                            'num_old_ff_per_row': num_old_ff_per_row,\n",
    "                            'num_new_ff_per_row': num_new_ff_per_row}\n",
    "\n",
    "        gas = GUAT_combine_info_class.GUATCombineInfoAcrossSessions(gc_kwargs_temp)\n",
    "        gas.retrieve_or_make_combined_info(gc_kwargs_temp, combined_info_exists_ok=True, traj_df_exist_in_GUAT_store_ok=True)\n",
    "        gas.unpack_and_reload_combined_info_back_to_self(gas.combined_info, gas.all_traj_feature_names)\n",
    "\n",
    "\n",
    "        gas.process_current_and_alternative_ff_info()\n",
    "        more_ff_attributes = ['ff_distance', 'ff_angle', 'curv_diff']\n",
    "        ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "        ff_next_seen_attributes = ['next_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_next_seen', 'angle_from_monkey_now_to_monkey_when_ff_next_seen']\n",
    "\n",
    "\n",
    "        gas.find_input_and_output(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "                                ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis', 'time_till_next_visible', 'duration_of_last_vis_period']\n",
    "                                + ff_last_seen_attributes)\n",
    "\n",
    "        gas.prepare_data_for_machine_learning()\n",
    "        gas.split_data_to_train_and_test(scaling_data=True)\n",
    "        gas.use_machine_learning_model_for_classification(model=None) #MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=1000, activation='relu', solver='adam', random_state=1))\n",
    "\n",
    "        gas.get_pred_results_df()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "# Visualization (not yet fully organized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcc.make_auto_annot()\n",
    "# gas.point_index_to_plot = gcc.auto_annot['starting_point_index'].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.traj_points = gas.traj_points_df.values\n",
    "gas.polar_plots_kwargs['traj_points_to_plot'] = gas.traj_points[gas.indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 3, 7, 8, 14]:\n",
    "    print(i)\n",
    "    current_plotly_polar_plot_kargs, all_ff_dict = plotly_utils_polar.prepare_to_make_one_plotly_polar_plot(i, gas.polar_plots_kwargs, gas.point_index_to_plot, gas.GUAT_joined_ff_info, gas.all_traj_feature_names, \n",
    "                                                                                                            more_ff_df=gas.more_ff_df, trajectory_features=gc_kwargs['trajectory_features'])\n",
    "\n",
    "    fig, customdata_columns = plotly_utils_polar.make_one_plotly_polar_plot(**current_plotly_polar_plot_kargs,\n",
    "                                                        symbol='group', color='time_since_last_vis', \n",
    "                                                        columns_for_annotation=['subgroup', 'curv_diff', 'time_till_next_visible', 'time_since_last_vis'],)\n",
    "                                                        #columns_for_annotation=['subgroup', 'ff_number', 'group', 'curv_diff'],)\n",
    "    print(all_ff_dict['more_monkey_info_for_ff_in_past_or_future'])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc, Input, Output, callback\n",
    "from dash.exceptions import PreventUpdate\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "reload(plotly_utils_polar)\n",
    "def use_dash(i, gas):\n",
    "    current_plotly_polar_plot_kargs, all_ff_dict = plotly_utils_polar.prepare_to_make_one_plotly_polar_plot(i, gas.polar_plots_kwargs, gas.point_index_to_plot, gas.GUAT_joined_ff_info, gas.all_traj_feature_names, \n",
    "                                                                                            more_ff_df=gas.more_ff_df, trajectory_features=gas.trajectory_features,)\n",
    "    fig, customdata_columns = plotly_utils_polar.make_one_plotly_polar_plot(**current_plotly_polar_plot_kargs, columns_for_annotation=['subgroup', 'curv_diff', 'time_since_last_vis', 'time_till_next_visible'], \n",
    "                                                                            additional_customdata_columns=['ff_number'], color='group')\n",
    "    initial_hover_data = current_plotly_polar_plot_kargs['ff_df'][customdata_columns].iloc[0].values\n",
    "    ff_number_index = np.where(np.array(customdata_columns) == 'ff_number')[0][0]\n",
    "\n",
    "    external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "    df = all_ff_dict['combined_ff_df'].copy()\n",
    "\n",
    "    app = Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "    app.layout = html.Div([\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Graph(\n",
    "                id='main_graph',\n",
    "                figure = fig,\n",
    "                hoverData={'points': [{'customdata': initial_hover_data}]} #['Original-Present', 0]}]}\n",
    "            )\n",
    "        ], style={'width': '50%', 'display': 'inline-block', 'padding': '0 0'}),\n",
    "        html.Div([\n",
    "            dcc.Graph(id='ff_history'),\n",
    "        ], style={'display': 'inline-block', 'width': '50%'}),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "    @callback(\n",
    "        Output('ff_history', 'figure'),\n",
    "        Input('main_graph', 'hoverData'))\n",
    "    def update_ff_history(hoverData):\n",
    "        print('hoverData:', hoverData)\n",
    "        print('hoverData[points][0]:', hoverData['points'][0])\n",
    "        current_ff_number = hoverData['points'][0]['customdata'][ff_number_index]\n",
    "        # if current_ff_number is not int\n",
    "        if not isinstance(current_ff_number, int):\n",
    "            raise PreventUpdate(\"No update was made because current_ff_number is not an integer.\")\n",
    "        else:\n",
    "            dff = df[df['ff_number'] == current_ff_number]\n",
    "            current_group = dff['group'].iloc[0]\n",
    "            symbol_maps_for_groups = {'Original': 'circle-dot', 'Alternative': 'star-dot', 'More': 'diamond-dot'}\n",
    "\n",
    "            title = '<b>{}</b>'.format(current_ff_number)\n",
    "            current_plotly_polar_plot_kargs_temp = current_plotly_polar_plot_kargs.copy()\n",
    "            current_plotly_polar_plot_kargs_temp['ff_df'] = dff.copy()\n",
    "            fig, customdata_columns = plotly_utils_polar.make_one_plotly_polar_plot(**current_plotly_polar_plot_kargs_temp,\n",
    "                                                                columns_for_annotation=['subgroup', 'ff_distance', 'ff_angle', 'curv_diff', 'time_since_last_vis', 'time_till_next_visible'],\n",
    "                                                                add_colorbar=True, add_legend=True, add_real_and_predicted_labels=False, size=None,\n",
    "                                                                size_max=15, symbol='time_label', symbol_map={'Present':symbol_maps_for_groups[current_group]})\n",
    "            return fig\n",
    "\n",
    "    app.run(debug=True)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dash(1, gas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dash(3, gas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dash(7, gas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## Other important distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### histplot of durations between stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the duration of the three stops\n",
    "diff_stop_time = GUAT_cluster_df['last_stop_time'] - GUAT_cluster_df['first_stop_time']\n",
    "sns.histplot(diff_stop_time, bins=20)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# make a line plot of 3 points on x-axis, with y-axis being time since first stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### histplot of time_till_next_visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## histplot of durations between stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(gcc.GUAT_cur_ff_info['time_till_next_visible'], bins=20, stat='probability')\n",
    "plt.title('time till next visible')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### curvature upper lower bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see clean_curvature_info function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['curv_of_traj', 'curvature_lower_bound', 'curvature_upper_bound', 'opt_arc_curv']:\n",
    "    sns.boxplot(gas.curvature_df[column].values, orient='h')\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "    \n",
    "   \n",
    "    sns.histplot(gas.curvature_df[column].values, bins=50)\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
