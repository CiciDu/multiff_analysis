{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if using google drive\n",
    "# %cd /content/drive/MyDrive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from data_wrangling import specific_utils, combine_info_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features, category_class\n",
    "from decision_making_analysis.ff_data_acquisition import cluster_replacement_utils\n",
    "from decision_making_analysis.data_compilation import miss_events_class, miss_events_across_sessions\n",
    "from decision_making_analysis.ff_data_acquisition import ff_data_utils\n",
    "from decision_making_analysis.ff_data_acquisition import get_missed_ff_data\n",
    "from decision_making_analysis.data_enrichment import miss_events_enricher\n",
    "\n",
    "from visualization.matplotlib_tools import plot_trials, plot_behaviors_utils\n",
    "from visualization.animation import animation_class\n",
    "from null_behaviors import show_null_trajectory, find_best_arc, curvature_utils, curv_of_traj_utils\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class\n",
    "from visualization.plotly_polar_tools import plotly_for_ff_polar, plotly_for_trajectory_polar\n",
    "from machine_learning.ml_methods import ml_methods_class\n",
    "from machine_learning.ml_methods.advanced_ml_methods import advanced_regression_utils, advanced_classification_utils, reg_feat_importance\n",
    "\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os, sys, sys\n",
    "from importlib import reload\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.max_rows = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Predict num stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict num_stops\n",
    "# combined_info_exists_ok = True\n",
    "# for monkey_name in ['monkey_Bruno', 'monkey_Schro']:\n",
    "#     gc_kwargs_temp = miss_events_enricher.gc_kwargs.copy()\n",
    "#     gc_kwargs_temp['num_old_ff_per_row'] = 2\n",
    "#     gc_kwargs_temp['num_new_ff_per_row'] = 3\n",
    "\n",
    "#     gas = miss_events_across_sessions.MissEventsAcrossSessions(gc_kwargs_temp, monkey_name=monkey_name)\n",
    "#     gas.retrieve_or_make_combined_info(combined_info_exists_ok=combined_info_exists_ok, \n",
    "#                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## data from all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_kwargs = miss_events_enricher.gc_kwargs.copy()\n",
    "\n",
    "gc_kwargs_temp = {**gc_kwargs,\n",
    "                    'num_old_ff_per_row': 2,\n",
    "                    'num_new_ff_per_row': 3}\n",
    "\n",
    "gas = miss_events_across_sessions.MissEventsAcrossSessions(gc_kwargs_temp, monkey_name='monkey_Bruno')\n",
    "gas.retrieve_or_make_combined_info(combined_info_exists_ok=True)\n",
    "gas.unpack_combined_info(gas.combined_info, gas.all_traj_feature_names)\n",
    "\n",
    "# shared part with 'data from one session'\n",
    "gas.process_current_and_alternative_ff_info()\n",
    "# more_ff_attributes = ['ff_distance', 'ff_angle', 'ff_angle_boundary', 'curv_diff']\n",
    "# ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "# ff_next_seen_attributes = ['next_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_next_seen', 'angle_from_monkey_now_to_monkey_when_ff_next_seen']\n",
    "more_ff_attributes = ['ff_distance', 'ff_angle', 'ff_angle_boundary']\n",
    "ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "gas.prepare_data_to_predict_num_stops(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "                          ff_attributes=['ff_distance', 'ff_angle', 'ff_angle_boundary', 'time_since_last_vis', 'duration_of_last_vis_period']\n",
    "                          + ff_last_seen_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## data from one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_kwargs = miss_events_enricher.gc_kwargs.copy()\n",
    "\n",
    "raw_data_folder_path = 'all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330'\n",
    "gcc = miss_events_class.MissEventsClass(raw_data_folder_path=raw_data_folder_path, \n",
    "                                                        gc_kwargs=gc_kwargs, new_point_index_start=0)\n",
    "_ = gcc.streamline_process_to_collect_info_from_one_session(miss_events_info_exists_ok=True)\n",
    "\n",
    "gas = miss_events_across_sessions.MissEventsAcrossSessions(gc_kwargs)\n",
    "gas.unpack_combined_info(gcc.important_info, gcc.all_traj_feature_names)\n",
    "\n",
    "# shared part with 'data from all sessions'\n",
    "gas.process_current_and_alternative_ff_info()\n",
    "more_ff_attributes = ['ff_distance', 'ff_angle', 'curv_diff']\n",
    "ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "# gas.prepare_data_to_predict_num_stops(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "#                           ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis', 'duration_of_last_vis_period']\n",
    "#                           + ff_last_seen_attributes)\n",
    "\n",
    "\n",
    "# additional features we can try: 'time_till_next_visible'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# predict num_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.miss_event_cur_ff_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.num_stops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.prepare_data_to_predict_num_stops(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "                          ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis', 'duration_of_last_vis_period']\n",
    "                          + ff_last_seen_attributes)\n",
    "\n",
    "gas.prepare_data_for_machine_learning(furnish_with_trajectory_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# predict rsw vs rcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.prepare_data_to_predict_rsw_vs_rcap(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "                          ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis', 'duration_of_last_vis_period']\n",
    "                          + ff_last_seen_attributes)\n",
    "\n",
    "gas.prepare_data_for_machine_learning(furnish_with_trajectory_data=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "tune = False\n",
    "\n",
    "cols_to_use = [col for col in gas.X_all_df.columns if ('last' in col) or ('mask' in col)]\n",
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gas.X_all_df[cols_to_use],\n",
    "                                     y_var_df=gas.y_var_df)\n",
    "\n",
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "model, y_pred, model_comparison_df = advanced_classification_utils.use_advanced_model_for_classification(\n",
    "    ml_inst.X_train, ml_inst.y_train, ml_inst.X_test, ml_inst.y_test,\n",
    "    kfold_cv=5,\n",
    "    tune=tune,                # turn tuning on/off\n",
    "    n_iter=30,                # ~3k samples sweet spot\n",
    "    tune_scoring=\"balanced_accuracy\",\n",
    "    checkpoint_dir=f\"all_monkey_data/decision_making/{gas.monkey_name}/pred_num_stops/cls_runs\",   # folder to save progress\n",
    "    resume=resume,              # skip finished models on rerun\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gas.X_all_df,\n",
    "                                     y_var_df=y_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_names=['linreg', 'grad_boosting', 'rf']\n",
    "model_names=None\n",
    "\n",
    "ml_inst.use_ml_model_for_regression(ml_inst.x_var_df, ml_inst.y_var_df, model_names=model_names)\n",
    "ml_inst.model_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## advanced regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "df, best = advanced_regression_utils.use_advanced_model_for_regression(\n",
    "    ml_inst.X_train, ml_inst.y_train, ml_inst.X_test, ml_inst.y_test,\n",
    "    use_cv=True, cv_splits=5, verbose=True,\n",
    "    save_dir=f\"all_monkey_data/decision_making/{gas.monkey_name}/pred_num_stops/cls_runs\",\n",
    "    resume=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, AdaBoostRegressor\n",
    "\n",
    "# Example: fit your models\n",
    "dt = DecisionTreeRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "gb = GradientBoostingRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "hgb = HistGradientBoostingRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "ada = AdaBoostRegressor(random_state=42).fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "# Collect in a dict\n",
    "models = {\n",
    "    \"Decision Tree\": dt,\n",
    "    \"Gradient Boosting\": gb,\n",
    "    \"HistGradientBoosting\": hgb,\n",
    "    \"AdaBoost\": ada,\n",
    "}\n",
    "\n",
    "# Get feature importances for each model\n",
    "for name, model in models.items():\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        feature_importance = pd.DataFrame({\n",
    "            \"feature\": ml_inst.x_var_df.columns,\n",
    "            \"importance\": importances\n",
    "        }).sort_values(by=\"importance\", ascending=False)\n",
    "        \n",
    "        print(f\"\\n{name} Feature Importances:\")\n",
    "        print(feature_importance.head(10))  # top 10\n",
    "    else:\n",
    "        print(f\"\\n{name} does not expose feature_importances_.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### in the future I can figure out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# models = {\n",
    "#     \"hist_gb\": fitted_hist_gradient_boosting_regressor_or_pipeline,\n",
    "#     \"dt\": fitted_decision_tree_regressor_or_pipeline,\n",
    "#     \"grad_boosting\": fitted_gradient_boosting_regressor_or_pipeline,\n",
    "#     \"boosting\": fitted_adaboost_or_xgboost_or_lightgbm_or_pipeline,\n",
    "# }\n",
    "\n",
    "# # For each model:\n",
    "# for name, mdl in models.items():\n",
    "#     try:\n",
    "#         df_imp = feature_importance_table(mdl, X_valid, y_valid)  # y_valid only needed if fallback\n",
    "#         print(f\"\\n{name} â€” top 10\")\n",
    "#         print(df_imp.head(10))\n",
    "#     except Exception as e:\n",
    "#         print(f\"{name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you forgot to do this first:\n",
    "gas.prepare_data_for_machine_learning(furnish_with_trajectory_data=False) \n",
    "y_var_df = pd.DataFrame(gas.num_stops, columns=['num_stops'])\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'].astype(int)\n",
    "\n",
    "\n",
    "# and for classification\n",
    "\n",
    "y_var_df.loc[y_var_df['num_stops'] > 2, 'num_stops'] = 2\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'].astype(int)\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'] - 1  # to avoid problem during classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gas.X_all_df,\n",
    "                                     y_var_df=y_var_df)\n",
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "ml_inst.use_ml_model_for_classification(ml_inst.x_var_df, ml_inst.y_var_df, model_names=model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## advanced classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you forgot to do this first:\n",
    "gas.prepare_data_for_machine_learning(furnish_with_trajectory_data=True) \n",
    "y_var_df = pd.DataFrame(gas.num_stops, columns=['num_stops'])\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'].astype(int)\n",
    "\n",
    "\n",
    "# and for classification\n",
    "\n",
    "y_var_df.loc[y_var_df['num_stops'] > 2, 'num_stops'] = 2\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'].astype(int)\n",
    "y_var_df['num_stops'] = y_var_df['num_stops'] - 1  # to avoid problem during classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "tune = False\n",
    "\n",
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gas.X_all_df,\n",
    "                                     y_var_df=y_var_df)\n",
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "model, y_pred, model_comparison_df = advanced_classification_utils.use_advanced_model_for_classification(\n",
    "    ml_inst.X_train, ml_inst.y_train, ml_inst.X_test, ml_inst.y_test,\n",
    "    kfold_cv=5,\n",
    "    tune=tune,                # turn tuning on/off\n",
    "    n_iter=30,                # ~3k samples sweet spot\n",
    "    tune_scoring=\"balanced_accuracy\",\n",
    "    checkpoint_dir=\"pred_num_stops/cls_runs\",   # folder to save progress\n",
    "    resume=resume,              # skip finished models on rerun\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best model by accuracy: catboost\n",
    "\n",
    "Chosen model accuracy: 0.7967741935483871\n",
    "\n",
    "Classification Report (encoded labels):\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.93      0.86       431\n",
    "           1       0.76      0.49      0.60       189\n",
    "\n",
    "    accuracy                           0.80       620\n",
    "   macro avg       0.78      0.71      0.73       620\n",
    "weighted avg       0.79      0.80      0.78       620\n",
    "\n",
    "\n",
    "Confusion Matrix (original class names):\n",
    "           Predicted 0  Predicted 1\n",
    "Actual 0          401           30\n",
    "Actual 1           96           93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# model's feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "statsmodels, logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Can't use it here because we are not predicting 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "\n",
    "# X2 = sm.add_constant(ml_inst.x_var_df)  # add intercept\n",
    "# logit_model = sm.Logit(ml_inst.y_var_df, X2)  # logistic regression\n",
    "# result = logit_model.fit()\n",
    "\n",
    "# print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": ml_inst.x_var_df.columns,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## grad_boosting (so that we can see feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.05, max_depth=7, max_features='sqrt',\n",
    "    min_samples_leaf=2, min_samples_split=7,\n",
    "    n_estimators=500, subsample=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': ml_inst.x_var_df.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 18))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df)\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "# Determine significant features (e.g., importance > 0.01)\n",
    "significant_features = feature_importances_df[feature_importances_df['Importance'] > 0.01]\n",
    "print(\"Significant features:\")\n",
    "print(significant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## sequential selection...? try it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "# model.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "# important = model.coef_[0] != 0\n",
    "# X_new = ml_inst.x_var_df.loc[:, important]\n",
    "# X_new.columns\n",
    "\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# sfs = SequentialFeatureSelector(model, n_features_to_select=10, direction=\"forward\")\n",
    "# X_new = sfs.fit_transform(ml_inst.x_var_df, ml_inst.y_var_df.values.ravel())\n",
    "\n",
    "\n",
    "# # Boolean mask of selected features\n",
    "# mask = sfs.get_support()\n",
    "\n",
    "# # Names of selected features\n",
    "# selected_features = ml_inst.x_var_df.columns[mask]\n",
    "\n",
    "# print(\"Selected features:\")\n",
    "# print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "# Compare distributions of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['ff_distance_ff_last_seen', \n",
    "            'time_since_ff_last_seen',\n",
    "            'ff_angle_ff_last_seen', \n",
    "            'ff_angle_boundary_ff_last_seen',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['ff_distance', 'ff_angle', 'ff_angle_boundary', 'time_since_last_vis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gas.X_all_df.copy()\n",
    "data['whether_rcap'] = gas.y_var_df['whether_rcap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each feature in significant_features, plot the histogram of the feature for each class\n",
    "for feature in ml_inst.x_var_df.columns:\n",
    "    sns.histplot(x=feature, data=data, stat='probability', kde=False, hue='whether_rcap', common_norm=False, bins=20)\n",
    "    plt.title(f'{feature} histogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "# Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.prepare_data_for_machine_learning(furnish_with_trajectory_data=False)\n",
    "gas.split_data_to_train_and_test(scaling_data=True)\n",
    "\n",
    "#bagging = BaggingClassifier(n_estimators=200, max_features=0.9, bootstrap_features=True, bootstrap=True, random_state=42)\n",
    "#gas.use_machine_learning_model_for_classification(model=bagging) \n",
    "\n",
    "gas.use_machine_learning_model_for_classification() #MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=1000, activation='relu', solver='adam', random_state=1))\n",
    "\n",
    "gas.get_pred_results_df()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proportion of cases where the number of stops is 1\n",
    "len(gas.num_stops[gas.num_stops==1])/len(gas.num_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(gas.num_stops)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "### loop through num_ff (as hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop\n",
    "for num_old_ff_per_row in [1, 2, 3]:\n",
    "    for num_new_ff_per_row in [1, 2, 3]:\n",
    "        print('num_old_ff_per_row:', num_old_ff_per_row)\n",
    "        print('num_new_ff_per_row:', num_new_ff_per_row)\n",
    "\n",
    "        gc_kwargs_temp = {**gc_kwargs,\n",
    "                            'num_old_ff_per_row': num_old_ff_per_row,\n",
    "                            'num_new_ff_per_row': num_new_ff_per_row}\n",
    "\n",
    "        gas = miss_events_across_sessions.MissEventsAcrossSessions(gc_kwargs_temp)\n",
    "        gas.retrieve_or_make_combined_info(combined_info_exists_ok=True)\n",
    "        gas.unpack_combined_info(gas.combined_info, gas.all_traj_feature_names)\n",
    "\n",
    "\n",
    "        gas.process_current_and_alternative_ff_info()\n",
    "        more_ff_attributes = ['ff_distance', 'ff_angle', 'curv_diff']\n",
    "        ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "        ff_next_seen_attributes = ['next_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_next_seen', 'angle_from_monkey_now_to_monkey_when_ff_next_seen']\n",
    "\n",
    "\n",
    "        gas.prepare_data_to_predict_num_stops(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "                                ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis', 'time_till_next_visible', 'duration_of_last_vis_period']\n",
    "                                + ff_last_seen_attributes)\n",
    "\n",
    "        gas.prepare_data_for_machine_learning()\n",
    "        gas.split_data_to_train_and_test(scaling_data=True)\n",
    "        gas.use_machine_learning_model_for_classification(model=None) #MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=1000, activation='relu', solver='adam', random_state=1))\n",
    "\n",
    "        gas.get_pred_results_df()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## Other important distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### histplot of durations between stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the duration of the three stops\n",
    "diff_stop_time = rsw_cluster_df['last_stop_time'] - rsw_cluster_df['stop_1_time']\n",
    "sns.histplot(diff_stop_time, bins=20)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# make a line plot of 3 points on x-axis, with y-axis being time since first stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "### histplot of time_till_next_visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## histplot of durations between stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(gcc.miss_event_cur_ff['time_till_next_visible'], bins=20, stat='probability')\n",
    "plt.title('time till next visible')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### curvature upper lower bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see clean_curvature_info function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['curv_of_traj', 'curvature_lower_bound', 'curvature_upper_bound', 'opt_arc_curv']:\n",
    "    sns.boxplot(gas.curvature_df[column].values, orient='h')\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "    \n",
    "   \n",
    "    sns.histplot(gas.curvature_df[column].values, bins=50)\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
