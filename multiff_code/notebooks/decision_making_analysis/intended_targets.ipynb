{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information, base_processing_class, retrieve_raw_data, further_processing_class\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_points, make_ff_dataframe, ff_dataframe_utils, pattern_by_trials, pattern_by_points, cluster_analysis, organize_patterns_and_features, category_class\n",
    "from decision_making_analysis.cluster_replacement import cluster_replacement_utils, plot_cluster_replacement\n",
    "from decision_making_analysis.decision_making import decision_making_utils, plot_decision_making, intended_targets_classes\n",
    "from decision_making_analysis.GUAT import GUAT_helper_class, GUAT_collect_info_class, GUAT_combine_info_class, process_GUAT_trials_class, GUAT_and_TAFT\n",
    "from decision_making_analysis import free_selection, replacement, trajectory_info\n",
    "from visualization.matplotlib_tools import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics, monkey_heading_utils\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class\n",
    "from machine_learning.RL.env_related import env_for_lstm, env_utils, base_env, collect_agent_data_utils\n",
    "from machine_learning.RL.lstm import GRU_functions, LSTM_functions\n",
    "from machine_learning.RL.SB3 import interpret_neural_network, sb3_for_multiff_class, rl_for_multiff_utils, SB3_functions\n",
    "from null_behaviors import show_null_trajectory, find_best_arc, curvature_utils\n",
    "from decision_making_analysis.decision_making import decision_making_class, decision_making_utils, intended_targets_classes\n",
    "import itertools\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, multilabel_confusion_matrix, fbeta_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from math import pi\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from importlib import reload\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.max_rows = 101\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Decision making\n",
    "\n",
    "There are two situations: \n",
    "\n",
    "Free selection:\tOne is when the monkey makes a decision among all possible ff (after catching the previous target)\n",
    "\n",
    "Replacement:\tThe other is when the monkey changes its mind (or decides not to change the current course) while pursuing another ff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Free selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(decision_making_class)\n",
    "reload(intended_targets_classes)\n",
    "\n",
    "dm = decision_making_class.DecisionMaking(raw_data_folder_path=raw_data_folder_path,\n",
    "                                            time_range_of_trajectory=[-2.5, 0], num_time_points_for_trajectory=5)\n",
    "# dm.retrieve_manual_anno()\n",
    "dm.get_monkey_data(already_retrieved_ok=True, include_ff_dataframe=True)\n",
    "dm.make_curvature_df()\n",
    "dm.make_auto_annot()\n",
    "dm.manual_anno = dm.auto_annot\n",
    "dm.manual_anno_long = dm.auto_annot_long\n",
    "\n",
    "dm.separate_manual_anno()\n",
    "dm.eliminate_crossing_boundary_cases(n_seconds_after_crossing_boundary = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.get_replacement_x_df()\n",
    "dm.get_free_selection_x()\n",
    "\n",
    "dm.prepare_data_for_machine_learning(kind=\"free selection\", furnish_with_trajectory_data=True, trajectory_data_kind=\"position\") \n",
    "dm.split_data_to_train_and_test(scaling_data=True)\n",
    "dm.use_machine_learning_model_for_classification(None)   \n",
    "dm.get_pred_results_df()  \n",
    "\n",
    "\n",
    "\n",
    "replacement_df = dm.replacement_df\n",
    "free_selection_df = dm.free_selection_df\n",
    "non_chosen_df = dm.non_chosen_df\n",
    "\n",
    "changing_pursued_ff_data = dm.changing_pursued_ff_data\n",
    "changing_pursued_ff_data_diff = dm.changing_pursued_ff_data_diff\n",
    "replacement_time = dm.replacement_time\n",
    "replacement_inputs = dm.replacement_inputs\n",
    "replacement_labels = dm.replacement_labels\n",
    "\n",
    "free_selection_x_df = dm.free_selection_x_df\n",
    "free_selection_labels = dm.free_selection_labels\n",
    "free_selection_time = dm.free_selection_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cases = None\n",
    "dm.prepare_to_plot_prediction_results()\n",
    "dm.plot_prediction_results(selected_cases, max_plot_to_make=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### moit\n",
    "Here, we tune parameters such as whether to pass in null arc info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of all the ff attributes combinations\n",
    "ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis']\n",
    "ff_attributes_combinations = []\n",
    "for i in range(1, len(ff_attributes)+1):\n",
    "    combo_w_i_elements = list(itertools.combinations(ff_attributes, i))\n",
    "    ff_attributes_combinations.extend([list(combo) for combo in combo_w_i_elements])\n",
    "    \n",
    "grid = {'ff_attributes': ff_attributes_combinations,\n",
    "        'trajectory_data_kind': ['position', 'velocity', None],\n",
    "        'add_arc_info': [True, False],\n",
    "        'add_current_curv_of_traj': [True, False],\n",
    "        'keep_whole_chunks' : [True, False],\n",
    "        'num_ff_per_row': [5, 6, 7],  # Note: here's an inherent limitation to this: data where the target is not within the n_ff_per_row ff are eliminated. So data can be biased.\n",
    "        'time_range_of_trajectory': [[-0.9, 0], [-0.9, 0.9]]\n",
    "        }\n",
    "\n",
    "# sample all the combinations from the grid\n",
    "keys, values = zip(*grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pattern_by_trials)\n",
    "reload(decision_making_class)\n",
    "reload(decision_making_utils)\n",
    "reload(show_null_trajectory)\n",
    "reload(intended_targets_classes)\n",
    "reload(regression_utils)\n",
    "\n",
    "combo = combinations[0]\n",
    "result_df = pd.DataFrame()\n",
    "for i in range(len(combinations)):\n",
    "    combo = combinations[i].copy()\n",
    "    print(i, 'out of', len(combinations))\n",
    "    print(combo)\n",
    "    combo['n_seconds_after_crossing_boundary'] = abs(combo['time_range_of_trajectory'][0])\n",
    "    combo['n_seconds_before_crossing_boundary'] = abs(combo['time_range_of_trajectory'][1])\n",
    "    # hide all printed material for below\n",
    "    with general_utils.HiddenPrints():\n",
    "        # hide all ConvergenceWarning\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "            model_comparison_df = regression_utils.test_moit_hyperparameters(ff_dataframe, ff_caught_T_new, ff_real_position_sorted, monkey_information, ff_flash_sorted, ff_life_sorted, auto_annot, auto_annot_long,\n",
    "                                curvature_df=curvature_df, select_every_nth_row=10, **combo)\n",
    "\n",
    "    combo_for_df = combo.copy()\n",
    "    combo_for_df['ff_attributes'] = [combo_for_df['ff_attributes']]\n",
    "    combo_for_df['time_range_of_trajectory'] = [combo_for_df['time_range_of_trajectory']]\n",
    "    # store the most accurate model\n",
    "    combo_for_df['best_model'] = model_comparison_df.iloc[0]['model']\n",
    "    # store the accuracy of the most accurate model\n",
    "    combo_for_df['best_model_accuracy'] = round(model_comparison_df.iloc[0]['accuracy'], 3)\n",
    "    # store the accuracies of all the other models\n",
    "    for index, row in model_comparison_df.iterrows():\n",
    "        combo_for_df[row['model']] = round(row['accuracy'], 3)\n",
    "    temp_result_df = pd.DataFrame(combo_for_df)\n",
    "    if i == 0:\n",
    "        result_df = temp_result_df\n",
    "    else:\n",
    "        result_df = pd.concat([result_df, temp_result_df], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### dm_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of all the ff attributes combinations\n",
    "ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis']\n",
    "ff_attributes_combinations = []\n",
    "for i in range(1, len(ff_attributes)+1):\n",
    "    combo_w_i_elements = list(itertools.combinations(ff_attributes, i))\n",
    "    ff_attributes_combinations.extend([list(combo) for combo in combo_w_i_elements])\n",
    "    \n",
    "grid = {'ff_attributes': ff_attributes_combinations,\n",
    "        'trajectory_data_kind': ['position', 'velocity', None],\n",
    "        'add_arc_info': [True, False],\n",
    "        'add_current_curv_of_traj': [True, False],\n",
    "        'time_range_of_trajectory': [[-0.9, 0], [-0.9, 0.9]],\n",
    "        'num_time_points_for_trajectory': [5, 10, 15],\n",
    "        'replacement_inputs_format': ['diff_between_old_and_new', 'old_plus_diff_between_old_and_new', 'both_old_and_new'],\n",
    "        }\n",
    "\n",
    "# sample all the combinations from the grid\n",
    "keys, values = zip(*grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(pattern_by_trials)\n",
    "reload(decision_making_class)\n",
    "reload(decision_making_utils)\n",
    "reload(show_null_trajectory)\n",
    "reload(intended_targets_classes)\n",
    "reload(regression_utils)\n",
    "\n",
    "combo = combinations[0]\n",
    "dm_result_df = pd.DataFrame()\n",
    "for i in range(len(combinations)):\n",
    "    combo = combinations[i].copy()\n",
    "    print(i, 'out of', len(combinations))\n",
    "    print(combo)\n",
    "    combo['n_seconds_after_crossing_boundary'] = abs(combo['time_range_of_trajectory'][0])\n",
    "    combo['n_seconds_before_crossing_boundary'] = abs(combo['time_range_of_trajectory'][1])\n",
    "    # hide all printed material for below\n",
    "    with general_utils.HiddenPrints():\n",
    "        # hide all ConvergenceWarning\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "            model_comparison_df = regression_utils.test_dm_replacement_hyperparameters(ff_dataframe, ff_caught_T_new, ff_real_position_sorted, monkey_information, auto_annot, curvature_df=curvature_df, **combo)\n",
    "\n",
    "    combo_for_df = combo.copy()\n",
    "    combo_for_df['ff_attributes'] = [combo_for_df['ff_attributes']]\n",
    "    combo_for_df['time_range_of_trajectory'] = [combo_for_df['time_range_of_trajectory']]\n",
    "    # store the most accurate model\n",
    "    combo_for_df['best_model'] = model_comparison_df.iloc[0]['model']\n",
    "    # store the accuracy of the most accurate model\n",
    "    combo_for_df['best_model_accuracy'] = round(model_comparison_df.iloc[0]['accuracy'], 3)\n",
    "    # store the accuracies of all the other models\n",
    "    for index, row in model_comparison_df.iterrows():\n",
    "        combo_for_df[row['model']] = round(row['accuracy'], 3)\n",
    "    temp_result_df = pd.DataFrame(combo_for_df)\n",
    "    if i == 0:\n",
    "        dm_result_df = temp_result_df\n",
    "    else:\n",
    "        dm_result_df = pd.concat([dm_result_df, temp_result_df], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def test_dm_replacement_hyperparameters(ff_dataframe, ff_caught_T_new, ff_real_position_sorted, monkey_information, auto_annot,\n",
    "#                               add_arc_info=True, add_current_curv_of_traj=True, furnish_with_trajectory_data=True, num_time_points_for_trajectory=20,\n",
    "#                               ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis'], trajectory_data_kind=['position'], curvature_df=None,\n",
    "#                               time_range_of_trajectory=[-0.8, 0.8], n_seconds_before_crossing_boundary=0.8, n_seconds_after_crossing_boundary=0.8,\n",
    "#                               replacement_inputs_format = 'diff_between_old_and_new'):\n",
    "\n",
    "#     dm = decision_making_class.DecisionMaking(raw_data_folder_path=raw_data_folder_path,\n",
    "#                                             time_range_of_trajectory=time_range_of_trajectory, num_time_points_for_trajectory=num_time_points_for_trajectory)\n",
    "#     dm.manual_anno = auto_annot\n",
    "#     dm.separate_manual_anno()\n",
    "#     dm.eliminate_crossing_boundary_cases(n_seconds_before_crossing_boundary=n_seconds_before_crossing_boundary, n_seconds_after_crossing_boundary=n_seconds_after_crossing_boundary) \n",
    "#     dm.get_replacement_x_df(add_arc_info=add_arc_info, add_current_curv_of_traj=add_current_curv_of_traj, curvature_df=curvature_df, ff_attributes=ff_attributes, replacement_inputs_format=replacement_inputs_format)\n",
    "#     dm.prepare_data_for_machine_learning(kind=\"replacement\", furnish_with_trajectory_data=furnish_with_trajectory_data, trajectory_data_kind=trajectory_data_kind) \n",
    "#     dm.split_data_to_train_and_test(scaling_data=True)\n",
    "#     dm.use_machine_learning_model_for_classification(model=None)  \n",
    "\n",
    "#     return dm.model_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Gaussian NB\n",
    "\n",
    "var_smooth: 1e-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = moit.X_train\n",
    "y_train = moit.y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(regression_utils)\n",
    "# reload(hyperparam_tuning_class)\n",
    "# gnb = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "# grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "# gnb.random_search(grid=grid, model=GaussianNB(), n_iter=50, n_folds=3, n_repeats=1)\n",
    "\n",
    "\n",
    "# grid = {'var_smoothing': np.logspace(-2,-9, num=100)}\n",
    "# gnb.grid_search(grid=grid, model=GaussianNB(), n_folds=3, n_repeats=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Adaptive boosting\n",
    "\n",
    "'n_estimators': 500,\n",
    "'learning_rate': 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(hyperparam_tuning_class)\n",
    "# adap_boosting = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "# grid = {'n_estimators': [10, 50, 100, 500],\n",
    "#         'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "# adap_boosting.random_search(grid=grid, model=AdaBoostClassifier(), n_iter=50, n_folds=3, n_repeats=1)\n",
    "\n",
    "\n",
    "adap_boosting = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "grid = {'n_estimators': [10, 50, 100, 200, 300, 500],\n",
    "        'learning_rate': [0.05, 0.1, 0.2, 0.4, 0.7, 1.0]}\n",
    "adap_boosting.grid_search(grid=grid, model=AdaBoostClassifier(), n_folds=3, n_repeats=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might also need to train on: max_features='sqrt', bootstrap=True, min_samples_split=7, min_samples_leaf=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(hyperparam_tuning_class)\n",
    "# gradient_boosting = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "# grid = {'n_estimators': [10, 50, 100, 200, 300, 400, 500], \n",
    "#         'learning_rate': [0.01, 0.05, 0.1], \n",
    "#         'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0], \n",
    "#         'max_depth': [3, 5, 7, 9] + [int(x) for x in np.linspace(20, 50, num = 4)]}\n",
    "# gradient_boosting.random_search(grid=grid, model=GradientBoostingClassifier(), n_iter=50, n_folds=3, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "grid = {'n_estimators': [10, 50, 100, 200, 300, 500], \n",
    "        'learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1], \n",
    "        'subsample': [0.5, 0.7, 1.0], \n",
    "        'max_depth': [3, 7, 9]}\n",
    "gradient_boosting.grid_search(grid=grid, model=GradientBoostingClassifier(), n_folds=3, n_repeats=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "n_estimators: 200\n",
    "max_features: 0.9\n",
    "bootstrap_features: True\n",
    "bootstrap: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(hyperparam_tuning_class)\n",
    "# bagging = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "# grid = {'n_estimators': [10, 20, 50, 100, 200, 300, 500, 800],\n",
    "#         'max_features': [0.90, 0.92, 0.95, 1.0],\n",
    "#         'bootstrap': [True, False],\n",
    "#         'bootstrap_features': [True, False]} \n",
    "# bagging.random_search(grid=grid, model=BaggingClassifier(), n_iter=50, n_folds=3, n_repeats=1)\n",
    "\n",
    "\n",
    "bagging = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "grid = {'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "        'max_features': [0.6, 0.65, 0.7, 0.75, 0.8, 0.85]}\n",
    "bagging.grid_search(grid=grid, model=BaggingClassifier(bootstrap=True, bootstrap_features=True), n_folds=3, n_repeats=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "bootstrap: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(hyperparam_tuning_class)\n",
    "# rf = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "# grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)],\n",
    "#         'max_features': [None, 'sqrt'],\n",
    "#         'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)] + [None],\n",
    "#         'min_samples_split': [2, 5, 10],\n",
    "#         'min_samples_leaf': [1, 2, 4],\n",
    "#         'bootstrap': [True, False]}\n",
    "\n",
    "# rf.random_search(grid=grid, model=RandomForestRegressor(), n_iter=50, n_folds=3, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 600, num = 5)],\n",
    "        'max_features': [None, 'sqrt'],\n",
    "        'max_depth': [80, 90, 100],\n",
    "        'min_samples_split': [2, 5, 7],\n",
    "        'min_samples_leaf': [1, 2, 3]}\n",
    "rf.grid_search(grid=grid, model=RandomForestRegressor(bootstrap=True), n_folds=3, n_repeats=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(hyperparam_tuning_class)\n",
    "lr = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "grid = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "        'penalty': ['l2'],\n",
    "        'C': [100, 10, 1.0, 0.1, 0.01]}\n",
    "\n",
    "lr.random_search(grid=grid, model=LogisticRegression(), n_iter=50, n_folds=3, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {'solvers': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "#         'penalty': ['l2'],\n",
    "#         'C': [100, 10, 1.0, 0.1, 0.01]}\n",
    "# lr.grid_search(grid=grid, model=LogisticRegression(), n_folds=3, n_repeats=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(hyperparam_tuning_class)\n",
    "lr = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "grid = {'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "        'C': [50, 10, 1.0, 0.1, 0.01],\n",
    "        'gamma': ['scale']}\n",
    "\n",
    "lr.random_search(grid=grid, model=SVC(), n_iter=50, n_folds=3, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "#         'C': [50, 10, 1.0, 0.1, 0.01],\n",
    "#         'gamma': ['scale']}\n",
    "# lr.grid_search(grid=grid, model=SVC(), n_folds=3, n_repeats=1)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(hyperparam_tuning_class)\n",
    "mlp = hyperparam_tuning_class.HyperparameterTuning(X_train=X_train, y_train=y_train)\n",
    "grid = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,), (50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'max_iter': [50, 100, 150],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp.random_search(grid=grid, model=MLPClassifier(), n_iter=50, n_folds=3, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     'hidden_layer_sizes': [(10,30,10),(20,), (50,50,50), (50,100,50), (100,)],\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'max_iter': [50, 100, 150],\n",
    "#     'solver': ['sgd', 'adam'],\n",
    "#     'alpha': [0.0001, 0.05],\n",
    "#     'learning_rate': ['constant','adaptive'],\n",
    "# }\n",
    "# mlp.grid_search(grid=grid, model=SVC(), n_folds=3, n_repeats=1)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
