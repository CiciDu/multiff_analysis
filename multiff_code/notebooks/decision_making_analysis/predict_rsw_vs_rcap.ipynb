{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_results.sort_values(by='num_caught_ff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_wrangling import specific_utils, combine_info_utils, general_utils, further_processing_class\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features, category_class\n",
    "from decision_making_analysis.ff_data_acquisition import cluster_replacement_utils\n",
    "from decision_making_analysis.data_compilation import miss_events_class\n",
    "from decision_making_analysis.ff_data_acquisition import ff_data_utils\n",
    "from decision_making_analysis.data_compilation import miss_events_across_sessions\n",
    "from decision_making_analysis.data_enrichment import miss_events_enricher\n",
    "\n",
    "from decision_making_analysis.data_compilation import miss_events_class\n",
    "from decision_making_analysis.data_compilation import miss_events_across_sessions\n",
    "from visualization.matplotlib_tools import plot_trials, plot_behaviors_utils\n",
    "from visualization.animation import animation_class\n",
    "from null_behaviors import show_null_trajectory, find_best_arc, curvature_utils, curv_of_traj_utils\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class\n",
    "from visualization.plotly_polar_tools import plotly_for_ff_polar, plotly_for_trajectory_polar\n",
    "from machine_learning.ml_methods import ml_methods_class\n",
    "from machine_learning.ml_methods.advanced_ml_methods import advanced_regression_utils, advanced_classification_utils, reg_feat_importance\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import os, sys, sys\n",
    "from importlib import reload\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict rcap vs rsw\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Schro']:\n",
    "    cgts = miss_events_across_sessions.MissEventsAcrossSessions()\n",
    "    combd_rsw_x_df, combd_rcap_x_df = cgts.streamline_getting_combd_rsw_or_rcap_x_df(monkey_name=monkey_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data across sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_name = 'monkey_Schro'\n",
    "cgts = miss_events_across_sessions.MissEventsAcrossSessions()\n",
    "cgts.streamline_getting_combd_decision_making_basic_ff_info(monkey_name=monkey_name, exists_ok=True)\n",
    "decision_making_basic_ff_info_cleaned = general_utils.drop_rows_with_any_na(cgts.combd_decision_making_basic_ff_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data for one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exists_ok = True\n",
    "cgt = miss_events_class.MissEventsClass(ref_point_mode='time', \n",
    "                                            raw_data_folder_path='all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330',\n",
    "                                            ref_point_value=-1.5,)\n",
    "cgt.make_decision_making_basic_ff_info()\n",
    "decision_making_basic_ff_info_cleaned = cgt.decision_making_basic_ff_info_cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## also cur & alt ff info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_kwargs = miss_events_enricher.gc_kwargs.copy()\n",
    "\n",
    "raw_data_folder_path = 'all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330'\n",
    "gcc = miss_events_class.MissEventsClass(raw_data_folder_path=raw_data_folder_path, \n",
    "                                                        gc_kwargs=gc_kwargs, new_point_index_start=0)\n",
    "_ = gcc.streamline_process_to_collect_info_from_one_session(miss_events_info_exists_ok=True)\n",
    "\n",
    "# shared part with 'data from all sessions'\n",
    "gcc.process_current_and_alternative_ff_info()\n",
    "more_ff_attributes = ['ff_distance', 'ff_angle', 'curv_diff']\n",
    "ff_last_seen_attributes = ['last_seen_' + attribute for attribute in more_ff_attributes] + ['distance_from_monkey_now_to_monkey_when_ff_last_seen', 'angle_from_monkey_now_to_monkey_when_ff_last_seen']\n",
    "\n",
    "\n",
    "gcc.prepare_data_to_predict_rsw_vs_rcap(add_arc_info=True, add_current_curv_of_traj=True, \n",
    "                                 use_alt_ff_only=True,       \n",
    "                          ff_attributes=['ff_distance', 'ff_angle', 'time_since_last_vis', 'duration_of_last_vis_period']\n",
    "                          + ff_last_seen_attributes)\n",
    "\n",
    "gcc.prepare_data_for_machine_learning(furnish_with_trajectory_data=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "tune = False\n",
    "\n",
    "cols_to_use = [col for col in gcc.X_all_df.columns if ('last' in col) or ('mask' in col)]\n",
    "ml_inst = ml_methods_class.MlMethods(x_var_df= gcc.X_all_df[cols_to_use],\n",
    "                                     y_var_df=gcc.y_var_df)\n",
    "\n",
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "model, y_pred, model_comparison_df = advanced_classification_utils.use_advanced_model_for_classification(\n",
    "    ml_inst.X_train, ml_inst.y_train, ml_inst.X_test, ml_inst.y_test,\n",
    "    kfold_cv=5,\n",
    "    tune=tune,                # turn tuning on/off\n",
    "    n_iter=30,                # ~3k samples sweet spot\n",
    "    tune_scoring=\"balanced_accuracy\",\n",
    "    checkpoint_dir=f\"all_monkey_data/decision_making/{gcc.monkey_name}/pred_num_stops/cls_runs\",   # folder to save progress\n",
    "    resume=resume,              # skip finished models on rerun\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcc.X_all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(gcc.miss_event_cur_ff['ff_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(gcc.X_all_df['ff_distance_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcc.miss_event_cur_ff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcc.miss_event_cur_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcc.miss_event_cur_ff.groupby('point_index').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# want: next capture\n",
    "\n",
    "but also just info of available ff up to the moment of stop....? especially since next ff might not be visible yet...\n",
    "\n",
    "i guess we can take out the trials where next ff was available at that point, and trials where it wasn't, to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to get 'nxt_captured_ff' info\n",
    "\n",
    "# cgt._get_rcap_df()\n",
    "# cgt._get_rsw_df()\n",
    "\n",
    "# cgt.new_rcap_df = cgt.rcap_df[cgt.rcap_df['ff_index'] < len(cgt.ff_caught_T_new) - 1].reset_index(drop=True)\n",
    "# cgt.new_rcap_df['nxt_captured_ff'] = cgt.new_rcap_df['ff_index'] + 1\n",
    "\n",
    "# cgt.new_rsw_df = cgt.rsw_df[cgt.rsw_df['ff_index'] < len(cgt.ff_caught_T_new) - 1].reset_index(drop=True)\n",
    "# cgt.new_rsw_df['nxt_captured_ff'] = np.searchsorted(cgt.ff_caught_T_new, cgt.new_rsw_df['stop_time'].values)\n",
    "# cgt.new_rsw_df['nxt_capture_time'] = cgt.ff_caught_T_new[cgt.new_rsw_df['nxt_captured_ff'].values]\n",
    "# cgt.new_rsw_df['prev_capture_time'] = cgt.ff_caught_T_new[cgt.new_rsw_df['nxt_captured_ff'].values - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgt.streamline_getting_rsw_or_rcap_x_df(rsw_or_rcap='rcap', exists_ok=exists_ok)\n",
    "cgt.streamline_getting_rsw_or_rcap_x_df(rsw_or_rcap='rsw', exists_ok=exists_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(cgt.rsw_x_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgt.rcap_x_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgt.rcap_events_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgt.rcap_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_making_basic_ff_info_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['ff_distance_ff_last_seen',\n",
    "            'ff_angle_ff_last_seen',\n",
    "            'ff_angle_boundary_ff_last_seen',\n",
    "            'time_since_ff_last_seen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attributes = ['ff_distance', 'ff_angle','ff_angle_boundary', 'time_since_last_vis']\n",
    "'''\n",
    "不能用ff_distance, 因为毕竟reference point是point on the trajectory closest to the stop. \n",
    "用distance to ff 的话, 很大程度上暴露了到底是不是rcap (虽说不是百分百暴露）\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regress on dwell time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var_df = decision_making_basic_ff_info_cleaned[attributes + ['whether_switched']]\n",
    "y_var_df = decision_making_basic_ff_info_cleaned[['stop_id_duration']].copy()\n",
    "\n",
    "\n",
    "ml_inst = ml_methods_class.MlMethods(x_var_df=x_var_df,\n",
    "                                     y_var_df=y_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or\n",
    "data_sub = decision_making_basic_ff_info_cleaned[decision_making_basic_ff_info_cleaned['whether_switched'] == 1].copy()\n",
    "x_var_df = data_sub[attributes]\n",
    "y_var_df = data_sub[['stop_id_duration']].copy()\n",
    "\n",
    "ml_inst = ml_methods_class.MlMethods(x_var_df=x_var_df,\n",
    "                                     y_var_df=y_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_ml_model_for_regression(ml_inst.x_var_df, ml_inst.y_var_df, model_names=['linreg', 'svr', 'dt', 'bagging', 'boosting', 'grad_boosting', 'rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_making_basic_ff_info_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classify type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var_df = decision_making_basic_ff_info_cleaned[attributes]\n",
    "y_var_df = decision_making_basic_ff_info_cleaned[['whether_switched']].copy()\n",
    "\n",
    "ml_inst = ml_methods_class.MlMethods(x_var_df=x_var_df,\n",
    "                                     y_var_df=y_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_ml_model_for_classification(ml_inst.x_var_df, ml_inst.y_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X2 = sm.add_constant(ml_inst.x_var_df)  # add intercept\n",
    "logit_model = sm.Logit(ml_inst.y_var_df, X2)  # logistic regression\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model's feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "important = model.coef_[0] != 0\n",
    "X_new = ml_inst.x_var_df.loc[:, important]\n",
    "X_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hmmm I don't think this is needed at the moment\n",
    "\n",
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# sfs = SequentialFeatureSelector(model, n_features_to_select=min(10, len(ml_inst.x_var_df.columns)-1), direction=\"forward\")\n",
    "# X_new = sfs.fit_transform(ml_inst.x_var_df, ml_inst.y_var_df.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Boolean mask of selected features\n",
    "# mask = sfs.get_support()\n",
    "\n",
    "# # Names of selected features\n",
    "# selected_features = ml_inst.x_var_df.columns[mask]\n",
    "\n",
    "# print(\"Selected features:\")\n",
    "# print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statsmodels, logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X2 = sm.add_constant(ml_inst.x_var_df)  # add intercept\n",
    "logit_model = sm.Logit(ml_inst.y_var_df, X2)  # logistic regression\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": ml_inst.x_var_df.columns,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grad_boosting (so that we can see feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.05, max_depth=7, max_features='sqrt',\n",
    "    min_samples_leaf=2, min_samples_split=7,\n",
    "    n_estimators=500, subsample=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': ml_inst.x_var_df.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 18))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df)\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "# Determine significant features (e.g., importance > 0.01)\n",
    "significant_features = feature_importances_df[feature_importances_df['Importance'] > 0.01]\n",
    "print(\"Significant features:\")\n",
    "print(significant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = False\n",
    "\n",
    "ml_inst.use_train_test_split(ml_inst.x_var_df, ml_inst.y_var_df)\n",
    "model, y_pred, model_comparison_df = advanced_classification_utils.use_advanced_model_for_classification(\n",
    "    ml_inst.X_train, ml_inst.y_train, ml_inst.X_test, ml_inst.y_test,\n",
    "    kfold_cv=5,\n",
    "    tune=tune,                # turn tuning on/off\n",
    "    n_iter=30,                # ~3k samples sweet spot\n",
    "    tune_scoring=\"balanced_accuracy\",\n",
    "    checkpoint_dir=f\"all_monkey_data/decision_making/{cgts.monkey_name}/pred_num_stops/cls_runs\",   # folder to save progress\n",
    "    resume=False,              # skip finished models on rerun\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btw, what's the reference point ??? (like at which point are we predicting rcap vs rsw?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # what might be interesting to add from rcap_x_df:\n",
    " \n",
    " 'angle_from_stop_to_nxt_ff',\n",
    " 'angle_from_cur_ff_to_nxt_ff',\n",
    " \n",
    " \n",
    " # monkey's own curvature info?\n",
    " # so like find curv of traj based on [-25, 0] or something,\n",
    " \n",
    " \n",
    " # rather than ff last seen, what about at ref?\n",
    " # (btw, I'm not gonna use exactly the below...will tweak it)\n",
    " 'cur_ff_angle_diff_boundary_at_ref',\n",
    " 'cur_ff_flash_duration_at_ref',\n",
    " 'cur_ff_earliest_flash_rel_time_at_ref',\n",
    " 'cur_ff_latest_flash_rel_time_at_ref',\n",
    " \n",
    " \n",
    " # and also all the eye-related features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare distributions of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['ff_distance_ff_last_seen', \n",
    "            'time_since_ff_last_seen',\n",
    "            'ff_angle_ff_last_seen', \n",
    "            'ff_angle_boundary_ff_last_seen',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['ff_distance', 'ff_angle', 'ff_angle_boundary', 'time_since_last_vis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each feature in significant_features, plot the histogram of the feature for each class\n",
    "for feature in attributes:\n",
    "    sns.histplot(x=feature, data=decision_making_basic_ff_info_cleaned, stat='probability', kde=False, hue='whether_switched', common_norm=False)\n",
    "    plt.title(f'{feature} histogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complex features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcap = cgt.rcap_x_df.copy()\n",
    "rcap['whether_rcap'] = 1\n",
    "rsw = cgt.rsw_x_df.copy()\n",
    "rsw['whether_rcap'] = 0\n",
    "both_df = pd.concat([rcap, rsw], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each feature in significant_features, plot the histogram of the feature for each class\n",
    "for feature in ['cur_ff_distance_at_ref', 'cur_ff_angle_at_ref']:\n",
    "    sns.histplot(x=feature, data=both_df, stat='probability', kde=False, hue='whether_rcap', common_norm=False)\n",
    "    plt.title(f'{feature} histogram')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each feature in significant_features, plot the histogram of the feature for each class\n",
    "max_features_to_plot = 3\n",
    "count = 0\n",
    "for feature in significant_features['Feature']:\n",
    "    sns.histplot(x=feature, data=both_df, stat='probability', kde=False, hue='whether_rcap', common_norm=False)\n",
    "    plt.title(f'{feature} histogram')\n",
    "    plt.show()\n",
    "    count += 1\n",
    "    if count >= max_features_to_plot:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # can skip this if only wanting ML results\n",
    "# pd.set_option('display.max_rows', 100)\n",
    "# ml_inst.use_vif(ml_inst.x_var_df)\n",
    "# features_w_big_vif = ml_inst.vif_df[ml_inst.vif_df['vif'] > 100].feature.values\n",
    "# #ml_inst.x_var_df = ml_inst.x_var_df.drop(columns=features_w_big_vif)\n",
    "# ml_inst.vif_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_columns = ml_inst.vif_df[ml_inst.vif_df[\"VIF\"] > 2000].feature.values\n",
    "# ml_inst.show_correlation_heatmap(specific_columns=specific_columns)\n",
    "# ml_inst.show_correlation_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test and see what is taking so long in running a function\n",
    "# import cProfile\n",
    "\n",
    "# cProfile.run(\"cgt.streamline_getting_rsw_or_rcap_x_df(rsw_or_rcap='rsw', exists_ok=False)\", sort='cumtime')\n",
    "\n",
    "# #ncalls  tottime  percall  cumtime  percall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
