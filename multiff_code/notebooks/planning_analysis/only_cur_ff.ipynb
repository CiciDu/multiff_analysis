{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This analysis is to see the effect of cluster on the pursuit of the current target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information, base_processing_class, combine_info_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_points, make_ff_dataframe, ff_dataframe_utils, pattern_by_trials, pattern_by_points, cluster_analysis, organize_patterns_and_features, category_class, cluster_analysis\n",
    "from decision_making_analysis.decision_making import decision_making_class, decision_making_utils, plot_decision_making, intended_targets_classes\n",
    "from decision_making_analysis.GUAT import GUAT_helper_class, GUAT_collect_info_class, GUAT_combine_info_class, add_features_GUAT_and_TAFT\n",
    "from decision_making_analysis import free_selection, replacement, trajectory_info\n",
    "from null_behaviors import show_null_trajectory, find_best_arc, curvature_utils, curv_of_traj_utils\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class\n",
    "from reinforcement_learning.base_classes import env_utils, base_env, more_envs, rl_base_class, rl_base_utils\n",
    "from reinforcement_learning.agents.rnn import gru_utils, lstm_utils\n",
    "from reinforcement_learning.agents.feedforward import interpret_neural_network, sb3_class, sb3_utils\n",
    "from visualization.matplotlib_tools import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics, monkey_heading_utils\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from planning_analysis.test_params_for_planning import params_test_combos_class, params_utils\n",
    "from visualization.plotly_tools import plotly_for_monkey, plotly_for_time_series, plotly_preparation, plotly_for_correlation\n",
    "from visualization.dash_tools import dash_prep_class, dash_utils, dash_utils, dash_comparison_class, dash_params_class\n",
    "from visualization.dash_tools.dash_main_class_methods import dash_main_class\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils\n",
    "from planning_analysis.show_planning import nxt_ff_utils, show_planning_class, show_planning_utils\n",
    "from planning_analysis import ml_for_planning_class, ml_for_planning_utils\n",
    "from planning_analysis.show_planning.cur_vs_nxt_ff import cvn_helper_class, find_cvn_utils, plot_cvn_class, plot_cvn_utils, plot_monkey_heading_helper_class, cvn_from_ref_class\n",
    "from planning_analysis.only_cur_ff import only_cur_ff_utils, only_cur_ff_class, only_cur_ff_utils, only_cur_ff_x_sess_class\n",
    "from planning_analysis.plan_factors import plan_factors_utils, build_factor_comp, plan_factors_class, monkey_plan_factors_x_sess_class\n",
    "from machine_learning.ml_methods import ml_methods_class, prep_ml_data_utils\n",
    "from planning_analysis.plan_factors import monkey_plan_factors_x_sess_class, test_vs_control_utils, monkey_plan_factors_x_sess_class\n",
    "from planning_analysis.only_cur_ff import features_to_keep_utils\n",
    "from eye_position_analysis import eye_positions\n",
    "\n",
    "from importlib import reload\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, RandomForestRegressor\n",
    "from matplotlib import cm\n",
    "from os.path import exists\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "from scipy.stats import rankdata\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, multilabel_confusion_matrix, fbeta_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import pi\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import warnings\n",
    "import os, sys, sys\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import plotly.graph_objects as go\n",
    "import gc\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.max_rows = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item = None\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run before sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_only_cur_lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osfxs =only_cur_ff_x_sess_class.OnlyStopFFAcrossSessions(monkey_name='monkey_Bruno')\n",
    "all_only_cur_lr_df = osfxs.make_or_retrieve_all_only_cur_lr_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_only_cur_ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osfxs =only_cur_ff_x_sess_class.OnlyStopFFAcrossSessions(monkey_name='monkey_Bruno')\n",
    "all_only_cur_ml_df = osfxs.make_or_retrieve_all_only_cur_ml_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnlyStopFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make df for one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = 'all_monkey_data/raw_monkey_data/monkey_Bruno/data_0326'\n",
    "osf = only_cur_ff_class.OnlyStopFF(raw_data_folder_path=raw_data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.make_only_cur_ff_df(exists_ok=True, ref_point_mode='distance', ref_point_value=-150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.make_x_features_df(exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point_mode = 'time after cur ff visible'\n",
    "ref_point_value = 0.1\n",
    "\n",
    "osfxs =only_cur_ff_x_sess_class.OnlyStopFFAcrossSessions(monkey_name='monkey_Bruno')\n",
    "osfxs.make_only_cur_ff_df_and_x_features_df_across_sessions(exists_ok=True, x_features_df_exists_ok=True, only_cur_ff_df_exists_ok=True,\n",
    "                                                           ref_point_mode=ref_point_mode, ref_point_value=ref_point_value)\n",
    "\n",
    "osfxs.prepare_only_cur_ff_data_for_ml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.only_cur_ff_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression: Use loop on y column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst = ml_methods_class.MlMethods()\n",
    "\n",
    "for y_var_column in ['curv_of_traj_before_stop',\n",
    "                    'd_heading_of_traj',\n",
    "                    'cur_opt_arc_d_heading',\n",
    "                    'diff_in_d_heading_to_cur_ff',\n",
    "                    'dir_from_cur_ff_to_stop' # this one is classification though\n",
    "                    ]:\n",
    "    print('y_var_column:', y_var_column)\n",
    "    osf.streamline_preparing_for_ml(y_var_column,\n",
    "                                     ref_columns_only=False)\n",
    "    ml_inst.use_train_test_split(osf.x_var_df, osf.y_var_df, y_var_column=y_var_column)\n",
    "    ml_inst.use_linear_regression(show_plot=True)\n",
    "    # show important features\n",
    "    print(ml_inst.summary_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.x_var_df, osf.y_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.x_var_df = osf.x_var_df\n",
    "ml_inst.y_var_df = osf.y_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "ml_inst.use_vif(ml_inst.x_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.vif_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_column = 'dir_from_cur_ff_to_stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.streamline_preparing_for_ml(y_var_column, \n",
    "                                ref_columns_only=False,\n",
    "                                cluster_to_keep='all',\n",
    "                                cluster_for_interaction='none',\n",
    "                                add_ref_interaction=True,\n",
    "                                winsorize_angle_features=True,\n",
    "                                using_lasso=False, \n",
    "                                ensure_cur_ff_at_front=True,\n",
    "                                use_pca=False,\n",
    "                                use_combd_features_for_cluster_only=False,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst = ml_methods_class.MlMethods()\n",
    "#ml_inst.use_train_test_split(osf.x_var_df, osf.y_var_df, y_var_column=y_var_column)\n",
    "ml_inst.use_logistic_regression(osf.x_var_df, osf.y_var_df)\n",
    "\n",
    "pd.options.display.max_rows = 101\n",
    "ml_inst.summary_df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns_of_interest = [\n",
    "                        'd_heading_of_traj',\n",
    "                        'diff_in_d_heading_to_cur_ff',\n",
    "                        'curv_of_traj_before_stop',\n",
    "                        'dir_from_cur_ff_to_stop' # this one is classification though\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_columns = [column for column in osf.x_features_df if 'ref' in column]\n",
    "ref_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_canon_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_columns_only = False\n",
    "\n",
    "for y_var in y_columns_of_interest:\n",
    "    # Define data\n",
    "    if ref_columns_only:\n",
    "        X1 = osf.x_features_df[ref_columns].copy()\n",
    "    else:\n",
    "        X1 = osf.x_features_df.copy()\n",
    "    #X2 = osf.only_cur_ff_df[[y_var]].copy()\n",
    "    X2 = osf.only_cur_ff_df[y_columns_of_interest].copy()\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    for column in ['data_name', 'stop_point_index']:\n",
    "        if column in X1.columns:\n",
    "            X1.drop(columns=[column], inplace=True)\n",
    "\n",
    "    print('Y var:', y_var)\n",
    "    avg_x_loadings, avg_y_loadings, avg_canon_corrs = cca_utils.run_cca(X1, X2, n_comp=5, n_splits=5, show_plots=True)\n",
    "\n",
    "\n",
    "    ml_inst.utils.plot_correlation_coefficients(avg_canon_corrs, len(avg_canon_corrs))\n",
    "    cca_plotting.plot_x_loadings(avg_x_loadings, avg_canon_corrs, X1)\n",
    "    cca_plotting.plot_y_loadings(avg_y_loadings, avg_canon_corrs, X2)\n",
    "       \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_plotting.plot_y_loadings(avg_y_loadings, avg_canon_corrs, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    cca_plotting.plot_correlation_coefficients(avg_canon_corrs)\n",
    "    cca_plotting.plot_x_loadings(avg_x_loadings, avg_canon_corrs, X1)\n",
    "    cca_plotting.plot_y_loadings(avg_y_loadings, avg_canon_corrs, X2)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for y_var_column in ['curv_of_traj_before_stop',\n",
    "                    'd_heading_of_traj',\n",
    "                    'cur_opt_arc_d_heading',\n",
    "                    'diff_in_d_heading_to_cur_ff',\n",
    "                    'dir_from_cur_ff_to_stop' # this one is classification though\n",
    "                    ]:\n",
    "    \n",
    "    osf.streamline_preparing_for_ml(y_var_column,\n",
    "                                     ref_columns_only=False, use_pca=True)\n",
    "    ml_inst.use_train_test_split(osf.x_var_df, osf.y_var_df, y_var_column=y_var_column)\n",
    "    ml_inst.use_linear_regression(show_plot=True)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.original_x_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of loadings\n",
    "loadings = osf.pca.components_\n",
    "feature_names = osf.original_x_df.columns\n",
    "column_names = [f'x{i}' for i in range(loadings.shape[0])]\n",
    "pca_loadings_df = pd.DataFrame(loadings.T, columns=column_names, index=feature_names)\n",
    "\n",
    "sorted_summary_df = ml_inst.summary_df[ml_inst.summary_df['p_value'] <= 0.05].sort_values(by='Coefficient', ascending=False).copy()\n",
    "for i in range(10):\n",
    "    print('i:', i)\n",
    "    sorted_result_row = sorted_summary_df.iloc[i]\n",
    "    pca_x = sorted_result_row.name\n",
    "    if pca_x == 'const':\n",
    "        continue\n",
    "    #column = pca_loadings_df.columns[i]\n",
    "    print('pca_x:', pca_x)\n",
    "    print('sorted_result_row:', sorted_result_row)\n",
    "    print(pca_loadings_df[pca_x].sort_values(ascending=False).head(50))\n",
    "    #print(df_loadings[column].sort_values(ascending=False).tail(5))\n",
    "sorted_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_loadings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeff = X2.corr()\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(corr_coeff, cmap='coolwarm', annot=True, linewidths=1, vmin=-1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other ml models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_column = 'curv_of_traj_before_stop'\n",
    "#y_var_column = 'diff_in_d_heading_to_cur_ff'\n",
    "ref_point_mode = 'time after cur ff visible'\n",
    "ref_point_value = 0.1\n",
    "\n",
    "osf.streamline_preparing_for_ml(y_var_column,\n",
    "                                ref_columns_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_ml_model_for_regression(osf.x_var_df, osf.y_var_df, y_var_column=y_var_column, model_names=['linreg', 'grad_boosting', 'rf'])\n",
    "ml_inst.model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rf feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Example dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Assuming you have the feature names in a list called feature_names\n",
    "feature_names = [f'Feature {i}' for i in range(X.shape[1])]\n",
    "\n",
    "# Combine feature names and their importances\n",
    "features_and_importances = zip(feature_names, feature_importances)\n",
    "\n",
    "# Sort the features by importance\n",
    "sorted_features_and_importances = sorted(features_and_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the sorted significant features and their importances\n",
    "for feature, importance in sorted_features_and_importances:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(regression_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### within clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = 'cur_ff_cluster_100'\n",
    " #'start_ang_cluster_20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in ['ff_distance', 'ff_angle', '_ff_angle', 'ff_angle_boundary', 'flash_duration', 'earliest_flash_rel_time', 'latest_flash_rel_time']:\n",
    "        specific_columns = [column for column in osf.x_features_df.columns if (cluster_name in column) & (category in column)]\n",
    "        if category == '_ff_angle':\n",
    "            specific_columns = [column for column in specific_columns if ('ff_angle_boundary' not in column)]\n",
    "        if len(specific_columns) > 1:\n",
    "            print(specific_columns)\n",
    "            ml_inst.show_correlation_heatmap(specific_columns=specific_columns)\n",
    "        else:\n",
    "            print('oops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in ['ff_distance', 'ff_angle', '_ff_angle', 'ff_angle_boundary', 'flash_duration', 'earliest_flash_rel_time', 'latest_flash_rel_time']:\n",
    "    for radius in [50, 100, 150, 200, 250, 300]:\n",
    "        specific_columns = [column for column in osf.x_features_df.columns if (f'cur_ff_cluster_{radius}' in column) & (category in column)]\n",
    "        if category == '_ff_angle':\n",
    "            specific_columns = [column for column in specific_columns if ('ff_angle_boundary' not in column)]\n",
    "        if len(specific_columns) > 1:\n",
    "            print(specific_columns)\n",
    "            ml_inst.show_correlation_heatmap(specific_columns=specific_columns)\n",
    "        else:\n",
    "            print('oops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i need (for 50):\n",
    "median (or mean) ff distance\n",
    "median (or mean) ff angle boundary\n",
    "EARLIEST_FLASH rel time, ff angle (or boundary)\n",
    "LATEST_FLASH rel time, ff angle\n",
    "LONGEST_FLASH, ff angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_vif(ml_inst.x_var_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### across 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = 'all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328'\n",
    "osf2 = only_cur_ff_class.OnlyStopFF(raw_data_folder_path=raw_data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf2.make_only_cur_ff_df()\n",
    "osf2.make_x_features_df(exists_ok=False)\n",
    "all_cluster_names = osf2.all_cluster_names\n",
    "feature = 'ff_angle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_1 = 'cur_ff_cluster_75'\n",
    "# cluster_2 = 'cur_ff_cluster_100'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_features_to_keep = features_to_keep_utils.get_minimal_features_to_keep(osf.x_features_df)\n",
    "osf.x_features_df = osf.x_features_df[minimal_features_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = 'cur_ff_cluster_100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combn_columns_in_cluster = [column for column in osf.x_features_df.columns if (cluster_name in column) & ('combd' in column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combn_columns_in_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_columns_1 = [column for column in osf.x_features_df.columns if (feature in column) & (cluster_1 in column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_cluster_names)):\n",
    "    #j = i+1\n",
    "    for j in range(i + 1, len(all_cluster_names)):\n",
    "        cluster_1 = all_cluster_names[i]\n",
    "        cluster_2 = all_cluster_names[j]\n",
    "        rel_columns_1 = [column for column in osf.x_features_df.columns if (feature in column) & (cluster_1 in column)]\n",
    "        rel_columns_2 = [column for column in osf.x_features_df.columns if (feature in column) & (cluster_2 in column)]\n",
    "        if (len(rel_columns_1) > 0) & (len(rel_columns_2) > 0):\n",
    "            rel_columns_1.sort()\n",
    "            rel_columns_2.sort()\n",
    "            rel_columns = rel_columns_1 + rel_columns_2\n",
    "            #ml_inst.show_correlation_heatmap(specific_columns=rel_columns)\n",
    "\n",
    "            #corr_coeff = osf.x_features_df[rel_columns_1].corrwith(osf.x_features_df[rel_columns_2])\n",
    "            corr_coeff = osf.x_features_df[rel_columns].corr()\n",
    "            #corr_coeff = corr_coeff.iloc[:len(rel_columns_1), len(rel_columns_1):]\n",
    "\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            sns.heatmap(corr_coeff, cmap='coolwarm', annot=True, linewidths=1, vmin=-1)\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.all_cluster_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### across clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ff_info = osf.ff_info_at_start_df.iloc[[100]]\n",
    "types_of_ff_to_include=['leftmost', 'rightmost', 'earliest_flash', 'latest_flash', 'longest_flash']\n",
    "columns_to_include=['ff_distance', 'ff_angle', 'angle_diff_boundary', 'earliest_flash_rel_time', 'latest_flash_rel_time', 'flash_duration']\n",
    "agg_columns_to_include=['combd_min_ff_angle', 'combd_max_ff_angle', 'combd_median_ff_angle', \n",
    "                        'combd_min_angle_diff_boundary', 'combd_max_angle_diff_boundary', 'combd_median_angle_diff_boundary', \n",
    "                        'combd_min_ff_distance', 'combd_max_ff_distance', 'combd_median_ff_distance', \n",
    "                        'combd_total_flash_duration', 'combd_longest_flash_duration', \n",
    "                        'combd_earliest_flash_rel_time', 'combd_latest_flash_rel_time',\n",
    "                        'num_ff_in_cluster'\n",
    "                        ]                    \n",
    "\n",
    "cluster_factors_df = only_cur_ff_utils._get_cluster_factors_df(cluster_ff_info, '', columns_to_include=columns_to_include,\n",
    "                                    types_of_ff_to_include=types_of_ff_to_include)\n",
    "cluster_factors_df_melted = cluster_factors_df.melt(id_vars=['group', 'ff'], var_name='feature', value_name='value')\n",
    "# add the column factor_name, which a concatenation of ff_name and factor\n",
    "cluster_factors_df_melted['ff_and_feature'] = cluster_factors_df_melted['ff'] + '_' + cluster_factors_df_melted['feature']                 \n",
    "\n",
    "factors = cluster_factors_df_melted['ff_and_feature'].values.tolist()\n",
    "factors.extend(agg_columns_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in factors:\n",
    "    specific_columns = [column for column in osf.x_features_df.columns if (feature in column)]\n",
    "    if len(specific_columns) > 1:\n",
    "        print('Feature:', feature)\n",
    "        print(specific_columns)\n",
    "        ml_inst.show_correlation_heatmap(specific_columns=specific_columns)\n",
    "    else:\n",
    "        print('oops')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histplot of x features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.x_features_df.columns[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_angle_columns = [column for column in osf.x_features_df.columns if ('ff_angle' in column) & \n",
    "                    ('rank' not in column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_features = random.sample(list(ff_angle_columns), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_point_mode = 'time after cur ff visible'\n",
    "ref_point_value = 0.1\n",
    "\n",
    "# ref_point_mode = 'distance'\n",
    "# ref_point_value = -190\n",
    "osfxs =only_cur_ff_x_sess_class.OnlyStopFFAcrossSessions(monkey_name='monkey_Bruno')\n",
    "osfxs.make_only_cur_ff_df_and_x_features_df_across_sessions(exists_ok=True, x_features_df_exists_ok=False, only_cur_ff_df_exists_ok=True,\n",
    "                                                           ref_point_mode=ref_point_mode, ref_point_value=ref_point_value)\n",
    "\n",
    "osfxs.prepare_only_cur_ff_data_for_ml()\n",
    "# osf.only_cur_ff_df = osf.combd_only_cur_ff_df.copy()\n",
    "# osf.x_features_df = osf.combd_x_features_df.copy()\n",
    "# osf.x_features_df_w_all_columns = osf.combd_x_features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in sampled_features:\n",
    "    sns.histplot(osfxs.x_features_df[feature])\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histplot of y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_var_column in y_columns_of_interest:\n",
    "    sns.histplot(osf.only_cur_ff_df[y_var_column])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_features_to_keep = features_to_keep_utils.get_minimal_features_to_keep(osf.x_features_df)\n",
    "osf.x_features_df = osf.x_features_df_w_all_columns[minimal_features_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonable_features_to_keep = features_to_keep_utils.get_reasonable_features_to_keep(osf.x_features_df)\n",
    "osf.x_features_df = osf.x_features_df_w_all_columns[reasonable_features_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = features_to_keep_utils.get_features_to_keep_based_on_specific_selections()\n",
    "features_to_keep_all = []\n",
    "for radius in features_to_keep.keys():\n",
    "    features_to_keep_all += features_to_keep[radius]\n",
    "osf.x_features_df = osf.x_features_df_w_all_columns[features_to_keep_all].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, using the original:\n",
    "osf.x_features_df = osf.x_features_df_w_all_columns.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selections: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.make_x_and_y_var_df(use_pca=True)\n",
    "\n",
    "y_var = osf.y_var_df[y_var_column].copy()\n",
    "x_var_df = osf.x_var_df.copy()\n",
    "x_var_df, y_var = show_planning_utils.remove_outliers(x_var_df, y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LASSO for variable selection\n",
    "lasso = LassoCV(cv=5).fit(x_var_df, y_var)\n",
    "\n",
    "# Selected variables (non-zero coefficients)\n",
    "selected_features = x_var_df.columns[(lasso.coef_ != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unselected_features = ml_inst.x_var_df.columns[(lasso.coef_ == 0)]\n",
    "unselected_features[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_inst.use_train_test_split(osf.x_var_df, osf.y_var_df, y_var_column=y_var_column)\n",
    "ml_inst.use_linear_regression(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### limit ref_time_rel_to_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.only_cur_ff_df['ref_time_rel_to_stop'] = osf.only_cur_ff_df['ref_time'] - osf.only_cur_ff_df['stop_time']\n",
    "osf.only_cur_ff_df = osf.only_cur_ff_df[osf.only_cur_ff_df['ref_time_rel_to_stop'].between(-0.5, -0.1)].copy()\n",
    "osf.x_features_df = osf.x_features_df.loc[osf.only_cur_ff_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.only_cur_ff_df['ref_time_rel_to_stop'] = osf.only_cur_ff_df['ref_time'] - osf.only_cur_ff_df['stop_time']\n",
    "osf.only_cur_ff_df = osf.only_cur_ff_df[osf.only_cur_ff_df['ref_time_rel_to_stop'] < -0.5].copy()\n",
    "osf.x_features_df = osf.x_features_df.loc[osf.only_cur_ff_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(osf.only_cur_ff_df['stop_time'] - osf.only_cur_ff_df['ref_time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify ref_point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.only_cur_ff_df['ref_time_rel_to_stop'] = osf.only_cur_ff_df['ref_time'] - osf.only_cur_ff_df['stop_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.only_cur_ff_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# osf.only_cur_ff_df['ref_cum_distance_rel_to_stop'] = osf.only_cur_ff_df['ref_cum_distance'] - osf.only_cur_ff_df['stop_cum_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.only_cur_ff_df['ref_time_rel_to_stop'] = osf.only_cur_ff_df['ref_time'] - osf.only_cur_ff_df['stop_time']\n",
    "osf.only_cur_ff_df[osf.only_cur_ff_df['ref_time_rel_to_stop'] > -0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find the closest stop time to each ff caught T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_sub = dc.monkey_information.loc[dc.monkey_information['monkey_speeddummy']==0, ['time', 'point_index']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_stop_to_capture_df = pd.DataFrame()\n",
    "all_closest_point_before_capture_rows = pd.DataFrame()\n",
    "for i in range(len(dc.ff_caught_T_new)):\n",
    "    caught_time = dc.ff_caught_T_new[i]\n",
    "    time = stop_sub['time'].values\n",
    "    iloc_of_closest_time = np.argmin(np.abs(time - caught_time))\n",
    "    closest_point_row = stop_sub.iloc[[iloc_of_closest_time]].copy()\n",
    "    closest_point_row['cur_ff_index'] = i\n",
    "    closest_point_row['caught_time'] = caught_time\n",
    "    closest_stop_to_capture_df = pd.concat([closest_stop_to_capture_df, closest_point_row], axis=0)\n",
    "\n",
    "    monkey_t_sub = time[time <= caught_time]\n",
    "    iloc_of_closest_time = np.argmin(np.abs(monkey_t_sub - caught_time))\n",
    "    closest_point_row = stop_sub.iloc[[iloc_of_closest_time]].copy()\n",
    "    closest_point_row['cur_ff_index'] = i\n",
    "    closest_point_row['caught_time'] = caught_time\n",
    "    all_closest_point_before_capture_rows = pd.concat([all_closest_point_before_capture_rows, closest_point_row], axis=0)\n",
    "\n",
    "closest_stop_to_capture_df['time_before_capture'] = all_closest_point_before_capture_rows['time'].values\n",
    "closest_stop_to_capture_df['diff_from_caught_time'] = closest_stop_to_capture_df['time'] - closest_stop_to_capture_df['caught_time']\n",
    "closest_stop_to_capture_df['diff_from_before_capture_to_caught_time'] = closest_stop_to_capture_df['time_before_capture'] - closest_stop_to_capture_df['caught_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make x and y axis equal scale\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Creating an ellipse using sine and cos functions:\n",
    "ax.scatter(x=closest_stop_to_capture_df['diff_from_caught_time'], y=closest_stop_to_capture_df['diff_from_before_capture_to_caught_time'], s=1)\n",
    "ax.plot([-1, 0], [-1, 0], color='black')\n",
    "ax.plot([0, 1], [0, -1], color='black')\n",
    "#ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_stop_to_capture_df[closest_stop_to_capture_df['diff_from_caught_time'] < -0.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_stop_to_capture_df_sub = closest_stop_to_capture_df[closest_stop_to_capture_df['diff_from_caught_time'] > 0].copy()\n",
    "closest_stop_to_capture_df_sub[closest_stop_to_capture_df_sub['diff_from_caught_time'] >= np.abs(closest_stop_to_capture_df_sub['diff_from_before_capture_to_caught_time'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_stop_to_capture_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(closest_stop_to_capture_df['diff_from_caught_time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(closest_stop_to_capture_df['diff_from_before_capture_to_caught_time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the above is enough justification to choose closest point rather than closest point before capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check vif in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_col = [column for column in mtc.x_var_df.columns if ('cur_ff_cluster_100_' in column)]\n",
    "#cluster_col = [column for column in mtc.x_var_df.columns if ('ref' in column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var_df = mtc.x_var_df[cluster_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_columns = [column for column in cluster_col if ('combd' in column)]\n",
    "x_var_df = prep_ml_data_utils.add_interaction_terms_to_df(x_var_df, specific_columns=specific_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = drop_high_vif_vars.get_vif_df(data_item.y_var)\n",
    "vif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
