{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.replicate_one_ff import population_analysis_utils, one_ff_data_processing, parameters, one_ff_pipeline, one_ff_glm_design\n",
    "from neural_data_analysis.topic_based_neural_analysis.replicate_one_ff.one_ff_gam import plot_gam_fit\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.tpg import glm_bases\n",
    "from neural_data_analysis.design_kits.design_by_segment import temporal_feats, spatial_feats\n",
    "from neural_data_analysis.topic_based_neural_analysis.replicate_one_ff.one_ff_gam import one_ff_gam_fit, assemble_one_ff_gam_design, penalty_tuning, backward_elimination\n",
    "from neural_data_analysis.topic_based_neural_analysis.replicate_one_ff.one_ff_gam.one_ff_gam_fit import GroupSpec, fit_poisson_gam_map\n",
    "\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "import cProfile\n",
    "import pstats\n",
    "import json\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "# To fit gpfa\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "from elephant.gpfa import GPFA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from elephant.gpfa import gpfa_core, gpfa_util\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Build design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(assemble_one_ff_gam_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariate_names = [\n",
    "    'v', 'w', 'd', 'phi',\n",
    "    'r_targ', 'theta_targ',\n",
    "    'eye_ver', 'eye_hor',\n",
    "]\n",
    "\n",
    "prs = parameters.default_prs()\n",
    "data_obj = one_ff_pipeline.OneFFSessionData(\n",
    "    mat_path='all_monkey_data/one_ff_data/sessions_python.mat',\n",
    "    prs=prs, \n",
    "    session_num=0,\n",
    ")\n",
    "\n",
    "covariate_names = [\n",
    "    'v', 'w', 'd', 'phi',\n",
    "    'r_targ', 'theta_targ',\n",
    "    'eye_ver', 'eye_hor'\n",
    "]\n",
    "\n",
    "# preprocessing\n",
    "data_obj.compute_covariates(covariate_names)\n",
    "data_obj.compute_spike_counts()\n",
    "data_obj.smooth_spikes()\n",
    "data_obj.compute_events()\n",
    "\n",
    "\n",
    "\n",
    "linear_vars = [\n",
    "    'v', 'w', 'd', 'r_targ',\n",
    "    'eye_ver', 'eye_hor',\n",
    "]\n",
    "\n",
    "angular_vars = [\n",
    "    'phi', 'theta_targ',\n",
    "]\n",
    "\n",
    "# Build design (in class)\n",
    "# build once\n",
    "temporal_df, temporal_meta, specs_meta = assemble_one_ff_gam_design.build_temporal_design_base(data_obj)\n",
    "X_tuning, tuning_meta = assemble_one_ff_gam_design.build_tuning_design(data_obj.data_df, linear_vars, angular_vars, \n",
    "                                                                        binrange_dict=data_obj.prs.binrange)\n",
    "\n",
    "\n",
    "# per-unit\n",
    "design_df, y, groups, all_meta = assemble_one_ff_gam_design.process_unit_design_and_groups(\n",
    "    unit_idx=unit_idx,\n",
    "    data_obj=data_obj,\n",
    "    temporal_df=temporal_df,\n",
    "    temporal_meta=temporal_meta,\n",
    "    X_tuning=X_tuning,\n",
    "    tuning_meta=tuning_meta,\n",
    "    specs_meta=specs_meta,\n",
    "    #coupling_units=[1, 3, 7],  # optional\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(f'all_monkey_data/one_ff_data/my_gam_results/neuron_{unit_idx}')\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "(outdir / 'fit_results').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lam_suffix = one_ff_gam_fit.generate_lambda_suffix(groups)\n",
    "save_path = outdir / 'fit_results' / f'{lam_suffix}.pkl'\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Fit the MAP Poisson GAM\n",
    "# ----------------------------\n",
    "fit_res = fit_poisson_gam_map(\n",
    "    design_df=design_df,\n",
    "    y=y,\n",
    "    groups=groups,\n",
    "    l1_groups=[],\n",
    "    max_iter=200,\n",
    "    tol=1e-6,\n",
    "    verbose=True,\n",
    "    save_path=save_path,\n",
    ")\n",
    "\n",
    "print('success:', fit_res.success)\n",
    "print('message:', fit_res.message)\n",
    "print('n_iter:', fit_res.n_iter)\n",
    "print('final objective:', fit_res.fun)\n",
    "print('grad_norm:', fit_res.grad_norm)\n",
    "\n",
    "beta = fit_res.coef  # pd.Series indexed by design_df columns\n",
    "\n",
    "# ----------------------------\n",
    "# 5) (Optional) Recover tuning curves / kernels in the same spirit as their MATLAB\n",
    "# ----------------------------\n",
    "# Helper to get weights for a group\n",
    "def get_group_beta(beta: pd.Series, cols: list) -> np.ndarray:\n",
    "    cols_present = [c for c in cols if c in beta.index]\n",
    "    return beta.loc[cols_present].to_numpy()\n",
    "\n",
    "temporal_groups = temporal_meta['groups']  # {'t_targ': [...], 't_move': [...], 't_rew': [...], 'spike_hist': [...]}\n",
    "# Example: event kernels (weights live in basis space)\n",
    "beta_t_targ = get_group_beta(beta, temporal_groups['t_targ'])\n",
    "beta_t_move = get_group_beta(beta, temporal_groups['t_move'])\n",
    "beta_t_rew = get_group_beta(beta, temporal_groups['t_rew'])\n",
    "beta_hist = get_group_beta(beta, all_meta['hist']['groups']['spike_hist'])\n",
    "\n",
    "# Example: tuning weights (boxcar/Fourier weights)\n",
    "beta_v = get_group_beta(beta, tuning_meta['groups']['v'])\n",
    "beta_phi = get_group_beta(beta, tuning_meta['groups']['phi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_res.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_res.n_iter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_res.grad_norm  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "X = design_df.to_numpy(dtype=float)\n",
    "y_array = np.asarray(y, dtype=float).ravel()\n",
    "\n",
    "# Initialize beta0 the same way the function does\n",
    "rng = np.random.default_rng(0)\n",
    "beta0 = 1e-3 * rng.standard_normal(X.shape[1])\n",
    "if 'const' in design_df.columns:\n",
    "    beta0[design_df.columns.get_loc('const')] = np.log(max(y_array.mean(), 1e-8))\n",
    "\n",
    "# Run diagnostics\n",
    "u0 = X @ beta0\n",
    "print(\"=\" * 80)\n",
    "print(\"PRE-FIT DIAGNOSTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Design matrix shape: {X.shape}\")\n",
    "print(f\"X range: [{X.min():.2e}, {X.max():.2e}]\")\n",
    "print(f\"y range: [{y_array.min():.2e}, {y_array.max():.2e}]\")\n",
    "print(f\"y mean: {y_array.mean():.2e}, y sum: {y_array.sum():.2e}\")\n",
    "print(f\"Initial beta range: [{beta0.min():.2e}, {beta0.max():.2e}]\")\n",
    "print(f\"Initial u = X @ beta0 range: [{u0.min():.2e}, {u0.max():.2e}]\")\n",
    "print(f\"Initial rate = exp(u) range: [{np.exp(u0.min()):.2e}, {np.exp(u0.max()):.2e}]\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = prs.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "beta0 = beta['const']\n",
    "baseline_rate = np.exp(beta0) / dt\n",
    "\n",
    "print(f'Baseline firing rate: {baseline_rate:.2f} Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in tuning_meta['linear_vars']:\n",
    "    plot_gam_fit.plot_linear_tuning(var, beta, tuning_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in tuning_meta['angular_vars']:\n",
    "    plot_gam_fit.plot_angular_tuning(var, beta, tuning_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot anything!\n",
    "plot_gam_fit.plot_variable('v', beta, all_meta)           # tuning\n",
    "plot_gam_fit.plot_variable('t_move', beta, all_meta)      # event\n",
    "plot_gam_fit.plot_variable('spike_hist', beta, all_meta)  # history\n",
    "\n",
    "# Or plot everything\n",
    "plot_gam_fit.plot_all_tuning_curves(beta, all_meta)\n",
    "plot_gam_fit.plot_all_temporal_filters(beta, all_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# save_path = 'all_monkey_data/one_ff_data/my_gam_results/neuron_2/kept_groups.pkl'\n",
    "# with open(save_path, 'rb') as f:\n",
    "#     saved_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_path = 'all_monkey_data/one_ff_data/my_gam_results/neuron_2/history.csv'\n",
    "# history = pd.read_csv(history_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory and paths\n",
    "outdir = Path(f'all_monkey_data/one_ff_data/my_gam_results/neuron_{unit_idx}')\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate descriptive filename with lambda configuration\n",
    "lam_suffix = one_ff_gam_fit.generate_lambda_suffix(groups)\n",
    "save_path = outdir / 'backward_elimination' / f'{lam_suffix}.pkl'\n",
    "#save_path = outdir / 'kept_groups.pkl'\n",
    "\n",
    "kept, history = backward_elimination.backward_elimination_gam(\n",
    "    design_df=design_df,\n",
    "    y=y,\n",
    "    groups=groups,\n",
    "    alpha=0.05,\n",
    "    n_folds=10,\n",
    "    verbose=True,\n",
    "    save_path=str(save_path),\n",
    ")\n",
    "\n",
    "print('\\nFinal retained variables:')\n",
    "for g in kept:\n",
    "    print(' ', g.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# penalty tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(f'all_monkey_data/one_ff_data/my_gam_results/neuron_{unit_idx}')\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "l1_groups = []  # coupling Laplace prior can go here later\n",
    "\n",
    "\n",
    "lam_grid = {\n",
    "    'lam_f': [10, 50, 100, 300],\n",
    "    'lam_g': [1, 5, 10, 30],\n",
    "    'lam_h': [1, 5, 10, 30],\n",
    "}\n",
    "\n",
    "group_name_map = {\n",
    "    'lam_f': list(tuning_meta['groups'].keys()),\n",
    "    'lam_g': ['t_targ', 't_move', 't_rew'],\n",
    "    'lam_h': ['spike_hist'],\n",
    "}\n",
    "\n",
    "best_lams, cv_results = penalty_tuning.tune_penalties(\n",
    "    design_df=design_df,\n",
    "    y=y,\n",
    "    base_groups=groups,\n",
    "    l1_groups=l1_groups,\n",
    "    lam_grid=lam_grid,\n",
    "    group_name_map=group_name_map,\n",
    "    n_folds=5,\n",
    "    save_path=outdir / 'penalty_tuning.pkl',\n",
    "    retrieve_only=True,\n",
    ")\n",
    "\n",
    "print('Best lambdas:', best_lams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Refit final model with best penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_groups = penalty_tuning.clone_groups_with_lams(groups, {\n",
    "    gname: best_lams['lam_f'] for gname in group_name_map['lam_f']\n",
    "} | {\n",
    "    gname: best_lams['lam_g'] for gname in group_name_map['lam_g']\n",
    "} | {\n",
    "    gname: best_lams['lam_h'] for gname in group_name_map['lam_h']\n",
    "})\n",
    "\n",
    "fit_res = fit_poisson_gam_map(\n",
    "    design_df=design_df,\n",
    "    y=y,\n",
    "    groups=final_groups,\n",
    "    l1_groups=l1_groups,\n",
    "    max_iter=200,\n",
    "    tol=1e-6,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# see one trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs = parameters.default_prs()\n",
    "data_obj = one_ff_pipeline.OneFFSessionData(\n",
    "    mat_path='all_monkey_data/one_ff_data/sessions_python.mat',\n",
    "    prs=prs, \n",
    "    session_num=0,\n",
    ")\n",
    "\n",
    "data_obj._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices\n",
    "session_num = 0\n",
    "trial_num = 0\n",
    "\n",
    "# params\n",
    "sessions = data_obj.sessions\n",
    "prs = parameters.default_prs()\n",
    "\n",
    "# session / behaviour\n",
    "session = sessions[session_num]\n",
    "behaviour = session.behaviour\n",
    "\n",
    "# trials / stats\n",
    "all_trials = behaviour.trials\n",
    "all_stats = behaviour.stats\n",
    "trial_ids = np.arange(len(all_trials))\n",
    "\n",
    "trial = all_trials[trial_num]\n",
    "stats = all_stats[trial_num]\n",
    "pos_rel = stats.pos_rel\n",
    "\n",
    "# continuous data\n",
    "continuous = trial.continuous\n",
    "print(continuous._fieldnames)\n",
    "\n",
    "x = continuous.xmp\n",
    "y = continuous.ymp\n",
    "v = continuous.v\n",
    "w = continuous.w\n",
    "t = continuous.ts\n",
    "\n",
    "# time step\n",
    "prs.dt = round(np.mean(np.diff(t)), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## verify compute_all_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = one_ff_data_processing.compute_all_covariates(trial, prs.dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "are_close = np.allclose(pos_rel.r_targ, covariates['r_targ'], rtol=1e-5, atol=1e-8, equal_nan=True)\n",
    "print(are_close)\n",
    "\n",
    "are_close = np.allclose(pos_rel.theta_targ, covariates['theta_targ'], rtol=1e-5, atol=1e-8, equal_nan=True)\n",
    "print(are_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in covariates.items():\n",
    "    print(k, v.shape, np.nanmin(v), np.nanmax(v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# try script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python multiff_analysis/jobs/one_ff/scripts/one_ff_back_elim_script.py --unit_idx 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python multiff_analysis/jobs/one_ff/scripts/one_ff_pen_tune_script.py --unit_idx 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
