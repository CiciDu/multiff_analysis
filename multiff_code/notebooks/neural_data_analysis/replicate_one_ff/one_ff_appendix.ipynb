{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat('all_monkey_data/one_ff_data/sessions_python.mat',\n",
    "               squeeze_me=True,\n",
    "               struct_as_record=False)\n",
    "\n",
    "sessions = data['sessions_out']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## see one trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices\n",
    "session_num = 0\n",
    "trial_num = 0\n",
    "\n",
    "# params\n",
    "prs = default_prs()\n",
    "\n",
    "# session / behaviour\n",
    "session = sessions[session_num]\n",
    "behaviour = session.behaviour\n",
    "\n",
    "# trials / stats\n",
    "all_trials = behaviour.trials\n",
    "all_stats = behaviour.stats\n",
    "trial_ids = np.arange(len(all_trials))\n",
    "\n",
    "trial = all_trials[trial_num]\n",
    "stats = all_stats[trial_num]\n",
    "pos_rel = stats.pos_rel\n",
    "\n",
    "# continuous data\n",
    "continuous = trial.continuous\n",
    "print(continuous._fieldnames)\n",
    "\n",
    "x = continuous.xmp\n",
    "y = continuous.ymp\n",
    "v = continuous.v\n",
    "w = continuous.w\n",
    "t = continuous.ts\n",
    "\n",
    "# time step\n",
    "prs.dt = round(np.mean(np.diff(t)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, y, 'k-')\n",
    "plt.xlabel('x (forward)')\n",
    "plt.ylabel('y (lateral)')\n",
    "plt.axis('equal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = sessions[session_num].units\n",
    "n_units = len(units)\n",
    " \n",
    "# get unit0's trial_0 spike times\n",
    "trial_neural_data = {}\n",
    "for unit_id in range(len(sessions[session_num].units)):\n",
    "    trial_neural_data[unit_id] = sessions[session_num].units[unit_id].trials[trial_num].tspk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_data_analysis.topic_based_neural_analysis.replicate_one_ff import one_ff_data_processing\n",
    "from neural_data_analysis.topic_based_neural_analysis.replicate_one_ff import population_analysis_utils\n",
    "\n",
    "covariate_names = [\n",
    "    'v', 'w', 'd', 'phi',\n",
    "    'r_targ', 'theta_targ',\n",
    "    'eye_ver', 'eye_hor'\n",
    "]\n",
    "\n",
    "covariates_concat, trial_id_vec = population_analysis_utils.concatenate_covariates_with_trial_id(\n",
    "    trials=all_trials,\n",
    "    trial_indices=trial_ids,\n",
    "    covariate_fn=lambda tr: one_ff_data_processing.compute_all_covariates(tr, prs.dt),\n",
    "    time_window_fn=population_analysis_utils.full_time_window,\n",
    "    covariate_names=covariate_names\n",
    ")\n",
    "\n",
    "covariates_concat['v'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros((len(trial_id_vec), n_units))\n",
    "for k in range(n_units):\n",
    "    spk_counts, trial_id_vec_spk = population_analysis_utils.concatenate_trials_with_trial_id(\n",
    "        all_trials,\n",
    "        trial_ids,\n",
    "        lambda tr, tid: population_analysis_utils.bin_spikes(\n",
    "            trial_neural_data[k],\n",
    "            tr.continuous.ts\n",
    "        ),\n",
    "        population_analysis_utils.full_time_window\n",
    "    )\n",
    "    Y[:, k] = spk_counts\n",
    "\n",
    "Y_smooth = population_analysis_utils.smooth_signal(Y, prs.neural_filtwidth) / prs.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = {}\n",
    "for event in ['t_targ', 't_move', 't_rew']:\n",
    "    events_concat, trial_id_vec_evt = population_analysis_utils.concatenate_trials_with_trial_id(\n",
    "        all_trials,\n",
    "        trial_ids,\n",
    "        lambda tr, tid: population_analysis_utils.event_impulse(tr, tid, event),\n",
    "        population_analysis_utils.full_time_window\n",
    "    )\n",
    "    all_events[event] = events_concat\n",
    "    \n",
    "events_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# PGAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## temporal covariance\n",
    "\n",
    "Temporal filters g were parameterized using a basis of ten raised cosine filters spanning a range of 600 milliseconds. The filter associated with target-onset was causal ([0, 600] ms), while the remaining filters were non-causal ([-300, 300] ms). Both spike-history filter h and coupling filter p were expressed using a basis of ten causal raised cosine filters in logarithmic time scale. Spike-history filters spanned 350 ms, while coupling filters spanned 1.375 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_idx = 0\n",
    "sm_handler = one_ff_pgam_design.build_smooth_handler_for_unit(\n",
    "    unit_idx=unit_idx,                         # <-- choose the unit you want\n",
    "    covariates_concat=covariates_concat,\n",
    "    covariate_names=covariate_names,\n",
    "    trial_id_vec=trial_id_vec,\n",
    "    Y_binned=Y,\n",
    "    all_events=all_events,\n",
    "    dt=prs.dt,\n",
    "    tuning_covariates=covariate_names,  # or a subset\n",
    "    use_cyclic=set(),                  # e.g., {'heading_angle'}\n",
    "    order=4,\n",
    ")\n",
    "\n",
    "sm_handler.smooths_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Call class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_spikes_df = pd.DataFrame(Y, columns=np.arange(n_units))\n",
    "runner = pgam_class.PGAMclass(x_var=binned_spikes_df, bin_width=prs.dt,\n",
    "                                 save_dir='all_monkey_data/one_ff_data/pgam_results')\n",
    "\n",
    "runner.sm_handler = sm_handler\n",
    "runner.trial_ids = trial_id_vec\n",
    "runner.train_trials = runner.trial_ids % 3 != 1\n",
    "runner.run_pgam(neural_cluster_number=unit_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.kernel_h_length = 100\n",
    "runner.post_processing_results()\n",
    "runner.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Build design (not using functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_obj.covariates)\n",
    "\n",
    "linear_vars = [\n",
    "    'v', 'w', 'd', 'r_targ',\n",
    "    'eye_ver', 'eye_hor',\n",
    "]\n",
    "\n",
    "angular_vars = [\n",
    "    'phi', 'theta_targ',\n",
    "]\n",
    "\n",
    "X_tuning, tuning_meta = one_ff_glm_design.build_continuous_tuning_block(\n",
    "    data=data_df,\n",
    "    linear_vars=linear_vars,\n",
    "    angular_vars=angular_vars,\n",
    "    n_bins=10,\n",
    "    center=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_idx = 0\n",
    "\n",
    "\n",
    "specs, meta = temporal_feats._init_predictor_specs(\n",
    "    data_obj.prs.dt,\n",
    "    data_obj.trial_ids,\n",
    ")\n",
    "\n",
    "\n",
    "lags, B_move = glm_bases.raised_cosine_basis(\n",
    "    n_basis=10,\n",
    "    t_min=-0.3,\n",
    "    t_max=0.3,\n",
    "    dt=meta['dt'],\n",
    ")\n",
    "\n",
    "lags, B_targ = glm_bases.raised_cosine_basis(\n",
    "    n_basis=10,\n",
    "    t_min=0.0,\n",
    "    t_max=0.6,\n",
    "    dt=meta['dt'],\n",
    ")\n",
    "\n",
    "lags, B_hist = glm_bases.raised_log_cosine_basis(\n",
    "    n_basis=10,\n",
    "    t_min=0.0,\n",
    "    t_max=0.35,   # or 1.375\n",
    "    dt=meta['dt'],\n",
    "    log_spaced=True,\n",
    ")\n",
    "\n",
    "# spike history basis (log-spaced, causal)\n",
    "_, B_hist = glm_bases.raised_log_cosine_basis(\n",
    "    n_basis=10,\n",
    "    t_min=0.0,\n",
    "    t_max=0.35,\n",
    "    dt=meta['dt'],\n",
    ")\n",
    "\n",
    "_, B_coup = glm_bases.raised_log_cosine_basis(\n",
    "    n_basis=10,\n",
    "    t_min=0.0,\n",
    "    t_max=1.375,\n",
    "    dt=meta['dt'],\n",
    ")\n",
    "\n",
    "specs['t_targ'] = temporal_feats.PredictorSpec(signal=data_obj.events['t_targ'], bases=[B_targ])\n",
    "specs['t_move'] = temporal_feats.PredictorSpec(signal=data_obj.events['t_move'], bases=[B_move])\n",
    "specs['t_rew'] = temporal_feats.PredictorSpec(signal=data_obj.events['t_rew'], bases=[B_move])\n",
    "specs['spike_hist'] = temporal_feats.PredictorSpec(\n",
    "    signal=data_obj.Y[:, unit_idx],   # THIS neuronâ€™s spikes (0/1 or counts)\n",
    "    bases=[B_hist],\n",
    ")\n",
    "\n",
    "# # add coupling terms later\n",
    "# specs[f'cpl_{j}'] = temporal_feats.PredictorSpec(\n",
    "#     signal=data_obj.Y[:, j],   # spikes from neuron j\n",
    "#     bases=[B_coup],\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1) Build temporal block (you already do this)\n",
    "# ----------------------------\n",
    "design_df, meta = temporal_feats.specs_to_design_df(\n",
    "    specs,\n",
    "    data_obj.covariate_trial_ids,\n",
    "    edge='zero',\n",
    "    add_intercept=True,\n",
    "    respect_trial_boundaries=False\n",
    ")\n",
    "\n",
    "# Align and concatenate\n",
    "X_tuning = X_tuning.reindex(design_df.index)\n",
    "design_df = pd.concat([design_df, X_tuning], axis=1)\n",
    "\n",
    "# Response aligned to design_df rows\n",
    "unit_idx = 0\n",
    "y = pd.Series(data_obj.Y[:, unit_idx], index=design_df.index).to_numpy()\n",
    "\n",
    "# If temporal builder provides a valid-row mask, apply it to X and y\n",
    "rows_mask = meta.get('valid_rows_mask', None)\n",
    "if rows_mask is not None:\n",
    "    design_df = design_df.loc[rows_mask]\n",
    "    y = y[rows_mask]\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Define lambdas (match paper defaults you pasted: f~100, g/h/p~10)\n",
    "# ----------------------------\n",
    "lam_f = 100.0  # tuning smoothness\n",
    "lam_g = 10.0   # event kernel smoothness\n",
    "lam_h = 10.0   # spike-history kernel smoothness\n",
    "# lam_p = 10.0 # coupling L1/smoothness (if you add coupling later)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Build GroupSpec list (this is the critical part)\n",
    "# suggested vartypes:\n",
    "#   - temporal kernels: 'event'\n",
    "#   - spike history: 'event'\n",
    "#   - linear tunings: '1D'\n",
    "#   - angular tunings: '1Dcirc' (if truly circular angles; otherwise use '1D')\n",
    "# ----------------------------\n",
    "groups = []\n",
    "\n",
    "# --- temporal groups are exact from meta['groups'] you pasted ---\n",
    "temporal_groups = meta['groups']  # {'t_targ': [...], 't_move': [...], 't_rew': [...], 'spike_hist': [...]}\n",
    "\n",
    "groups.append(GroupSpec(name='t_targ', cols=temporal_groups['t_targ'], vartype='event', lam=lam_g))\n",
    "groups.append(GroupSpec(name='t_move', cols=temporal_groups['t_move'], vartype='event', lam=lam_g))\n",
    "groups.append(GroupSpec(name='t_rew',  cols=temporal_groups['t_rew'],  vartype='event', lam=lam_g))\n",
    "groups.append(GroupSpec(name='spike_hist', cols=temporal_groups['spike_hist'], vartype='event', lam=lam_h))\n",
    "\n",
    "# --- tuning groups come from tuning_meta['groups'] ---\n",
    "# tuning_meta['groups'] maps each variable -> its column names in X_tuning\n",
    "for var, cols in tuning_meta['groups'].items():\n",
    "    if var in angular_vars:\n",
    "        vartype = '1Dcirc'\n",
    "    else:\n",
    "        vartype = '1D'\n",
    "    groups.append(GroupSpec(name=var, cols=cols, vartype=vartype, lam=lam_f))\n",
    "\n",
    "# If you later add 2D variables (e.g. position x/y tiled), set vartype='2D' for that group\n",
    "# If you later add coupling filters and want Laplace prior (L1), put those in l1_groups below.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
