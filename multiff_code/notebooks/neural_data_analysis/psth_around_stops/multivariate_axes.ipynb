{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "    \n",
    "from data_wrangling import specific_utils, process_monkey_information, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class, pn_aligned_by_seg, pn_aligned_by_event\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from machine_learning.ml_methods import regression_utils, regz_regression_utils, ml_methods_class, classification_utils, ml_plotting_utils, ml_methods_utils\n",
    "from planning_analysis.show_planning import nxt_ff_utils, show_planning_utils\n",
    "from neural_data_analysis.neural_analysis_tools.gpfa_methods import elephant_utils, fit_gpfa_utils, plot_gpfa_utils, gpfa_helper_class\n",
    "from neural_data_analysis.neural_analysis_tools.align_trials import time_resolved_regression, time_resolved_gpfa_regression,plot_time_resolved_regression\n",
    "from neural_data_analysis.neural_analysis_tools.align_trials import align_trial_utils\n",
    "from decision_making_analysis.event_detection import detect_rsw_and_rcap\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_psth import core_stops_psth, psth_postprocessing, psth_stats, compare_events, dpca_utils\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.get_stop_events import get_stops_utils, collect_stop_data\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_fit import stop_glm_fit, cv_stop_glm, glm_fit_utils, variance_explained\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_plotting import plot_spikes, plot_glm_fit, plot_tuning_func\n",
    "from neural_data_analysis.design_kits.design_around_event import event_binning, stop_design, cluster_design, design_checks\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_hyperparams import compare_glm_configs, glm_hyperparams_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.ff_visibility import ff_vis_epochs, vis_design\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.glm_decoding_tools import glm_decoding_llr\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.get_stop_events import assemble_stop_design\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import raster_plot, raster_plot_3d\n",
    "\n",
    "# import decoding\n",
    "from neural_data_analysis.neural_analysis_tools.decoding_tools import decoding_utils, decoding_analysis, plot_decoding, cmp_decode, load_results\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_neural_viz import stop_event_raster\n",
    "\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data\n",
    "\n",
    "from neural_data_analysis.neural_analysis_tools.lfads import lfads_visualizer\n",
    "\n",
    "from neural_data_analysis.neural_analysis_tools.neural_axes import window_search, axis_utils\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "import cProfile\n",
    "import pstats\n",
    "import json\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "# To fit gpfa\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "from elephant.gpfa import GPFA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from elephant.gpfa import gpfa_core, gpfa_util\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0327\"\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0326\"\n",
    "\n",
    "pn, datasets, comparisons = collect_stop_data.collect_stop_data_func(\n",
    "    raw_data_folder_path)\n",
    "\n",
    "globals().update(datasets)\n",
    "\n",
    "captures_df, valid_captures_df, filtered_no_capture_stops_df, stops_with_stats = get_stops_utils.prepare_no_capture_and_captures(\n",
    "    monkey_information=pn.monkey_information,\n",
    "    closest_stop_to_capture_df=pn.closest_stop_to_capture_df,\n",
    "    ff_caught_T_new=pn.ff_caught_T_new,\n",
    "    distance_col=\"distance_from_ff_to_stop\",\n",
    ")\n",
    "\n",
    "keys = ['rsw_first_vs_rcap_first', 'rsw_middle_vs_rcap_middle', 'one_stop_vs_both_first_miss', 'switch_vs_retry_after_miss', 'switch_vs_retry_after_retry']\n",
    "\n",
    "cfg = core_stops_psth.PSTHConfig(\n",
    "    pre_window=0.5,\n",
    "    post_window=0.5,\n",
    "    bin_width=0.05,\n",
    "    smoothing_sigma=0.1,\n",
    "    min_trials=5,\n",
    "    normalize=\"zscore\",            # try: None, \"sub\", or \"div\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# get stop_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['stop_id', 'time', 'point_index', 'stop_id_start_time', 'stop_id_end_time', 'stop_id_duration']\n",
    "stop_label_df = pn.stop_category_df[cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combd_retry_df = pd.concat([datasets['rcap'], datasets['rsw']], axis=0).reset_index(drop=True)\n",
    "datasets['combd_retry_first'] = combd_retry_df[combd_retry_df['is_first']].copy()\n",
    "datasets['combd_retry_second'] = combd_retry_df[combd_retry_df['is_second']].copy()\n",
    "datasets['combd_retry_third'] = combd_retry_df[combd_retry_df['is_third']].copy()\n",
    "datasets['combd_retry_last'] = combd_retry_df[combd_retry_df['is_last']].copy()\n",
    "datasets['rcap_second_to_last'] = combd_retry_df[combd_retry_df['is_second_to_last']].copy()\n",
    "datasets['rcap_before_second_to_last'] = combd_retry_df[combd_retry_df['before_second_to_last']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col_name, df, value in [\n",
    "    ('capture', datasets['captures'], 1),\n",
    "    ('as_retry', datasets['retry_after_miss'], 1),\n",
    "    ('will_retry', pd.concat([datasets['rcap_nonfinal'], datasets['rsw_nonfinal']], axis=0), 1),\n",
    "    ('first_retry', datasets['combd_retry_first'], 1),\n",
    "    ('second_retry', datasets['combd_retry_second'], 1),\n",
    "    ('third_retry', datasets['combd_retry_third'], 1),\n",
    "    ('last_retry', datasets['combd_retry_last'], 1),\n",
    "    ('attempt', datasets['non_captures_minus_all_misses'], 0),\n",
    "    ('next_retry_capture', datasets['rcap_second_to_last'], 1),\n",
    "    ('next_retry_miss', pd.concat([datasets['rsw_nonfinal'], datasets['rcap_before_second_to_last']], axis=0), 1),\n",
    "]:\n",
    "    \n",
    "    df = df.copy()\n",
    "    df[col_name] = value\n",
    "    stop_label_df.drop(columns=[col_name], inplace=True, errors='ignore')\n",
    "    stop_label_df = pd.merge(stop_label_df, df[['stop_id', col_name]], on='stop_id', how='left')\n",
    "    stop_label_df[col_name] = stop_label_df[col_name].fillna(1-value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# retry x geometry interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['capture', 'as_retry', 'will_retry', 'first_retry', 'second_retry', 'third_retry', 'last_retry', 'attempt', 'next_retry_capture', 'next_retry_miss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_label_df = stop_label_df[stop_label_df['capture']==0].copy().drop(columns=['capture'])\n",
    "columns.remove('capture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_data_analysis.neural_analysis_tools.neural_axes import multivariate_axis_analyzer\n",
    "\n",
    "analyzer = multivariate_axis_analyzer.MultivariateAxisAnalyzer(\n",
    "    spikes_df=pn.spikes_df,\n",
    "    behavior_df=stop_label_df,\n",
    "    event_col='time',\n",
    "    behavior_cols=columns,\n",
    "    bin_width_ms=10,\n",
    ")\n",
    "\n",
    "axis_info = analyzer.compute_axes(\n",
    "    window_ms=(100, 200),\n",
    "    interaction_pairs=[(0, 1)],   # retry × angular_error\n",
    "    rank=10,\n",
    ")\n",
    "\n",
    "W = axis_info['axes']\n",
    "proj = axis_info['projection']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(1, 10):\n",
    "    axis_info = analyzer.compute_axes(window_ms=(100, 200), rank=r)\n",
    "    print(r, axis_info['projection'].var(axis=0).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W.shape)          # (n_neurons, 3)\n",
    "print(proj.shape)       # (T, 3)\n",
    "assert proj.shape[0] == analyzer.fr_mat.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_var = proj.var(axis=0)\n",
    "\n",
    "order = np.argsort(axis_var)[::-1]\n",
    "W = W[:, order]\n",
    "proj = proj[:, order]\n",
    "axis_var = axis_var[order]\n",
    "\n",
    "axis_var / axis_var.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Plot each axis separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_bins = analyzer._events_to_bins(stop_label_df['time'].to_numpy())\n",
    "\n",
    "window_ms = (-300, 500)\n",
    "so = int(window_ms[0] / analyzer.bin_width_ms)\n",
    "eo = int(window_ms[1] / analyzer.bin_width_ms)\n",
    "offsets = np.arange(so, eo)\n",
    "\n",
    "T = proj.shape[0]\n",
    "idx = event_bins[:, None] + offsets[None, :]\n",
    "idx = np.clip(idx, 0, T - 1)\n",
    "\n",
    "aligned_proj = proj[idx]   # (n_stops, time, 3)\n",
    "time = offsets * analyzer.bin_width_s\n",
    "\n",
    "for k in range(10):\n",
    "    if k >= aligned_proj.shape[2]:\n",
    "        break\n",
    "    mean = aligned_proj[:, :, k].mean(axis=0)\n",
    "    sem = aligned_proj[:, :, k].std(axis=0) / np.sqrt(aligned_proj.shape[0])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.fill_between(time, mean - sem, mean + sem, alpha=0.3)\n",
    "    plt.plot(time, mean)\n",
    "    plt.axvline(0, color='k', linestyle='--')\n",
    "    plt.title(f'Axis {k+1}')\n",
    "    plt.xlabel('Time from stop (s)')\n",
    "    plt.ylabel('Projection')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Relate axes back to behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_proj = aligned_proj[:, (offsets >= 0) & (offsets <= 20), :].mean(axis=1)\n",
    "\n",
    "for col in columns:\n",
    "    y = stop_label_df[col].to_numpy()\n",
    "    print(col)\n",
    "    for k in range(3):\n",
    "        plt.figure()\n",
    "        plt.boxplot([stop_proj[y==0, k], stop_proj[y==1, k]])\n",
    "        plt.xticks([1, 2], ['Not ' + col, '' + col])\n",
    "        plt.title(f'Axis {k+1}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Conditioned peri-stop plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_bins = analyzer._events_to_bins(stop_label_df['time'].to_numpy())\n",
    "\n",
    "window_ms = (-300, 500)\n",
    "so = int(window_ms[0] / analyzer.bin_width_ms)\n",
    "eo = int(window_ms[1] / analyzer.bin_width_ms)\n",
    "offsets = np.arange(so, eo)\n",
    "\n",
    "idx = event_bins[:, None] + offsets[None, :]\n",
    "idx = np.clip(idx, 0, proj.shape[0] - 1)\n",
    "\n",
    "aligned_proj = proj[idx]            # (n_stops, n_timepoints, n_axes)\n",
    "time = offsets * analyzer.bin_width_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Split by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_label_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_idx = 0\n",
    "\n",
    "y = stop_label_df['first_retry'].to_numpy().astype(bool)\n",
    "\n",
    "aligned_last = aligned_proj[y]       # last_retry == 1\n",
    "aligned_not  = aligned_proj[~y]      # last_retry == 0\n",
    "\n",
    "mean_last = aligned_last[:, :, axis_idx].mean(axis=0)\n",
    "sem_last  = aligned_last[:, :, axis_idx].std(axis=0) / np.sqrt(aligned_last.shape[0])\n",
    "\n",
    "mean_not = aligned_not[:, :, axis_idx].mean(axis=0)\n",
    "sem_not  = aligned_not[:, :, axis_idx].std(axis=0) / np.sqrt(aligned_not.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.fill_between(time, mean_last - sem_last, mean_last + sem_last, alpha=0.3)\n",
    "plt.plot(time, mean_last, label='Last retry')\n",
    "\n",
    "plt.fill_between(time, mean_not - sem_not, mean_not + sem_not, alpha=0.3)\n",
    "plt.plot(time, mean_not, label='Not last retry')\n",
    "\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Time from stop (s)')\n",
    "plt.ylabel('Axis 1 projection')\n",
    "plt.legend()\n",
    "plt.title('Axis 1 conditioned on last_retry')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Average Axis 1 separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Axis geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Angles between axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_data_analysis.neural_analysis_tools.neural_axes.axis_utils import axis_angle\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(i+1, 3):\n",
    "        print(i, j, axis_angle(W[:, i], W[:, j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Neuron loadings (who contributes?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(W, aspect='auto', cmap='bwr')\n",
    "plt.colorbar(label='Weight')\n",
    "plt.xlabel('Axis')\n",
    "plt.ylabel('Neuron')\n",
    "plt.title('Neuron loadings on axes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Cross-validation / stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Angles between vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "rs = ShuffleSplit(n_splits=5, test_size=0.5)\n",
    "Ws = []\n",
    "\n",
    "for train, _ in rs.split(stop_label_df):\n",
    "    sub_analyzer = multivariate_axis_analyzer.MultivariateAxisAnalyzer(\n",
    "        spikes_df=pn.spikes_df,\n",
    "        behavior_df=stop_label_df.iloc[train].reset_index(drop=True),\n",
    "        event_col='time',\n",
    "        behavior_cols=columns,\n",
    "        bin_width_ms=10,\n",
    "    )\n",
    "    info = sub_analyzer.compute_axes(\n",
    "        window_ms=(100, 200),\n",
    "        interaction_pairs=[(0, 1)],\n",
    "        rank=3,\n",
    "    )\n",
    "    Ws.append(info['axes'])\n",
    "    \n",
    "for k in range(3):\n",
    "    angles = [\n",
    "        axis_angle(W[:, k], W2[:, k])\n",
    "        for W2 in Ws\n",
    "    ]\n",
    "    print(f'Axis {k+1}: mean angle = {np.mean(angles):.1f}°')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Angles between subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "rs = ShuffleSplit(n_splits=5, test_size=0.5)\n",
    "Ws = []\n",
    "\n",
    "for train, _ in rs.split(stop_label_df):\n",
    "    sub_analyzer = multivariate_axis_analyzer.MultivariateAxisAnalyzer(\n",
    "        spikes_df=pn.spikes_df,\n",
    "        behavior_df=stop_label_df.iloc[train].reset_index(drop=True),\n",
    "        event_col='time',\n",
    "        behavior_cols=columns,\n",
    "        bin_width_ms=10,\n",
    "    )\n",
    "    info = sub_analyzer.compute_axes(\n",
    "        window_ms=(100, 200),\n",
    "        interaction_pairs=[(0, 1)],\n",
    "        rank=3,\n",
    "    )\n",
    "    Ws.append(info['axes'])   # each: (neurons, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a reference subspace\n",
    "# Typically the full-data fit, or the first split:\n",
    "W_ref = Ws[0]\n",
    "\n",
    "from scipy.linalg import subspace_angles\n",
    "import numpy as np\n",
    "\n",
    "angles_all = []\n",
    "\n",
    "for W2 in Ws[1:]:\n",
    "    angles_rad = subspace_angles(W_ref, W2)   # radians, length = rank\n",
    "    angles_deg = np.degrees(angles_rad)\n",
    "    angles_all.append(angles_deg)\n",
    "\n",
    "angles_all = np.array(angles_all)  # shape (n_splits-1, rank)\n",
    "\n",
    "print('Principal angles (degrees) per split:')\n",
    "print(angles_all)\n",
    "\n",
    "print('\\nMean principal angle per dimension:')\n",
    "print(angles_all.mean(axis=0))\n",
    "\n",
    "print('\\nMean principal angle (overall):')\n",
    "print(angles_all.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# 3D projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = proj[:, :3]   # shape (T, 3)\n",
    "\n",
    "# Plot trajectory with time ordering\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot(\n",
    "    Z[:, 0],\n",
    "    Z[:, 1],\n",
    "    Z[:, 2],\n",
    "    linewidth=0.8,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Subspace dim 1')\n",
    "ax.set_ylabel('Subspace dim 2')\n",
    "ax.set_zlabel('Subspace dim 3')\n",
    "ax.set_title('Neural population trajectory (3D subspace)')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## peri-stop 3D trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_label_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_aligned = aligned_proj[:, :, :3]\n",
    "y = stop_label_df['will_retry'].to_numpy().astype(bool)\n",
    "\n",
    "mean_last = Z_aligned[y].mean(axis=0)     # (time, 3)\n",
    "mean_not  = Z_aligned[~y].mean(axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot(\n",
    "    mean_not[:, 0],\n",
    "    mean_not[:, 1],\n",
    "    mean_not[:, 2],\n",
    "    label='Not last retry'\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    mean_last[:, 0],\n",
    "    mean_last[:, 1],\n",
    "    mean_last[:, 2],\n",
    "    label='Last retry'\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    mean_not[0, 0], mean_not[0, 1], mean_not[0, 2],\n",
    "    marker='o', s=40\n",
    ")\n",
    "ax.scatter(\n",
    "    mean_last[0, 0], mean_last[0, 1], mean_last[0, 2],\n",
    "    marker='^', s=40\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Dim 1')\n",
    "ax.set_ylabel('Dim 2')\n",
    "ax.set_zlabel('Dim 3')\n",
    "ax.legend()\n",
    "ax.set_title('Peri-stop population trajectories')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Overlay trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_data_analysis.neural_analysis_tools.neural_axes import multivariate_axis_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(multivariate_axis_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = multivariate_axis_utils.plot_peri_event_trajectories_3d(\n",
    "    aligned_proj=aligned_proj,\n",
    "    labels=stop_label_df['last_retry'].to_numpy(),\n",
    "    dims=(0, 1, 2),\n",
    "    n_show=30,\n",
    "    colors=('tab:blue', 'tab:orange'),\n",
    "    labels_text=('Not last retry', 'Last retry'),\n",
    "    title='Peri-stop population trajectories'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Compute distance between condition means in subspace as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.linalg.norm(mean_last - mean_not, axis=1)\n",
    "\n",
    "# Bootstrap confidence interval (this is the key)\n",
    "n_boot = 1000\n",
    "boot_dist = np.zeros((n_boot, len(time)))\n",
    "\n",
    "idx_last = np.where(y)[0]\n",
    "idx_not  = np.where(~y)[0]\n",
    "\n",
    "for b in range(n_boot):\n",
    "    samp_last = np.random.choice(idx_last, size=len(idx_last), replace=True)\n",
    "    samp_not  = np.random.choice(idx_not,  size=len(idx_not),  replace=True)\n",
    "\n",
    "    mean_l = Z_aligned[samp_last].mean(axis=0)\n",
    "    mean_n = Z_aligned[samp_not].mean(axis=0)\n",
    "\n",
    "    boot_dist[b] = np.linalg.norm(mean_l - mean_n, axis=1)\n",
    "\n",
    "# Plot with error band\n",
    "low = np.percentile(boot_dist, 2.5, axis=0)\n",
    "high = np.percentile(boot_dist, 97.5, axis=0)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.fill_between(time, low, high, alpha=0.3)\n",
    "plt.plot(time, dist, color='k')\n",
    "plt.axvline(0, linestyle='--', color='k')\n",
    "plt.ylabel('Distance between condition means')\n",
    "plt.xlabel('Time from stop (s)')\n",
    "plt.title('Population separation with 95% CI')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## Axis-wise error bars (only for axis 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the dominant latent variable significantly different between conditions over time?\n",
    "\n",
    "axis1_last = Z_aligned[y, :, 0]\n",
    "axis1_not  = Z_aligned[~y, :, 0]\n",
    "\n",
    "mean_last = axis1_last.mean(axis=0)\n",
    "sem_last  = axis1_last.std(axis=0) / np.sqrt(axis1_last.shape[0])\n",
    "\n",
    "mean_not = axis1_not.mean(axis=0)\n",
    "sem_not  = axis1_not.std(axis=0) / np.sqrt(axis1_not.shape[0])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "plt.fill_between(time, mean_last-sem_last, mean_last+sem_last, alpha=0.3)\n",
    "plt.plot(time, mean_last, label='Last retry')\n",
    "\n",
    "plt.fill_between(time, mean_not-sem_not, mean_not+sem_not, alpha=0.3)\n",
    "plt.plot(time, mean_not, label='Not last retry')\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='k')\n",
    "plt.legend()\n",
    "plt.ylabel('Axis 1 projection')\n",
    "plt.xlabel('Time from stop (s)')\n",
    "plt.title('Axis 1 with SEM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## 2D confidence ellipses (for figures)\n",
    "\n",
    "This is for visualization, not statistics.\n",
    "\n",
    "What it shows is: Where does each condition live in subspace, and how variable is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "import numpy.linalg as LA\n",
    "\n",
    "def plot_cov_ellipse(mean, cov, ax, n_std=2.0, **kwargs):\n",
    "    vals, vecs = LA.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "    width, height = 2 * n_std * np.sqrt(vals)\n",
    "\n",
    "    ell = Ellipse(xy=mean, width=width, height=height,\n",
    "                  angle=theta, **kwargs)\n",
    "    ax.add_patch(ell)\n",
    "\n",
    "t0 = np.argmin(np.abs(time - 0.1))  # e.g. 100 ms post-stop\n",
    "\n",
    "X_last = Z_aligned[y, t0, :2]\n",
    "X_not  = Z_aligned[~y, t0, :2]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_not[:,0], X_not[:,1], alpha=0.3)\n",
    "ax.scatter(X_last[:,0], X_last[:,1], alpha=0.3)\n",
    "\n",
    "plot_cov_ellipse(X_not.mean(0), np.cov(X_not.T), ax, edgecolor='blue', fill=False)\n",
    "plot_cov_ellipse(X_last.mean(0), np.cov(X_last.T), ax, edgecolor='orange', fill=False)\n",
    "\n",
    "ax.set_xlabel('Dim 1')\n",
    "ax.set_ylabel('Dim 2')\n",
    "ax.set_title('Population states with covariance ellipses')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "# Planning vs execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_cols = [\n",
    "    'pre_stop',\n",
    "    'post_stop',\n",
    "    'retry',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "# Multitask linear with explicit interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = MultivariateAxisAnalyzer(\n",
    "    spikes_df=spikes_df,\n",
    "    events_df=stop_df,\n",
    "    behavior_df=trial_df,\n",
    "    event_col='stop_time',\n",
    "    behavior_cols=['retry', 'same_side', 'captured'],\n",
    ")\n",
    "\n",
    "axis_info = analyzer.compute_axes(\n",
    "    window_ms=(-200, 300),\n",
    "    interaction_pairs=[(0, 1), (0, 2)],\n",
    "    fit_backend='linear',\n",
    "    linear_method='mt_elasticnet',\n",
    "    alpha=1e-2,\n",
    "    l1_ratio=0.3,\n",
    ")\n",
    "\n",
    "W = axis_info['axes']\n",
    "proj = axis_info['projection']  # (T, n_targets_aug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "# Reduced-rank multitask (shared subspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_info = analyzer.compute_axes(\n",
    "    window_ms=(-200, 300),\n",
    "    interaction_pairs=[(0, 1)],\n",
    "    fit_backend='linear',\n",
    "    rank=3,\n",
    "    alpha=1.0,\n",
    ")\n",
    "\n",
    "proj = axis_info['projection']  # (T, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "# Nonlinear axes (MLP multi-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_info = analyzer.compute_axes(\n",
    "    window_ms=(-200, 300),\n",
    "    interaction_pairs=[(0, 1)],\n",
    "    fit_backend='nonlinear',\n",
    "    nonlinear_hidden=(64, 32),\n",
    "    nonlinear_alpha=1e-4,\n",
    ")\n",
    "\n",
    "proj = axis_info['projection']  # (T, n_targets_aug)\n",
    "project_fn = axis_info['project_fn']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "# CEBRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.behavior_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(cebra_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_data_analysis.neural_analysis_tools.neural_axes import cebra_analyzer\n",
    "\n",
    "analyzer = cebra_analyzer.CEBRAAnalyzer(\n",
    "    spikes_df=pn.spikes_df,\n",
    "    behavior_df=stop_label_df,\n",
    "    event_col='time',\n",
    "    behavior_cols=columns,\n",
    "    bin_width_ms=10,\n",
    ")\n",
    "\n",
    "embedding, model = analyzer.fit_cebra(\n",
    "    output_dim=3,\n",
    "    conditional='behavior',\n",
    "    max_iterations=8000,\n",
    ")\n",
    "\n",
    "aligned_embed, time = analyzer.extract_peri_event_embeddings(\n",
    "    window_ms=(-300, 500)\n",
    ")\n",
    "\n",
    "results = analyzer.permutation_test_peri_event_distance(\n",
    "    aligned_embed=aligned_embed,\n",
    "    labels=stop_label_df['last_retry'].to_numpy(),\n",
    "    n_perm=1000,\n",
    ")\n",
    "\n",
    "obs_dist = results['obs_dist']\n",
    "perm_dist = results['perm_dist']\n",
    "p_vals = results['p_values']\n",
    "p_global = results['p_global']\n",
    "\n",
    "low = np.percentile(perm_dist, 2.5, axis=0)\n",
    "high = np.percentile(perm_dist, 97.5, axis=0)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.fill_between(time, low, high, alpha=0.3, label='Permutation null (95%)')\n",
    "plt.plot(time, obs_dist, color='k', label='Observed')\n",
    "plt.axvline(0, linestyle='--', color='k')\n",
    "plt.xlabel('Time from stop (s)')\n",
    "plt.ylabel('Distance in CEBRA space')\n",
    "plt.legend()\n",
    "plt.title(f'Permutation test (global p = {p_global:.3g})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cebra\n",
    "print(cebra.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cebra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
