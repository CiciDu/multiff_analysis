{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "    \n",
    "from data_wrangling import specific_utils, process_monkey_information, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class, pn_aligned_by_seg, pn_aligned_by_event\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from machine_learning.ml_methods import regression_utils, regz_regression_utils, ml_methods_class, classification_utils, ml_plotting_utils, ml_methods_utils\n",
    "from planning_analysis.show_planning import nxt_ff_utils, show_planning_utils\n",
    "from neural_data_analysis.neural_analysis_tools.gpfa_methods import elephant_utils, fit_gpfa_utils, plot_gpfa_utils, gpfa_helper_class\n",
    "from neural_data_analysis.neural_analysis_tools.align_trials import time_resolved_regression, time_resolved_gpfa_regression,plot_time_resolved_regression\n",
    "from neural_data_analysis.neural_analysis_tools.align_trials import align_trial_utils\n",
    "from decision_making_analysis.compare_GUAT_and_TAFT import find_GUAT_or_TAFT_trials\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_psth import core_stops_psth, get_stops_utils, psth_postprocessing, psth_stats, compare_events, dpca_utils\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm import binning_for_glm, stop_glm_fit, cv_stop_glm, lagged_design, stop_design\n",
    "\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "# To fit gpfa\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "from elephant.gpfa import GPFA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from elephant.gpfa import gpfa_core, gpfa_util\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0413\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0321\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0329\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0403\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0312\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0316\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0327\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_y_var_lags = False\n",
    "planning_data_by_point_exists_ok = True\n",
    "y_data_exists_ok = True\n",
    "\n",
    "pn = pn_aligned_by_event.PlanningAndNeuralEventAligned(raw_data_folder_path=raw_data_folder_path)\n",
    "pn.prep_data_to_analyze_planning(planning_data_by_point_exists_ok=planning_data_by_point_exists_ok)\n",
    "# pn.planning_data_by_point, cols_to_drop = general_utils.drop_columns_with_many_nans(\n",
    "#     pn.planning_data_by_point)\n",
    "#pn.get_x_and_y_data_for_modeling(exists_ok=y_data_exists_ok, reduce_y_var_lags=reduce_y_var_lags)\n",
    "\n",
    "if not hasattr(pn, 'spikes_df'):\n",
    "    pn.retrieve_or_make_monkey_data()\n",
    "    pn.spikes_df = neural_data_processing.make_spikes_df(pn.raw_data_folder_path, pn.ff_caught_T_sorted,\n",
    "                                                            sampling_rate=pn.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# NEXT: try stop end time instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Get captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(get_stops_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example wiring (mirrors your original usage)\n",
    "valid_captures_df, filtered_no_capture_stops_df, stops_with_stats = get_stops_utils.prepare_no_capture_and_captures(\n",
    "    monkey_information=pn.monkey_information,\n",
    "    closest_stop_to_capture_df=pn.closest_stop_to_capture_df,\n",
    "    ff_caught_T_new=pn.ff_caught_T_new,\n",
    "    min_stop_duration=0.01,\n",
    "    max_stop_duration=1.0,\n",
    "    capture_match_window=0.3,\n",
    "    distance_thresh=25.0,\n",
    "    distance_col=\"distance_from_ff_to_stop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stop_id' not in pn.closest_stop_to_capture_df.columns:\n",
    "    pn.closest_stop_to_capture_df = get_stops_utils.add_stop_id_to_closest_stop_to_capture_df(\n",
    "        pn.closest_stop_to_capture_df,\n",
    "        pn.monkey_information,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.monkey_information.loc[17730:17740]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.monkey_information[pn.monkey_information['monkey_speeddummy']==0].loc[17730:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.closest_stop_to_capture_df[pn.closest_stop_to_capture_df['stop_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.closest_stop_to_capture_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stops_with_stats.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Get misses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "##  one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = [\"stop_id\", \"stop_id_duration\", \"stop_id_start_time\", \"stop_id_end_time\"]\n",
    "\n",
    "pn.make_one_stop_w_ff_df()\n",
    "one_stop_miss_df = pn.one_stop_w_ff_df[['first_stop_point_index', 'first_stop_time', 'latest_visible_ff', 'ff_distance', 'min_distance_from_adjacent_stops']].copy()\n",
    "one_stop_miss_df.rename(columns={'first_stop_point_index': 'stop_point_index', 'first_stop_time': 'stop_time'}, inplace=True)\n",
    "one_stop_miss_df[columns_to_add] = pn.monkey_information.loc[one_stop_miss_df['stop_point_index'], columns_to_add].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.get_try_a_few_times_info()\n",
    "pn.get_give_up_after_trying_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = [\"stop_id\", \"stop_id_duration\", \"stop_id_start_time\", \"stop_id_end_time\"]\n",
    "shared_columns = [\"stop_point_index\", \"stop_time\"] + columns_to_add\n",
    "\n",
    "# --- Build expanded + ordered tables for GUAT / TAFT ---\n",
    "GUAT_expanded = get_stops_utils._expand_trials(pn.GUAT_trials_df, pn.monkey_information)\n",
    "TAFT_expanded = get_stops_utils._expand_trials(pn.TAFT_trials_df, pn.monkey_information)\n",
    "\n",
    "# add stop_id to GUAT_trials_df and TAFT_trials_df\n",
    "GUAT_expanded[columns_to_add] = pn.monkey_information.loc[GUAT_expanded['stop_point_index'], columns_to_add].values\n",
    "TAFT_expanded[columns_to_add] = pn.monkey_information.loc[TAFT_expanded['stop_point_index'], columns_to_add].values\n",
    "\n",
    "\n",
    "GUAT = get_stops_utils._add_cluster_ordering(GUAT_expanded)\n",
    "TAFT = get_stops_utils._add_cluster_ordering(TAFT_expanded)\n",
    "\n",
    "# --- Per-cluster slices (consistent, vectorized) ---\n",
    "# First stop in each cluster\n",
    "GUAT_first = GUAT[GUAT[\"is_first\"]].reset_index(drop=True)\n",
    "TAFT_first = TAFT[TAFT[\"is_first\"]].reset_index(drop=True)\n",
    "\n",
    "# Last stop in each cluster\n",
    "giveup_GUAT_last = GUAT[GUAT[\"is_last\"]].reset_index(drop=True)\n",
    "capture_TAFT_last = TAFT[TAFT[\"is_last\"]].reset_index(drop=True)\n",
    "\n",
    "# Middle stops (exclude first and last)\n",
    "GUAT_middle = GUAT[GUAT[\"is_middle\"]].reset_index(drop=True)\n",
    "TAFT_middle = TAFT[TAFT[\"is_middle\"]].reset_index(drop=True)\n",
    "\n",
    "# “First several” = all but the last stop in each cluster\n",
    "persist_GUAT_nonfinal = GUAT[GUAT[\"order_in_cluster\"] < GUAT[\"cluster_size\"] - 1].reset_index(drop=True)\n",
    "persist_TAFT_nonfinal = TAFT[TAFT[\"order_in_cluster\"] < TAFT[\"cluster_size\"] - 1].reset_index(drop=True)\n",
    "\n",
    "# Combine the “first several” from both, keep only columns you care about, then sort by index\n",
    "both_nonfinal = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            persist_GUAT_nonfinal[shared_columns],\n",
    "            persist_TAFT_nonfinal[shared_columns],\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    .sort_values(\"stop_point_index\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "persist_both_first = pd.concat([GUAT_first[shared_columns], \n",
    "                         TAFT_first[shared_columns]])\n",
    "\n",
    "both_middle = pd.concat([GUAT_middle[shared_columns], \n",
    "                         TAFT_middle[shared_columns]])\n",
    "\n",
    "# Optional: if you also want “last several” (all but the first), it’s symmetrical:\n",
    "# giveup_GUAT_last_several = GUAT[GUAT[\"order_in_cluster\"] > 0].reset_index(drop=True)\n",
    "# capture_TAFT_last_several = TAFT[TAFT[\"order_in_cluster\"] > 0].reset_index(drop=True)\n",
    "\n",
    "giveup_GUAT_last_plus_single_miss = pd.concat([giveup_GUAT_last[shared_columns], \n",
    "                                         one_stop_miss_df[shared_columns]])\n",
    "\n",
    "all_misses = pd.concat([one_stop_miss_df[shared_columns], \n",
    "                                         GUAT_expanded[shared_columns],\n",
    "                                         persist_TAFT_nonfinal[shared_columns]\n",
    "                                         ])\n",
    "\n",
    "all_first_misses = pd.concat(\n",
    "    [one_stop_miss_df[shared_columns], GUAT_first[shared_columns], TAFT_first[shared_columns]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# captures not in TAFT last (assuming capture_TAFT_last is a subset of captures)\n",
    "captures_minus_TAFT_last = compare_events.diff_by(valid_captures_df, capture_TAFT_last, key='stop_id')\n",
    "\n",
    "# non-captures excluding those flagged as 'all_misses'\n",
    "non_captures_minus_all_misses = compare_events.diff_by(filtered_no_capture_stops_df, all_misses, key='stop_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# ===COMPARE EVENTS==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- dataset registry (canonical) ----------\n",
    "datasets_raw = {\n",
    "    'captures': valid_captures_df.copy(),\n",
    "    'no_capture': filtered_no_capture_stops_df.copy(),\n",
    "    'persist_nonfinal': both_nonfinal.copy(),\n",
    "    'persist_middle': both_middle.copy(),\n",
    "    'giveup_GUAT_last': giveup_GUAT_last.copy(),\n",
    "    'capture_TAFT_last': capture_TAFT_last.copy(),\n",
    "    'giveup_single_miss': one_stop_miss_df.copy(),\n",
    "    'persist_both_first': persist_both_first.copy(),\n",
    "    'persist_GUAT_nonfinal': persist_GUAT_nonfinal.copy(),\n",
    "    'persist_TAFT_nonfinal': persist_TAFT_nonfinal.copy(),\n",
    "    'giveup_GUAT_last_plus_single_miss': giveup_GUAT_last_plus_single_miss.copy(),\n",
    "    'captures_minus_TAFT_last': captures_minus_TAFT_last.copy(),\n",
    "    'all_misses': all_misses.copy(),\n",
    "    'non_captures_minus_all_misses': non_captures_minus_all_misses.copy(),\n",
    "    'all_first_misses': all_first_misses.copy(),\n",
    "}\n",
    "\n",
    "# normalize schema + dedupe within each dataset\n",
    "datasets = {k: compare_events.dedupe_within(compare_events.ensure_event_schema(v)) for k, v in datasets_raw.items()}\n",
    "\n",
    "comparisons = compare_events.build_comparisons([\n",
    "    {'a': 'captures', 'b': 'no_capture', 'key': 'captures_vs_no_capture'},\n",
    "\n",
    "    {'a': 'persist_nonfinal', 'b': 'giveup_GUAT_last'},\n",
    "    {'a': 'persist_middle',  'b': 'giveup_GUAT_last'},\n",
    "\n",
    "    {'a': 'persist_nonfinal', 'b': 'giveup_GUAT_last_plus_single_miss'},\n",
    "    {'a': 'persist_middle',   'b': 'giveup_GUAT_last_plus_single_miss'},\n",
    "\n",
    "    {'a': 'giveup_single_miss', 'b': 'giveup_GUAT_last'},\n",
    "    {'a': 'giveup_single_miss', 'b': 'persist_both_first'},\n",
    "\n",
    "    {'a': 'persist_GUAT_nonfinal', 'b': 'persist_TAFT_nonfinal'},\n",
    "\n",
    "    {'a': 'giveup_GUAT_last', 'b': 'capture_TAFT_last'},\n",
    "\n",
    "    {'a': 'captures_minus_TAFT_last', 'b': 'capture_TAFT_last'},\n",
    "\n",
    "    {'a': 'captures', 'b': 'all_misses'},\n",
    "\n",
    "    {'a': 'non_captures_minus_all_misses', 'b': 'all_misses'},\n",
    "    {'a': 'non_captures_minus_all_misses', 'b': 'all_first_misses'},\n",
    "])\n",
    "\n",
    "\n",
    "compare_events.validate(datasets, comparisons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# new_seg_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_with_stats['stop_time'] = stops_with_stats['stop_id_start_time']\n",
    "stops_with_stats['prev_time'] = stops_with_stats['stop_id_end_time'].shift(1)\n",
    "stops_with_stats['next_time'] = stops_with_stats['stop_id_start_time'].shift(-1)\n",
    "new_seg_info = binning_for_glm.pick_stop_window(stops_with_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Get bin info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build bins from your stop windows (gaps allowed)\n",
    "bins_2d, meta = binning_for_glm.stops_windows_to_bins2d(new_seg_info, bin_dt=0.04, only_ok=False)\n",
    "\n",
    "# 2) Get overlap assignments once\n",
    "sample_idx, bin_idx_array, dt_array, n_bins = binning_for_glm.build_bin_assignments(\n",
    "    pn.monkey_information['time'].to_numpy(),\n",
    "    bins_2d,\n",
    ")\n",
    "\n",
    "# 3) Subselect raw samples once\n",
    "monkey_information_sub = pn.monkey_information.iloc[sample_idx].copy()\n",
    "\n",
    "# 3a) One pass to get exposure and used_bins\n",
    "_dummy, exposure, used_bins = binning_for_glm.bin_timeseries_weighted(\n",
    "    monkey_information_sub['time'].to_numpy(),  # any column of same length works\n",
    "    dt_array, bin_idx_array, how='mean'\n",
    ")\n",
    "\n",
    "# 3b) Aggregate features with the SAME assignments\n",
    "def agg_feat(col):\n",
    "    vals = monkey_information_sub[col].to_numpy()\n",
    "    out, _exp, _ub = binning_for_glm.bin_timeseries_weighted(vals, dt_array, bin_idx_array, how='mean')\n",
    "    # Defensive checks: exposure/used_bins should match\n",
    "    assert np.shares_memory(_exp, exposure) or np.allclose(_exp, exposure)\n",
    "    assert np.array_equal(_ub, used_bins)\n",
    "    return out\n",
    "\n",
    "binned_feats = pd.DataFrame({\n",
    "    'accel':     agg_feat('accel'),\n",
    "    'speed':     agg_feat('speed'),\n",
    "    'ang_speed': agg_feat('ang_speed'),\n",
    "})\n",
    "\n",
    "# Clean NaNs (optional: choose your policy)\n",
    "binned_feats = binned_feats.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "# 3c) Keep bins with exposure > 0\n",
    "mask_used = exposure > 0\n",
    "pos = used_bins[mask_used]\n",
    "offset_log = np.log(np.clip(exposure[mask_used], 1e-12, None))\n",
    "\n",
    "binned_feats = binned_feats.iloc[mask_used].reset_index(drop=True)\n",
    "binned_feats['offset_log'] = offset_log\n",
    "\n",
    "# 4) Bin spikes per cluster across ALL bins, then slice by pos\n",
    "spike_counts, cluster_ids = binning_for_glm.bin_spikes_by_cluster(\n",
    "    pn.spikes_df, bins_2d, time_col='time', cluster_col='cluster'\n",
    ")\n",
    "\n",
    "# Sanity checks\n",
    "assert pos.size == binned_feats.shape[0]\n",
    "assert spike_counts.shape[0] >= (pos.max() + 1)\n",
    "\n",
    "binned_spikes = pd.DataFrame(\n",
    "    spike_counts[pos, :],        # slice rows to align with pos\n",
    "    columns=cluster_ids,         # cluster IDs as column labels\n",
    ").reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "# Add stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X: predictors + offset (e.g., ['speed_z', 'accel_z', 'offset_log'])\n",
    "# df_Y: responses per unit (e.g., columns = unit IDs)\n",
    "\n",
    "features = ['ang_speed']\n",
    "df_X = binned_feats[features + ['offset_log']]\n",
    "df_Y = binned_spikes\n",
    "\n",
    "\n",
    "report = stop_glm_fit.glm_mini_report(\n",
    "    df_X,\n",
    "    df_Y,\n",
    "    offset_col='offset_log',\n",
    "    feature_names=None,       # infer automatically from df_X\n",
    "    cluster_ids=None,         # use df_Y.columns\n",
    "    alpha=0.05,\n",
    "    delta_for_rr=1.0,\n",
    "    forest_term='ang_speed',         # defaults to first feature\n",
    "    forest_top_n=30,\n",
    "    add_intercept=True,\n",
    "    cov_type='HC1',\n",
    "    show_plots=True,\n",
    "    save_dir=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = 5\n",
    "cv_stop_glm.plot_pred_vs_obs(report['results'][cluster_id], binned_feats[features], binned_spikes[cluster_id], binned_feats['offset_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df    = report['coefs_df']\n",
    "metrics_df  = report['metrics_df']\n",
    "pop_tests   = report['population_tests_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = meta['stop_id']  # or your session/stop-window IDs\n",
    "scores = cv_stop_glm.glm_mini_report_batch(binned_feats, binned_spikes, groups, n_splits=5)\n",
    "cv_stop_glm.plot_cv_scores(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "# new new_seg_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_new_seg_info_from_stops(stops_with_stats: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the per-stop table expected by build_stop_design_from_meta from your\n",
    "    stops_with_stats, carrying through any capture/reward columns if present.\n",
    "\n",
    "    Expected columns (present in your example):\n",
    "      - 'stop_id'\n",
    "      - 'time' or 'stop_id_start_time' (interpreted as stop_time)\n",
    "      - 'stop_id_duration' (interpreted as duration)\n",
    "\n",
    "    Optional columns (carried through if present):\n",
    "      - 'captured', 'rewarded', 'reward_size'\n",
    "      - 'cond' (if you ever add one later)\n",
    "      - 'trial_id' / 'session_id' (kept for your own bookkeeping)\n",
    "    \"\"\"\n",
    "    df = stops_with_stats.copy()\n",
    "\n",
    "    # pick stop_time from the columns you have\n",
    "    if 'time' in df.columns:\n",
    "        df['stop_time'] = df['time'].astype(float)\n",
    "    elif 'stop_id_start_time' in df.columns:\n",
    "        df['stop_time'] = df['stop_id_start_time'].astype(float)\n",
    "    else:\n",
    "        raise ValueError('need a stop time column: expected \"time\" or \"stop_id_start_time\"')\n",
    "\n",
    "    # map duration\n",
    "    if 'stop_id_duration' in df.columns:\n",
    "        df['duration'] = df['stop_id_duration'].astype(float)\n",
    "    elif {'stop_id_start_time', 'stop_id_end_time'}.issubset(df.columns):\n",
    "        df['duration'] = (df['stop_id_end_time'] - df['stop_id_start_time']).astype(float)\n",
    "    else:\n",
    "        df['duration'] = np.nan  # ok; the helper will handle NaNs\n",
    "\n",
    "    keep = ['stop_id', 'stop_time', 'duration']\n",
    "    # carry capture/reward if present\n",
    "    for opt in ['captured', 'rewarded', 'reward_size', 'cond', 'trial_id', 'session_id']:\n",
    "        if opt in df.columns:\n",
    "            keep.append(opt)\n",
    "\n",
    "    new_seg_info = df[keep].drop_duplicates('stop_id').sort_values('stop_time').reset_index(drop=True)\n",
    "\n",
    "    # sanity\n",
    "    assert new_seg_info['stop_id'].is_unique, 'stop_id must be unique in new_seg_info'\n",
    "    return new_seg_info\n",
    "\n",
    "# --- usage ---------------------------------------------------------------\n",
    "\n",
    "# 1) Build per-stop table from your stops_with_stats\n",
    "new_seg_info = make_new_seg_info_from_stops(stops_with_stats)\n",
    "\n",
    "# 2) Build the stop-aware design block (same helper we wrote earlier)\n",
    "X_stop, X_stop_names = stop_design.build_stop_design_from_meta(\n",
    "    meta=meta,\n",
    "    pos=pos,\n",
    "    new_seg_info=new_seg_info,\n",
    "    speed_used=binned_feats['speed'].values,\n",
    "    history_mode='gated',  # or 'single' / 'sumdiff'\n",
    "    include_columns=(\n",
    "        'basis', 'duration_z', 'history_gated',\n",
    "        'captured', 'basis*captured',\n",
    "        'rewarded_post', 'reward_size_z_post'\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3) Append to your existing design\n",
    "X = np.column_stack([X, X_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(stop_design)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# stop design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Across-stop history terms (e.g., time_since_prev_stop_z): you need the ordered list of stop times, preferably as a per-stop table (new_seg_info with one row per stop). You can derive this from meta (see helper below).\n",
    "\n",
    "Capture / reward: per-stop columns like captured (0/1), rewarded (0/1), reward_size (float). These live on new_seg_info (not in meta), then get broadcast to bins by stop_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stop_df = stop_design.build_stop_design_from_meta(\n",
    "    meta=meta, pos=pos, new_seg_info=new_seg_info,\n",
    "    speed_used=binned_feats['speed'].values,\n",
    "    history_mode='gated',\n",
    "    include_columns=('basis','duration_z','history_gated','captured','basis*captured',\n",
    "                     'rewarded_post','reward_size_z_post')\n",
    ")\n",
    "# X = np.column_stack([X, X_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## lean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stop, names = build_stop_design_from_meta(\n",
    "    meta=meta,\n",
    "    pos=pos,\n",
    "    new_seg_info=new_seg_info,\n",
    "    speed_used=binned_feats['speed'].values,\n",
    "    include_columns=(\n",
    "        'prepost',\n",
    "        'duration_z',\n",
    "        'time_since_prev_stop_z',   # choose ONE: prev OR next\n",
    "        'cond_dummies',\n",
    "    ),\n",
    "    add_interactions=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "## Shape-aware (captures peri-stop dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stop, names = build_stop_design_from_meta(\n",
    "    meta=meta,\n",
    "    pos=pos,\n",
    "    new_seg_info=new_seg_info,\n",
    "    speed_used=binned_feats['speed'].values,\n",
    "    include_columns=(\n",
    "        'basis',                    # replaces prepost\n",
    "        'duration_z',\n",
    "        'time_since_prev_stop_z',   # or 'time_to_next_stop_z'\n",
    "        'cond_dummies',\n",
    "        'prepost*speed'             # optional; keeps a single interpretable interaction\n",
    "    ),\n",
    "    add_interactions=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build stop-aware block, aligned to your fitted rows\n",
    "X_stop_df = stop_design.build_stop_design_from_meta(\n",
    "    meta=meta,                   # the DataFrame you showed\n",
    "    pos=pos,                     # global bin indices you fit (mask_used -> positions)\n",
    "    new_seg_info=new_seg_info,   # per-stop table (must have stop_id, stop_time)\n",
    "    speed_used=binned_feats['speed'].values, # already aligned to pos\n",
    "    rc_width=0.10,               # ~200 ms support per bump\n",
    "    add_interactions=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stop_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(binned_feats) == len(X_stop_df)\n",
    "cols_to_add = [c for c in X_stop_df.columns if c not in binned_feats.columns]\n",
    "binned_feats.loc[:, cols_to_add] = X_stop_df[cols_to_add].to_numpy()  # equivalent to .values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "# Lagged design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## discrete lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose window and binning\n",
    "lag_min_s, lag_max_s, bin_dt = -0.30, 0.40, 0.02\n",
    "lags = lagged_design.make_integer_lags(lag_min_s, lag_max_s, bin_dt)\n",
    "\n",
    "df_X_design, df_Y_aligned = lagged_design.build_lagged_design_by_group(\n",
    "    df_X=binned_feats,\n",
    "    df_Y=binned_spikes,\n",
    "    group_col='stop_id',\n",
    "    predictors=['speed', 'accel', 'ang_speed'],\n",
    "    offset_col='offset_log',\n",
    "    order_col='time',             # optional: if you have a time column\n",
    "    lags_bins=lags,\n",
    "    basis_df=None,\n",
    "    add_intercept=True,\n",
    "    standardize=True,             # z-score features\n",
    "    standardize_within_group=False,\n",
    "    keep_cols=['session_id']      # optional passthrough\n",
    ")\n",
    "\n",
    "results, coefs_df, metrics_df = lagged_design.fit_poisson_glm_per_cluster_df(\n",
    "    df_X_design, df_Y_aligned,\n",
    "    offset_col='offset_log',\n",
    "    add_intercept=False,          # already added by builder\n",
    "    cov_type='HC1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "## raised-cosine basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = make_raised_cosine_basis(\n",
    "    n_basis=6,\n",
    "    lag_min_s=-0.30,\n",
    "    lag_max_s=0.40,\n",
    "    bin_dt=0.02\n",
    ")\n",
    "\n",
    "df_X_basis, df_Y_aligned = build_lagged_design_by_group(\n",
    "    df_X=df_X,\n",
    "    df_Y=df_Y,\n",
    "    group_col='stop_id',\n",
    "    predictors=['speed_z', 'accel_z'],\n",
    "    offset_col='offset_log',\n",
    "    order_col='time',\n",
    "    lags_bins=None,\n",
    "    basis_df=basis,\n",
    "    add_intercept=True,\n",
    "    standardize=True,\n",
    "    standardize_within_group=False\n",
    ")\n",
    "\n",
    "results, coefs_df, metrics_df = fit_poisson_glm_per_cluster_df(\n",
    "    df_X_basis, df_Y_aligned,\n",
    "    offset_col='offset_log',\n",
    "    add_intercept=False,\n",
    "    cov_type='HC1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## hyper-param tuning on binwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def cv_glm_per_second_loglik(X, y, offset, groups, n_splits=5):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    ll, T = 0.0, 0.0  # total loglik and total time (s)\n",
    "    for tr, te in gkf.split(X, y, groups):\n",
    "        fit = sm.GLM(y.iloc[tr], sm.add_constant(X.iloc[tr], has_constant='add'),\n",
    "                     family=sm.families.Poisson(), offset=offset.iloc[tr]).fit()\n",
    "        mu = np.clip(fit.predict(sm.add_constant(X.iloc[te], has_constant='add'),\n",
    "                                 offset=offset.iloc[te]), 1e-12, None)\n",
    "        # Poisson log-likelihood up to constant terms\n",
    "        ll += float(np.sum(y.iloc[te] * np.log(mu) - mu))\n",
    "        T  += float(np.sum(np.exp(offset.iloc[te])))  # since offset=log(dt), sum dt = total seconds\n",
    "    return ll / T  # loglik per second\n",
    "\n",
    "def evaluate_bin_grid(binned_by_dt, feature_cols, target_col='spike_count',\n",
    "                      offset_col='bin_dt', group_col='stop_cluster_id'):\n",
    "    rows = []\n",
    "    for dt, df in binned_by_dt.items():  # dict: {0.016: df16ms, 0.024: df24ms, ...}\n",
    "        use = df['stop_id'].notna()\n",
    "        if 'straddle_stop_boundary' in df.columns:\n",
    "            use &= ~df['straddle_stop_boundary']\n",
    "        X = df.loc[use, feature_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0).astype(float)\n",
    "        y = df.loc[use, target_col].astype(float)\n",
    "        offset = np.log(df.loc[use, offset_col].astype(float))\n",
    "        groups = df.loc[use, group_col] if group_col in df else pd.Series(np.arange(X.shape[0]))\n",
    "        per_s = cv_glm_per_second_loglik(X, y, offset, groups)\n",
    "        rows.append({'dt_s': float(dt), 'bins_per_s': 1.0/float(dt), 'cv_loglik_per_s': per_s})\n",
    "    out = pd.DataFrame(rows).sort_values('dt_s')\n",
    "    out['rank'] = out['cv_loglik_per_s'].rank(ascending=False, method='min').astype(int)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## Debug ff dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.make_or_retrieve_ff_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.ff_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.ff_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file_pathway = os.path.join(os.path.join(\n",
    "    pn.processed_data_folder_path, 'ff_dataframe.h5'))\n",
    "\n",
    "h5_file_pathway = 'all_monkey_data/processed_data/monkey_Schro/data_0413/ff_dataframe.h5'\n",
    "\n",
    "ff_dataframe = pd.read_hdf(h5_file_pathway, 'ff_dataframe')\n",
    "print(\"Retrieved ff_dataframe from\", h5_file_pathway)\n",
    "ff_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "## use concat_new_seg_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg_info['new_segment'] = np.arange(len(new_seg_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_seg_data = pn_utils.concat_new_seg_info(\n",
    "    pn.monkey_information, new_seg_info, bin_width=0.04)\n",
    "\n",
    "concat_seg_data['time_since_start_time'] = concat_seg_data['time'] - concat_seg_data['new_seg_start_time']\n",
    "concat_seg_data['dt'] = np.minimum(concat_seg_data['time_since_start_time'], concat_seg_data['dt'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
