{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "    \n",
    "from data_wrangling import specific_utils, process_monkey_information, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class, pn_aligned_by_seg, pn_aligned_by_event\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from machine_learning.ml_methods import regression_utils, regz_regression_utils, ml_methods_class, classification_utils, ml_plotting_utils, ml_methods_utils\n",
    "from planning_analysis.show_planning import nxt_ff_utils, show_planning_utils\n",
    "from neural_data_analysis.neural_analysis_tools.gpfa_methods import elephant_utils, fit_gpfa_utils, plot_gpfa_utils, gpfa_helper_class\n",
    "from neural_data_analysis.neural_analysis_tools.align_trials import time_resolved_regression, time_resolved_gpfa_regression,plot_time_resolved_regression\n",
    "from neural_data_analysis.neural_analysis_tools.align_trials import align_trial_utils\n",
    "from decision_making_analysis.compare_GUAT_and_TAFT import find_GUAT_or_TAFT_trials\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_psth import core_stops_psth, get_stops_utils, psth_postprocessing, psth_stats, compare_events, dpca_utils\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_fit import stop_glm_fit, cv_stop_glm, glm_fit_utils, variance_explained\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_plotting import plot_spikes, plot_glm_fit, plot_tuning_func\n",
    "from neural_data_analysis.design_kits.design_around_event import event_binning, stop_design, cluster_design, design_checks\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_hyperparams import compare_glm_configs, glm_hyperparams_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.ff_visibility import ff_vis_epochs, vis_design\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.glm_decoding_tools import glm_decoding_llr, glmglm_decoding_llrglm_decoding_llrglm_decoding_llr\n",
    "\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "# To fit gpfa\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "from elephant.gpfa import GPFA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from elephant.gpfa import gpfa_core, gpfa_util\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0413\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0321\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0329\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0403\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\"\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0312\"\n",
    "\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0316\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0327\"\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_y_var_lags = False\n",
    "planning_data_by_point_exists_ok = True\n",
    "y_data_exists_ok = True\n",
    "\n",
    "pn = pn_aligned_by_event.PlanningAndNeuralEventAligned(raw_data_folder_path=raw_data_folder_path)\n",
    "pn.prep_data_to_analyze_planning(planning_data_by_point_exists_ok=planning_data_by_point_exists_ok)\n",
    "\n",
    "if not hasattr(pn, 'spikes_df'):\n",
    "    pn.retrieve_or_make_monkey_data()\n",
    "    pn.spikes_df = neural_data_processing.make_spikes_df(pn.raw_data_folder_path, pn.ff_caught_T_sorted,\n",
    "                                                            sampling_rate=pn.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# FF visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.make_or_retrieve_ff_dataframe()\n",
    "df = pn.ff_dataframe.copy()\n",
    "\n",
    "# minimal: detect runs, no merging (each run is its own cluster)\n",
    "df2 = ff_vis_epochs.compute_visibility_runs_and_clusters(\n",
    "    df, ff_col='ff_index', t_col='point_index', time_col='time', vis_col='visible',\n",
    "    chunk_merge_gap=0.05,    # seconds: merge *raw* runs into chunks if gap <= this\n",
    "    cluster_merge_gap=1\n",
    ")\n",
    "\n",
    "df2 = ff_vis_epochs.add_global_visibility_bursts(df2, global_merge_gap=0.25)\n",
    "#df2 = ff_vis_epochs.add_global_vis_cluster_id(df2, group_cols=None, nullable_int=True)\n",
    "df2 = ff_vis_epochs.add_global_vis_chunk_id(df2, group_cols=None, nullable_int=True)\n",
    "#df2 = ff_vis_epochs.add_global_vis_cluster_id(df2, group_cols=None, nullable_int=True)\n",
    "\n",
    "vis_df = df2.loc[df2['visible'] == 1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on any ff visible\n",
    "sequential_vis_df = vis_df[['ff_index', 'ff_vis_start_time', 'ff_vis_end_time',\n",
    "                           'global_vis_chunk_id', 'global_burst_id', 'global_burst_start_time','global_burst_end_time',\n",
    "                           'global_burst_duration','global_burst_size',\n",
    "                           #'global_burst_prev_start_time','global_burst_prev_end_time'\n",
    "                           ]].drop_duplicates().reset_index(drop=True)\n",
    "sequential_vis_df = sequential_vis_df.sort_values('ff_vis_start_time').reset_index(drop=True)\n",
    "sequential_vis_df['prev_time'] = sequential_vis_df['ff_vis_start_time'].shift(1)\n",
    "sequential_vis_df['next_time'] = sequential_vis_df['ff_vis_start_time'].shift(-1)\n",
    "\n",
    "\n",
    "new_seg_info = event_binning.pick_event_window(sequential_vis_df,\n",
    "                                                event_time_col='ff_vis_start_time',\n",
    "                                                prev_event_col='prev_time',\n",
    "                                                next_event_col='next_time',\n",
    "                                                pre_s=1, post_s=1.0, min_pre_bins=3, min_post_bins=3, bin_dt=0.04)\n",
    "new_seg_info['event_id'] = new_seg_info['global_vis_chunk_id']\n",
    "new_seg_info['event_time'] = new_seg_info['ff_vis_start_time']\n",
    "new_seg_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_with_stats = sequential_vis_df[['global_vis_chunk_id', 'global_burst_id', 'ff_vis_start_time', 'ff_vis_end_time']].copy()\n",
    "events_with_stats = sequential_vis_df.rename(columns={'global_vis_chunk_id': 'event_id', \n",
    "                                           'global_burst_id': 'event_cluster_id', \n",
    "                                           'ff_vis_start_time': 'event_id_start_time', \n",
    "                                           'ff_vis_end_time': 'event_id_end_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_with_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Prepare for GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## binned_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(event_binning)\n",
    "reload(stop_design)\n",
    "reload(cluster_design)\n",
    "reload(design_checks)\n",
    "reload(stop_glm_fit)\n",
    "reload(glm_fit_utils)\n",
    "reload(cv_stop_glm)\n",
    "reload(plot_tuning_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build bins from your event windows (gaps allowed)\n",
    "bin_dt = 0.04\n",
    "bins_2d, meta = event_binning.event_windows_to_bins2d(new_seg_info, bin_dt=bin_dt, only_ok=False)\n",
    "\n",
    "# 2) Get overlap assignments once\n",
    "sample_idx, bin_idx_array, dt_array, n_bins = event_binning.build_bin_assignments(\n",
    "    pn.monkey_information['time'].to_numpy(),\n",
    "    bins_2d,\n",
    ")\n",
    "\n",
    "# 3) Subselect raw samples once\n",
    "monkey_information_sub = pn.monkey_information.iloc[sample_idx].copy()\n",
    "\n",
    "# 3a) One pass to get exposure and used_bins\n",
    "_dummy, exposure, used_bins = event_binning.bin_timeseries_weighted(\n",
    "    monkey_information_sub['time'].to_numpy(),  # any column of same length works\n",
    "    dt_array, bin_idx_array, how='mean'\n",
    ")\n",
    "\n",
    "# 3b) Aggregate features with the SAME assignments\n",
    "def agg_feat(col):\n",
    "    vals = monkey_information_sub[col].to_numpy()\n",
    "    out, _exp, _ub = event_binning.bin_timeseries_weighted(vals, dt_array, bin_idx_array, how='mean')\n",
    "    # Defensive checks: exposure/used_bins should match\n",
    "    assert np.shares_memory(_exp, exposure) or np.allclose(_exp, exposure)\n",
    "    assert np.array_equal(_ub, used_bins)\n",
    "    return out\n",
    "\n",
    "binned_feats = pd.DataFrame({\n",
    "    'accel':     agg_feat('accel'),\n",
    "    'speed':     agg_feat('speed'),\n",
    "    'ang_speed': agg_feat('ang_speed'),\n",
    "})\n",
    "\n",
    "# Clean NaNs (optional: choose your policy)\n",
    "binned_feats = binned_feats.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "# 3c) Keep bins with exposure > 0\n",
    "mask_used = exposure > 0\n",
    "pos = used_bins[mask_used]\n",
    "binned_feats = binned_feats.iloc[mask_used].reset_index(drop=True)\n",
    "\n",
    "meta_by_bin = meta.set_index('bin').sort_index()\n",
    "meta_used   = meta_by_bin.loc[pos].reset_index()   # rows now match binned_feats \n",
    "\n",
    "\n",
    "# 4) Bin spikes per cluster across ALL bins, then slice by pos\n",
    "spike_counts, cluster_ids = event_binning.bin_spikes_by_cluster(\n",
    "    pn.spikes_df, bins_2d, time_col='time', cluster_col='cluster'\n",
    ")\n",
    "\n",
    "# Sanity checks\n",
    "assert pos.size == binned_feats.shape[0]\n",
    "assert spike_counts.shape[0] >= (pos.max() + 1)\n",
    "\n",
    "binned_spikes = pd.DataFrame(\n",
    "    spike_counts[pos, :],        # slice rows to align with pos\n",
    "    columns=cluster_ids,         # cluster IDs as column labels\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Build the stop-aware design block (same helper we wrote earlier)\n",
    "X_event_df = stop_design.build_event_design_from_meta(\n",
    "    meta=meta,\n",
    "    pos=pos,\n",
    "    new_seg_info=new_seg_info,\n",
    "    speed_used=binned_feats['speed'].values,\n",
    "    include_columns=(\n",
    "        'basis', 'prepost', 'prepost*speed',\n",
    "        'captured', 'basis*captured', #'prepost*captured',\n",
    "        #'time_since_prev_event_pre', 'time_to_next_event_post',\n",
    "        'time_since_prev_event', 'time_to_next_event',\n",
    "    )\n",
    ")\n",
    "\n",
    "cluster_df = cluster_design.build_cluster_features_workflow(\n",
    "    meta_used[['event_id', 'rel_center']], events_with_stats,\n",
    "    rel_time_col='rel_center',\n",
    "    winsor_p=0.5,\n",
    "    use_midbin_progress=True,\n",
    "    zscore_progress=False,   # set True if you want progress in SD units\n",
    "    zscore_rel_time=True\n",
    ")\n",
    "cluster_feats = [\n",
    "        'is_clustered',\n",
    "        'event_is_first_in_cluster', \n",
    "        #'event_is_last_in_cluster',\n",
    "        'prev_gap_s_z',\n",
    "        'next_gap_s_z',\n",
    "        'cluster_duration_s_z',\n",
    "        'cluster_progress_c', 'cluster_progress_c2',\n",
    "        #'log_event_cluster_size_z',      # optional\n",
    "        'cluster_rel_time_s_z',          # optional (bin-level)\n",
    "    ]\n",
    "\n",
    "\n",
    "cols_to_add_from_event_design = [c for c in X_event_df.columns if c not in binned_feats.columns]\n",
    "binned_feats.loc[:, cols_to_add_from_event_design] = X_event_df[cols_to_add_from_event_design].to_numpy()  # equivalent to .values\n",
    "\n",
    "cols_to_add_from_cluster_design = [c for c in cluster_feats if c not in binned_feats.columns]\n",
    "binned_feats.loc[:, cols_to_add_from_cluster_design] = cluster_df[cols_to_add_from_cluster_design].to_numpy()  # equivalent to .values\n",
    "\n",
    "offset_log = np.log(np.clip(exposure[mask_used], 1e-12, None)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- usage ---\n",
    "binned_feats_sc, scaled_cols = event_binning.selective_zscore(binned_feats)\n",
    "binned_feats_sc = sm.add_constant(binned_feats_sc, has_constant='add')\n",
    "print('Scaled columns:', scaled_cols)\n",
    "\n",
    "df_X = binned_feats_sc.copy()\n",
    "df_Y = binned_spikes.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.ff_dataframe['memory'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# add more columns\n",
    "binned_feats['time_rel_to_event_start'] = meta_used['rel_center']\n",
    "\n",
    "\n",
    "# add ff visible/in-memory info\n",
    "max_in_memory_time_since_seen = 2\n",
    "ff_df_sub = pn.ff_dataframe[pn.ff_dataframe['time_since_last_vis']\n",
    "                                        < max_in_memory_time_since_seen].copy()\n",
    "ff_df_sub['in_memory'] = 1\n",
    "\n",
    "for state in ['visible', 'in_memory']:\n",
    "    k_ff_visible = vis_design.count_visible_from_time_df_fast(\n",
    "        ff_df_sub,\n",
    "        bins_2d,\n",
    "        vis_col=state\n",
    "    )\n",
    "\n",
    "    any_visiblef_visible = (k_ff_visible > 0).astype('int8')\n",
    "\n",
    "    binned_feats[f'any_visiblef_{state}'] = any_visiblef_visible[used_bins]\n",
    "    binned_feats[f'k_ff_{state}'] = k_ff_visible[used_bins]\n",
    "\n",
    "\n",
    "# --- usage ---\n",
    "binned_feats_sc, scaled_cols = event_binning.selective_zscore(binned_feats)\n",
    "binned_feats_sc = sm.add_constant(binned_feats_sc, has_constant='add')\n",
    "print('Scaled columns:', scaled_cols)\n",
    "\n",
    "df_X = binned_feats_sc.copy()\n",
    "df_Y = binned_spikes.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build params from the report and align to your spike matrix:\n",
    "params_df = glm_decoding_llr.params_df_from_coefs_df(report['coefs_df'])     # long → wide\n",
    "params_df = glm_decoding_llr.align_params_to_Y(params_df, df_Y)              # row order = df_Y columns\n",
    "\n",
    "# 2) Decode on all rows (no CV)\n",
    "#    vis_col must match the column name you used for visibility in df_X/params_df.\n",
    "llr, p_vis = glm_decoding_llr.decode_from_fitted_glm(\n",
    "    df_X, \n",
    "    df_Y,\n",
    "    offset_log,\n",
    "    params_df=params_df,\n",
    "    vis_col='any_visiblef_visible'                   # <-- change if your term is named 'visible', etc.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X['any_visiblef_visible'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "\n",
    "eps = 1e-9\n",
    "\n",
    "# If you have ground-truth per-bin labels:\n",
    "auc = roc_auc_score(y_visible, llr)               # using raw LLR is fine\n",
    "aupr = average_precision_score(y_visible, p_vis)  # PR-AUC often more informative with class imbalance\n",
    "print(f\"AUC={auc:.3f}, PR-AUC={aupr:.3f}\")\n",
    "\n",
    "# Pick an operating point (threshold)\n",
    "fpr, tpr, thr = roc_curve(y_visible, llr)\n",
    "# Example choices:\n",
    "# - Youden J (maximizes tpr - fpr)\n",
    "j_idx = np.argmax(tpr - fpr)\n",
    "thr_llr = thr[j_idx]\n",
    "\n",
    "# Hard labels\n",
    "y_hat = (llr >= thr_llr).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with prior\n",
    "\n",
    "prior = y_visible.mean()                     # or any prior you believe\n",
    "logit_prior = np.log((prior+eps)/(1-prior+eps))\n",
    "p_post = 1 / (1 + np.exp(-(llr + logit_prior)))  # posterior with prior\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "\n",
    "eps = 1e-9\n",
    "\n",
    "# If you have ground-truth per-bin labels:\n",
    "auc = roc_auc_score(y_visible, llr)               # using raw LLR is fine\n",
    "aupr = average_precision_score(y_visible, p_post)  # PR-AUC often more informative with class imbalance\n",
    "print(f\"AUC={auc:.3f}, PR-AUC={aupr:.3f}\")\n",
    "\n",
    "# Pick an operating point (threshold)\n",
    "fpr, tpr, thr = roc_curve(y_visible, llr)\n",
    "# Example choices:\n",
    "# - Youden J (maximizes tpr - fpr)\n",
    "j_idx = np.argmax(tpr - fpr)\n",
    "thr_llr = thr[j_idx]\n",
    "\n",
    "# Hard labels\n",
    "y_hat = (llr >= thr_llr).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dt from your bins (if irregular)\n",
    "dt = np.ones(len(meta_used), dtype=float) * 0.04\n",
    "groups = meta_used['event_id']\n",
    "\n",
    "\n",
    "for col in ['any_visiblef_visible', 'any_visiblef_in_memory']:\n",
    "    y_visible = binned_feats[col].values\n",
    "    p = y_visible.mean()\n",
    "    print(f\"{col} prevalence = {p:.2f}\")\n",
    "    \n",
    "    # # If your spikes/feats are DataFrames, you can pass them directly,\n",
    "    # # or use .to_numpy() if you prefer explicit arrays.\n",
    "    # auc_mean, auc_std = glm_decoding_llr.cv_decode_glm(\n",
    "    #     binned_spikes,      # (T, N) DataFrame or array\n",
    "    #     binned_feats,       # (T, F) DataFrame or array\n",
    "    #     y_visible,          # (T,)\n",
    "    #     groups,             # (T,)\n",
    "    #     dt,                 # float or (T,)\n",
    "    #     alpha=0.1\n",
    "    # )\n",
    "    # print(auc_mean, auc_std)\n",
    "\n",
    "    auc_mean, auc_std = glm_decoding_llr.cv_decode_glm(\n",
    "        binned_spikes,      # DataFrame or ndarray (T,N)\n",
    "        binned_feats,       # DataFrame or ndarray (T,F)\n",
    "        y_visible,          # ndarray (T,)\n",
    "        groups,             # ndarray (T,)\n",
    "        dt,                 # float or ndarray (T,)\n",
    "        alpha=0.1,          # ridge strength\n",
    "        scale_X=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"GLM-LLR AUC: {auc_mean:.3f} ± {auc_std:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # auc_mean, auc_std = glm_decoding_llr.cv_decode_glm(binned_spikes, binned_feats, y_visible, groups, dt, alpha=0.1)\n",
    "    # print(f\"GLM-LLR AUC: {auc_mean:.3f} ± {auc_std:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_feats['any_visiblef_visible'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_feats['any_visiblef_in_memory'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['any_visiblef_visible', 'any_visiblef_in_memory']:\n",
    "    y_visible = binned_feats[col].values\n",
    "    p = y_visible.mean()\n",
    "    print(f\"{col} prevalence = {p:.2f}\")\n",
    "    best_model, cv_auc, all_auc, best_params = glm_decoding_llr.decode_visible_with_lr(\n",
    "        binned_spikes, y_visible, groups, dt=bin_dt, try_pca=False\n",
    "    )\n",
    "    print(best_params, f'CV AUC={cv_auc:.3f}, all-data AUC={all_auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_visible = binned_feats[col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = glm_decoding_llr.run_full_decode_pipeline(\n",
    "    report, df_X, df_Y, offset_log, bins_2d,\n",
    "    vis_col='any_visiblef_visible',\n",
    "    prior=None,          # or a base rate like 0.15\n",
    "    use_hmm=True, tau_vis=0.5, tau_inv=0.7, pi0=0.05,\n",
    "    y_visible=y_visible, # optional\n",
    "    fpr_target=None      # or e.g. 0.05 for ~5% FPR\n",
    ")\n",
    "print(f\"AUC={out['auc']:.3f}, PR-AUC={out['ap']:.3f}, tau={out['tau']:.3f}\")\n",
    "print(\"First 5 episodes (HMM):\", out['episodes_hmm'][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_obs, pval, null = auc_permutation_test(y_visible, p_post_f, groups=g_f, n_perm=1000, rng=0, mask=mask_guard_f)\n",
    "print(f\"Observed AUC={auc_obs:.3f}, permutation p≈{pval:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_obs, pval, null = glm_decoding_llr.auc_permutation_test(\n",
    "    y_visible, p_post, groups=groups, n_perm=5000, rng=0,\n",
    "    progress=True, desc=\"Permutations\"\n",
    ")\n",
    "\n",
    "mean_auc, lo, hi, aucs = glm_decoding_llr.auc_block_bootstrap_ci(\n",
    "    y_visible, p_post, groups=groups, n_boot=5000, rng=1,\n",
    "    progress=True, desc=\"Bootstraps\"\n",
    ")\n",
    "\n",
    "print(\"=== Decoding significance ===\")\n",
    "print(f\"Observed AUC        : {auc_obs:.3f}\")\n",
    "print(f\"Permutation p-value : {pval:.4g}  (n={len(null)})\")\n",
    "print(f\"Bootstrap mean AUC  : {mean_auc:.3f}\")\n",
    "print(f\"Bootstrap 95% CI    : [{lo:.3f}, {hi:.3f}]  (n={len(aucs)})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = glm_decoding_llr.cv_decode_with_glm_report(\n",
    "    df_X=df_X,                 # design (must include 'any_ff_visible')\n",
    "    df_Y=df_Y,                 # spikes (T x N), columns are unit IDs\n",
    "    y=y_visible,               # (T,) 0/1\n",
    "    groups=groups,             # (T,) session/episode IDs for GroupKFold\n",
    "    offset_log=offset_log,     # scalar or (T,)\n",
    "    fit_fn=stop_glm_fit.glm_mini_report,\n",
    "    fit_kwargs=dict(cov_type='HC1', fast_mle=True, do_inference=False, make_plots=False, show_plots=False),\n",
    "    bins_2d=bins_2d[used_bins],           # to enable guard-band evaluation\n",
    "    vis_col='any_ff_visible',\n",
    "    n_splits=5,\n",
    "    standardize=False,         # set True if you want z-scoring of features on train only\n",
    "    guard=0.05                 # None to disable; else ignores test bins near edges\n",
    ")\n",
    "\n",
    "print(f\"GroupKFold AUC: {res['auc_mean']:.3f} ± {res['auc_std']:.3f} | \"\n",
    "      f\"PR-AUC: {res['pr_mean']:.3f} ± {res['pr_std']:.3f} | folds={res['n_splits']}\")\n",
    "for m in res['fold_metrics']:\n",
    "    print(f\"fold {m['fold']}: AUC={m['auc']:.3f}, PR-AUC={m['pr_auc']:.3f}, n_test={m['n_test']}, kept={m['n_kept']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_visible.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## hmm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def runs_from_binary(y):\n",
    "    y = np.asarray(y, int)\n",
    "    edges = np.flatnonzero(np.diff(np.r_[0, y, 0]) != 0)\n",
    "    starts, ends = edges[::2], edges[1::2]\n",
    "    return starts, ends\n",
    "\n",
    "def estimate_taus_from_labels(y, bins_2d):\n",
    "    # medians of visible runs and invisible gaps (in seconds)\n",
    "    dt = bins_2d[:,1] - bins_2d[:,0]\n",
    "    s1, e1 = runs_from_binary(y)        # visible runs\n",
    "    vis_durs = (bins_2d[e1-1,1] - bins_2d[s1,0]) if len(s1) else np.array([])\n",
    "    # gaps are runs of 0 between visible runs\n",
    "    y0 = 1 - y\n",
    "    s0, e0 = runs_from_binary(y0)\n",
    "    gap_durs = (bins_2d[e0-1,1] - bins_2d[s0,0]) if len(s0) else np.array([])\n",
    "    tau_vis = float(np.median(vis_durs)) if vis_durs.size else 0.5\n",
    "    tau_inv = float(np.median(gap_durs)) if gap_durs.size else 0.7\n",
    "    return max(tau_vis, 1e-3), max(tau_inv, 1e-3)\n",
    "\n",
    "def hmm_binary_smoother(llr, dt, tau_inv=0.7, tau_vis=0.5, pi0=0.05):\n",
    "    from scipy.special import logsumexp\n",
    "    llr = np.asarray(llr, float); dt = np.asarray(dt, float)\n",
    "    if dt.ndim == 0: dt = np.full_like(llr, float(dt))\n",
    "    T = llr.size\n",
    "    L = np.vstack([-0.5*llr, +0.5*llr]).T\n",
    "    p11 = np.clip(np.exp(-dt/max(tau_vis,1e-6)), 1e-6, 1-1e-6)\n",
    "    p00 = np.clip(np.exp(-dt/max(tau_inv,1e-6)), 1e-6, 1-1e-6)\n",
    "    p10 = 1.0 - p11; p01 = 1.0 - p00\n",
    "    logA00,logA01,logA10,logA11 = np.log(p00),np.log(p01),np.log(p10),np.log(p11)\n",
    "    log_pi = np.log([1-0.05, 0.05])\n",
    "    # forward\n",
    "    la = np.empty((T,2)); la[0]=log_pi+L[0]\n",
    "    for t in range(1,T):\n",
    "        a0 = logsumexp([la[t-1,0]+logA00[t-1], la[t-1,1]+logA10[t-1]]); \n",
    "        a1 = logsumexp([la[t-1,0]+logA01[t-1], la[t-1,1]+logA11[t-1]]);\n",
    "        la[t,0]=a0+L[t,0]; la[t,1]=a1+L[t,1]\n",
    "    # backward\n",
    "    lb = np.zeros((T,2))\n",
    "    for t in range(T-2,-1,-1):\n",
    "        b0 = logsumexp([logA00[t]+L[t+1,0]+lb[t+1,0], logA01[t]+L[t+1,1]+lb[t+1,1]])\n",
    "        b1 = logsumexp([logA10[t]+L[t+1,0]+lb[t+1,0], logA11[t]+L[t+1,1]+lb[t+1,1]])\n",
    "        lb[t,0]=b0; lb[t,1]=b1\n",
    "    lg = la+lb; lg -= logsumexp(lg, axis=1, keepdims=True)\n",
    "    return np.exp(lg)[:,1]  # posterior P(visible)\n",
    "\n",
    "def grid_search_hmm(llr_or_p, bins_2d, y_true=None, use_probs=True, base_taus=None, mult=(0.5, 0.75, 1.0, 1.5, 2.0)):\n",
    "    dt = (bins_2d[:,1]-bins_2d[:,0])\n",
    "    if use_probs:\n",
    "        eps=1e-12\n",
    "        llr = np.log(llr_or_p+eps) - np.log(1-llr_or_p+eps)\n",
    "    else:\n",
    "        llr = np.asarray(llr_or_p, float)\n",
    "    if base_taus is None:\n",
    "        tau_v, tau_i = estimate_taus_from_labels((y_true if y_true is not None else (llr>0).astype(int)), bins_2d)\n",
    "    else:\n",
    "        tau_v, tau_i = base_taus\n",
    "    best = {\"auc\": -np.inf, \"tau_vis\": None, \"tau_inv\": None, \"p\": None}\n",
    "    for mv in mult:\n",
    "        for mi in mult:\n",
    "            p = hmm_binary_smoother(llr, dt, tau_inv=tau_i*mi, tau_vis=tau_v*mv)\n",
    "            if y_true is None:\n",
    "                # no labels: prefer smoother (lower total variation)\n",
    "                tv = np.sum(np.abs(np.diff(p)))\n",
    "                score = -tv\n",
    "            else:\n",
    "                score = roc_auc_score(y_true, p)\n",
    "            if score > best[\"auc\"]:\n",
    "                best = {\"auc\": float(score), \"tau_vis\": tau_v*mv, \"tau_inv\": tau_i*mi, \"p\": p}\n",
    "    return best\n",
    "\n",
    "# run it\n",
    "base_tau = estimate_taus_from_labels(y_visible, bins_2d)\n",
    "best = grid_search_hmm(p_post, bins_2d, y_true=y_visible, use_probs=True, base_taus=base_tau)\n",
    "print(f\"[HMM tuned] AUC={best['auc']:.3f}, tau_vis={best['tau_vis']:.3f}s, tau_inv={best['tau_inv']:.3f}s\")\n",
    "p_smooth = best['p']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## check df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pruned = design_checks.check_design(binned_feats_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(glm_fit_utils)\n",
    "reload(stop_glm_fit)\n",
    "\n",
    "report = stop_glm_fit.glm_mini_report(\n",
    "    df_X=df_X, df_Y=df_Y, offset_log=offset_log,\n",
    "    cov_type='HC1',            # or 'nonrobust' for even faster\n",
    "    fast_mle=True,             # << use the ultra-fast path\n",
    "    do_inference=True,        # skip FDR/ratios/pop-tests\n",
    "    make_plots=True,          # skip figure creation\n",
    "    show_plots=True,          # nothing to display\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
