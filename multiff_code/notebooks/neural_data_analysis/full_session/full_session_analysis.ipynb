{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from machine_learning.ml_methods import regression_utils, ml_methods_utils, regz_regression_utils, ml_methods_class, classification_utils, ml_plotting_utils\n",
    "from neural_data_analysis.design_kits.design_by_segment import create_pn_design_df, predictor_utils, other_feats\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class, pn_aligned_by_seg, pn_aligned_by_event, pn_glm_utils\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.tpg import glm_bases, glm_plotting, glm_plotting2, glm_fit\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_psth import core_stops_psth, psth_postprocessing, psth_stats, compare_events, dpca_utils\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.glm_fit import general_glm_fit, cv_stop_glm, glm_fit_utils, variance_explained, glm_runner\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_plotting import plot_spikes, plot_glm_fit, plot_tuning_func, compare_glm_fit\n",
    "from neural_data_analysis.design_kits.design_around_event import event_binning, stop_design, cluster_design, design_checks\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_hyperparams import compare_glm_configs, glm_hyperparams_class\n",
    "from neural_data_analysis.design_kits.design_by_segment import spike_history, rebin_segments\n",
    "from neural_data_analysis.topic_based_neural_analysis.full_session import create_full_session_design, create_best_arc_design\n",
    "from neural_data_analysis.design_kits.design_by_segment import temporal_feats\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.get_stop_events import get_stops_utils\n",
    "from neural_data_analysis.topic_based_neural_analysis.full_session import selected_raw_data_features, selected_pn_design_features, selected_stop_design_features, select_fs_features\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.get_stop_events import prepare_stop_design, collect_stop_data\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.glm_fit import full_session_glm_runner\n",
    "from decision_making_analysis.data_compilation import miss_events_class\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "import json\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "from numpy import pi\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Fully use class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0314\"\n",
    "fs = full_session_glm_runner.FullSessionGLMRunner(raw_data_folder_path=raw_data_folder_path)\n",
    "fs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.pn_design_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python multiff_analysis/jobs/decoding/decode_vis/scripts/decode_vis_script.py --raw_data_folder_path \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python multiff_analysis/jobs/glm/scripts/glm_script.py --raw_data_folder_path \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\" --hyperparam_tuning True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Try using a subset of features for glm (to make sure it's not overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = fs.merged_design_df[select_fs_features.ALL_REGRESSORS].copy()\n",
    "df_Y = fs.binned_spikes.copy()\n",
    "\n",
    "output_root = os.path.join(fs.pn.planning_and_neural_folder_path, 'full_session_sel_cols')\n",
    "\n",
    "pipeline = glm_runner.GLMPipeline(\n",
    "    spikes_df=fs.pn.spikes_df,\n",
    "    bin_df=fs.bin_df,\n",
    "    df_X=df_X,\n",
    "    df_Y=df_Y,\n",
    "    meta_groups=fs.merged_meta_groups,\n",
    "    bin_width=fs.bin_width,\n",
    "    output_root=output_root,\n",
    "    cv_splitter='blocked_time_buffered'\n",
    ")\n",
    "\n",
    "pipeline.run(glm_results_exists_ok=False, pruned_columns_exists_ok=True)\n",
    "pipeline.plot_comparisons()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_y_var_lags = False\n",
    "planning_data_by_point_exists_ok = True\n",
    "y_data_exists_ok = True\n",
    "\n",
    "pn = pn_aligned_by_event.PlanningAndNeuralEventAligned(raw_data_folder_path=raw_data_folder_path)\n",
    "pn.prep_data_to_analyze_planning(planning_data_by_point_exists_ok=planning_data_by_point_exists_ok)\n",
    "#pn.get_x_and_y_data_for_modeling(exists_ok=y_data_exists_ok, reduce_y_var_lags=reduce_y_var_lags)\n",
    "\n",
    "pn.rebin_data_in_new_segments(cur_or_nxt='cur', first_or_last='first', time_limit_to_count_sighting=3,\n",
    "                                 start_t_rel_event=0, end_at_stop_time=True, rebinned_max_x_lag_number=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Get full session design df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add num_ff_visible etc.\n",
    "pn.make_or_retrieve_ff_dataframe()\n",
    "pn.monkey_information = pn_utils.add_ff_visible_or_in_memory_info_by_point(\n",
    "    pn.monkey_information, pn.ff_dataframe)\n",
    "dt = pn.bin_width\n",
    "\n",
    "new_seg_info = pd.DataFrame({\n",
    "    'new_segment': 0,\n",
    "    'new_seg_start_time': max(0, pn.ff_caught_T_sorted.min() - 1),\n",
    "    'new_seg_end_time': pn.ff_caught_T_sorted.max(),\n",
    "    'new_seg_duration': pn.ff_caught_T_sorted.max() - max(0, pn.ff_caught_T_sorted.min() - 1)\n",
    "}, index=[0])\n",
    "\n",
    "monkey_information = pn.monkey_information.copy()\n",
    "rebinned_monkey_data, global_bins_2d = rebin_segments.rebin_all_segments_local_bins(\n",
    "            monkey_information, new_seg_info, bin_width=pn.bin_width, respect_old_segment=False,\n",
    "            add_bin_edges=True,\n",
    "            )\n",
    "\n",
    "trial_ids = np.repeat(0, len(rebinned_monkey_data))\n",
    "rebinned_monkey_data = temporal_feats.add_stop_and_capture_columns(rebinned_monkey_data, trial_ids, pn.ff_caught_T_new)\n",
    "\n",
    "fs_design_df, meta0, meta = create_full_session_design.get_initial_full_session_design_df(rebinned_monkey_data, dt, trial_ids)\n",
    "fs_meta_groups = meta['groups']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## best arc features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data_folder_path='all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330'\n",
    "raw_data_folder_path='all_monkey_data/raw_monkey_data/monkey_Schro/data_0413'\n",
    "\n",
    "mec = miss_events_class.MissEventsClass(raw_data_folder_path=raw_data_folder_path, time_range_of_trajectory=[-0.5, 2.5], num_time_points_for_trajectory=10)\n",
    "mec.get_monkey_data(already_retrieved_ok=True, include_ff_dataframe=True)\n",
    "mec.ff_dataframe = mec.ff_dataframe[abs(mec.ff_dataframe['ff_angle_boundary']) <= math.pi/4]\n",
    "mec.ff_dataframe = mec.ff_dataframe[mec.ff_dataframe['time_since_last_vis'] <= 2.5]\n",
    "mec.make_curvature_df([-25, 25], curv_of_traj_mode='distance')\n",
    "mec.eliminate_crossing_boundary_cases(n_seconds_after_crossing_boundary=0.5)\n",
    "mec.make_or_retrieve_best_arc_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_arc_df_sub = mec.best_arc_df[['ff_index', 'ff_distance', 'ff_angle', 'opt_arc_curv', 'opt_arc_length', 'curv_diff', 'abs_curv_diff']].copy()\n",
    "# add 'ba_' prefix to the column names\n",
    "best_arc_df_sub.columns = ['best_arc_' + c for c in best_arc_df_sub.columns]\n",
    "best_arc_df_sub['point_index'] = mec.best_arc_df['point_index']\n",
    "best_arc_df_sub['time'] = mec.best_arc_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebinned_best_arc_df, bin_edges = rebin_segments.rebin_all_segments_global_bins_pick_point(\n",
    "            best_arc_df_sub, new_seg_info, bins_2d=global_bins_2d, respect_old_segment=False,\n",
    "            add_bin_edges=True,\n",
    "            )\n",
    "\n",
    "best_arc_design_df, best_arc_ff_meta0, best_arc_ff_meta = create_best_arc_design.get_best_arc_design_df(rebinned_best_arc_df, dt)\n",
    "best_arc_design_df['bin'] = rebinned_best_arc_df['new_bin']\n",
    "best_arc_meta_groups = best_arc_ff_meta['groups']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## pn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pn_df, pn_bin_edges = rebin_segments.rebin_all_segments_global_bins(\n",
    "    pn.planning_data_by_point,\n",
    "    pn.new_seg_info,\n",
    "    bins_2d=global_bins_2d,\n",
    "    how='mean',\n",
    "    respect_old_segment=True,\n",
    "    require_full_bin=True,\n",
    "    add_bin_edges=True,\n",
    "    add_support_duration=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_ids = pn_df['new_segment']\n",
    "dt = pn.bin_width\n",
    "pn_df = temporal_feats.add_stop_and_capture_columns(pn_df, trial_ids, pn.ff_caught_T_new)\n",
    "pn_design_df, pn_meta0, pn_meta = create_pn_design_df.get_initial_design_df(pn_df, dt, trial_ids)\n",
    "pn_meta_groups = pn_meta['groups']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## stop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0327\"\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0301\"\n",
    "\n",
    "pn, datasets, comparisons = collect_stop_data.collect_stop_data_func(\n",
    "    raw_data_folder_path)\n",
    "\n",
    "globals().update(datasets)\n",
    "\n",
    "captures_df, valid_captures_df, filtered_no_capture_stops_df, stops_with_stats = get_stops_utils.prepare_no_capture_and_captures(\n",
    "    monkey_information=pn.monkey_information,\n",
    "    closest_stop_to_capture_df=pn.closest_stop_to_capture_df,\n",
    "    ff_caught_T_new=pn.ff_caught_T_new,\n",
    "    distance_col=\"distance_from_ff_to_stop\",\n",
    ")\n",
    "\n",
    "stops_with_stats['stop_time'] = stops_with_stats['stop_id_start_time']\n",
    "stops_with_stats['prev_time'] = stops_with_stats['stop_id_end_time'].shift(1)\n",
    "stops_with_stats['next_time'] = stops_with_stats['stop_id_start_time'].shift(-1)\n",
    "\n",
    "new_seg_info = event_binning.make_new_seg_info_for_stop_design(stops_with_stats, pn.closest_stop_to_capture_df, pn.monkey_information)\n",
    "\n",
    "\n",
    "events_with_stats = stops_with_stats[['stop_id','stop_cluster_id','stop_id_start_time','stop_id_end_time']].copy()\n",
    "events_with_stats.rename(columns={'stop_id':'event_id', 'stop_cluster_id':'event_cluster_id', \n",
    "                                  'stop_id_start_time':'event_id_start_time', \n",
    "                                  'stop_id_end_time':'event_id_end_time'}, inplace=True)\n",
    "\n",
    "stop_binned_spikes, stop_binned_feats, stop_offset_log, stop_meta_used, stop_meta_groups = prepare_stop_design.build_stop_design(new_seg_info, events_with_stats, \n",
    "                                                                             pn.monkey_information, \n",
    "                                                                             pn.spikes_df, pn.ff_dataframe, \n",
    "                                                                             datasets=datasets,\n",
    "                                                                             add_ff_visible_info=True,\n",
    "                                                                             global_bins_2d=global_bins_2d)\n",
    "\n",
    "stop_binned_feats = prepare_stop_design.add_interaction_columns(stop_binned_feats)\n",
    "stop_binned_feats_sc = prepare_stop_design.scale_binned_feats(stop_binned_feats)\n",
    "\n",
    "stop_binned_feats_sc['bin'] = stop_meta_used['global_bin']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- FS (monkey) design ---\n",
    "fs_design_df['bin'] = rebinned_monkey_data['new_bin']\n",
    "\n",
    "\n",
    "best_arc_design_df_sub = best_arc_design_df.drop(columns=['const'])\n",
    "best_arc_design_df_sub['having_best_arc_ff'] = 1\n",
    "\n",
    "# --- PN design ---\n",
    "pn_design_df_sub = pn_design_df[selected_pn_design_features.pn_design_predictors].copy()\n",
    "pn_design_df_sub['bin'] = pn_df['new_bin']\n",
    "pn_design_df_sub['in_pn_window'] = 1\n",
    "\n",
    "# --- Stop-binned PN features ---\n",
    "stop_design_df_sub = stop_binned_feats_sc[\n",
    "    selected_stop_design_features.stop_design_predictors\n",
    "].copy()\n",
    "stop_design_df_sub['bin'] = stop_meta_used['global_bin']\n",
    "stop_design_df_sub['in_stop_window'] = 1\n",
    "\n",
    "\n",
    "merged_design_df = create_full_session_design.merge_design_blocks(\n",
    "    fs_design_df,\n",
    "    best_arc_design_df_sub,\n",
    "    pn_design_df_sub,\n",
    "    stop_design_df_sub,\n",
    ")\n",
    "\n",
    "merged_meta_groups = {\n",
    "    **fs_meta_groups,\n",
    "    **best_arc_meta_groups,\n",
    "    **stop_meta_groups,\n",
    "    **pn_meta_groups,\n",
    "}\n",
    "\n",
    "spike_counts, cluster_ids = event_binning.bin_spikes_by_cluster(\n",
    "    pn.spikes_df, global_bins_2d, time_col='time', cluster_col='cluster'\n",
    ")\n",
    "\n",
    "binned_spikes = (\n",
    "    pd.DataFrame(spike_counts, columns=cluster_ids)\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_design_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Get x_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_path = os.path.join(pn.planning_and_neural_folder_path, 'full_session', 'selected_cols.json')\n",
    "X_pruned, vif_report = design_checks.load_or_compute_selected_cols(merged_design_df, cols_path, exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# Get spike history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = merged_design_df[['bin']].rename(columns={'bin': 'new_bin'})\n",
    "bin_df['new_segment'] = 0\n",
    "bin_df['bin_left'] = global_bins_2d[:, 0]\n",
    "bin_df['bin_right'] = global_bins_2d[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Take out subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_design_df[['in_stop_window', 'in_pn_window']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_mask = (merged_design_df['in_stop_window'] == 1) | (merged_design_df['in_pn_window'] == 1)\n",
    "merged_design_df_sub = merged_design_df[sub_mask].copy()\n",
    "binned_spikes_sub = binned_spikes[sub_mask].copy()\n",
    "bin_df_sub = bin_df[sub_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_rel = 1e-6\n",
    "\n",
    "# pct_near_zero_per_col = (\n",
    "#     (merged_design_df_sub.abs() < eps_rel).mean()\n",
    "#     .mul(100)\n",
    "#     .rename('pct_near_zero')\n",
    "#     .to_frame()\n",
    "# )\n",
    "# pct_near_zero_per_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# GLM with regularization (behavior only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = merged_design_df.copy()\n",
    "df_Y = binned_spikes.copy()\n",
    "\n",
    "exposure = np.repeat(pn.bin_width, len(df_Y))\n",
    "offset_log = np.log(exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y_sub = df_Y[[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a subset, just to show thing things work\n",
    "\n",
    "save_dir = os.path.join(\n",
    "    pn.planning_and_neural_folder_path, 'full_session', 'glm_fit'\n",
    ")\n",
    "\n",
    "report0 = general_glm_fit.glm_mini_report(\n",
    "    df_X=X_pruned,\n",
    "    df_Y=df_Y_sub,\n",
    "    offset_log=offset_log,\n",
    "\n",
    "    # ---- GLM / inference ----\n",
    "    cov_type='HC1',\n",
    "    do_inference=True,\n",
    "    make_plots=True,\n",
    "    show_plots=True,\n",
    "\n",
    "    # ---- ðŸ”‘ TURN ON REGULARIZATION + TUNING ----\n",
    "    fast_mle=False,                      # REQUIRED\n",
    "    regularization='elastic_net',        # enables fit_regularized\n",
    "    # alpha_grid=(1e-4, 3e-4, 1e-3, 3e-3, 1e-2),\n",
    "    alpha_grid=(1e-4, 3e-4),\n",
    "    l1_wt_grid=(0.0,),                   # ridge (recommended)\n",
    "    cv_metric='loglik',\n",
    "    n_splits=5,\n",
    "    cv_splitter='blocked_time_buffered',\n",
    "    refit_on_support=False,              # ridge â†’ no refit\n",
    "\n",
    "    # ---- bookkeeping ----\n",
    "    #save_dir=save_dir,\n",
    "    exists_ok=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "report0['cv_tables_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_glm_fit.plot_insample_model_comparison(\n",
    "    {'Behavior': report0['metrics_df']},\n",
    "    show=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## use full session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = merged_design_df.copy()\n",
    "df_Y = binned_spikes.copy()\n",
    "\n",
    "output_root = os.path.join(pn.planning_and_neural_folder_path, 'full_session')\n",
    "\n",
    "pipeline = glm_runner.GLMPipeline(\n",
    "    spikes_df=pn.spikes_df,\n",
    "    bin_df=bin_df,\n",
    "    df_X=df_X,\n",
    "    df_Y=df_Y,\n",
    "    meta_groups=merged_meta_groups,\n",
    "    bin_width=pn.bin_width,\n",
    "    output_root=output_root,\n",
    "    cv_splitter='blocked_time_buffered'\n",
    ")\n",
    "\n",
    "pipeline.run(glm_results_exists_ok=False, pruned_columns_exists_ok=True)\n",
    "pipeline.plot_comparisons()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## use subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = merged_design_df_sub.copy()\n",
    "df_Y = binned_spikes_sub.copy()\n",
    "\n",
    "output_root = os.path.join(pn.planning_and_neural_folder_path, 'full_session_sub')\n",
    "\n",
    "pipeline = glm_runner.GLMPipeline(\n",
    "    spikes_df=pn.spikes_df,\n",
    "    bin_df=bin_df_sub,\n",
    "    df_X=df_X,\n",
    "    df_Y=df_Y,\n",
    "    meta_groups=merged_meta_groups,\n",
    "    bin_width=pn.bin_width,\n",
    "    output_root=output_root,\n",
    "    cv_splitter='blocked_time_buffered'\n",
    ")\n",
    "\n",
    "pipeline.run()\n",
    "pipeline.plot_comparisons()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## just behavioral vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = merged_design_df.copy()\n",
    "df_Y = binned_spikes.copy()\n",
    "\n",
    "exposure = np.repeat(pn.bin_width, len(df_Y))\n",
    "offset_log = np.log(exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(pn.planning_and_neural_folder_path, 'full_session', 'glm_fit')\n",
    "\n",
    "report0 = general_glm_fit.glm_mini_report(\n",
    "    df_X=X_pruned, df_Y=df_Y, offset_log=offset_log,\n",
    "    cov_type='HC1', \n",
    "    fast_mle=True,\n",
    "    do_inference=True, \n",
    "    make_plots=True,\n",
    "    show_plots=True,\n",
    "    save_dir=save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = report0['coefs_df']\n",
    "coefs_df[(coefs_df['term'] == 'captured') & (coefs_df['sig_FDR'] == True)].sort_values('p', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df['refit_on_support'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## both (behav and spike history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_path = os.path.join(pn.planning_and_neural_folder_path, 'full_session', 'selected_cols_w_spike_history.json')\n",
    "try:\n",
    "    with open(cols_path, 'r') as f:\n",
    "        selected_cols_w_history = json.load(f)\n",
    "    X_pruned1 = design_w_history[selected_cols_w_history].copy()\n",
    "    print(f'Loaded selected columns from {cols_path}')\n",
    "except:\n",
    "    os.makedirs(os.path.dirname(cols_path), exist_ok=True)\n",
    "    X_pruned1, vif_report = design_checks.check_design(design_w_history)\n",
    "    with open(cols_path, 'w') as f:\n",
    "        json.dump(X_pruned1.columns.tolist(), f)\n",
    "    print(f'Saved selected columns to {cols_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(pn.planning_and_neural_folder_path, 'full_session', 'glm_fit')\n",
    "\n",
    "report1 = general_glm_fit.glm_mini_report(\n",
    "    df_X=X_pruned1, df_Y=df_Y, \n",
    "    offset_log=offset_log,\n",
    "    cov_type='HC1', \n",
    "    fast_mle=True,\n",
    "    do_inference=True, \n",
    "    make_plots=True,\n",
    "    show_plots=True,\n",
    "    meta_groups=merged_meta_groups,\n",
    "    save_dir=save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## just spike history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history_cols = [c for c in design_w_history.columns if (c.startswith('cluster_') \n",
    "                                                            and c not in binned_feats_sc.columns)]\n",
    "cols_path = os.path.join(pn.planning_and_neural_folder_path, 'full_session', 'selected_spike_history_cols.json')\n",
    "try:\n",
    "    with open(cols_path, 'r') as f:\n",
    "        selected_history_cols = json.load(f)\n",
    "    X_pruned2 = design_w_history[selected_history_cols].copy()\n",
    "    print(f'Loaded selected columns from {cols_path}')\n",
    "except:\n",
    "    os.makedirs(os.path.dirname(cols_path), exist_ok=True)\n",
    "    X_pruned2, vif_report = design_checks.check_design(design_w_history[all_history_cols])\n",
    "    with open(cols_path, 'w') as f:\n",
    "        json.dump(X_pruned2.columns.tolist(), f)\n",
    "    print(f'Saved selected columns to {cols_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(pn.planning_and_neural_folder_path, 'full_session', 'glm_fit')\n",
    "\n",
    "report2 = general_glm_fit.glm_mini_report(\n",
    "    df_X=X_pruned2, df_Y=df_Y, \n",
    "    offset_log=offset_log,\n",
    "    cov_type='HC1', \n",
    "    fast_mle=True,\n",
    "    do_inference=True, \n",
    "    make_plots=True,\n",
    "    show_plots=True,\n",
    "    meta_groups=merged_meta_groups,\n",
    "    save_dir=save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "# Compare deviance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "## In-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_model = {\n",
    "    'Behavior only': report0['metrics_df'],\n",
    "    'Behavior + history': report1['metrics_df'],\n",
    "    'History only': report2['metrics_df'],\n",
    "}\n",
    "\n",
    "compare_glm_fit.plot_insample_model_comparison(metrics_by_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_by_model = {\n",
    "    'Behavior only': report0['metrics_df'],\n",
    "    'Behavior + history': report1['metrics_df'],\n",
    "    'History only': report2['metrics_df'],\n",
    "}\n",
    "\n",
    "compare_glm_fit.plot_cv_model_comparison(metrics_by_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "# Deviance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## in sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_glm_fit.plot_insample_model_diagnostics(\n",
    "    report0['metrics_df'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_glm_fit.plot_insample_model_diagnostics(\n",
    "    report1['metrics_df'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_glm_fit.plot_insample_model_diagnostics(\n",
    "    report2['metrics_df'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_glm_fit.plot_cv_model_diagnostics(\n",
    "    report0['metrics_df'],\n",
    "    bins=20,\n",
    "    show=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_df = report['metrics_df'].copy()\n",
    "\n",
    "# ---- derived quantities ----\n",
    "metrics_df['ll_improvement'] = metrics_df['llf'] - metrics_df['llnull']\n",
    "metrics_df['ll_improvement_per_obs'] = metrics_df['ll_improvement'] / metrics_df['n_obs']\n",
    "\n",
    "# ---- figure layout ----\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# ========== 1. Deviance explained distribution ==========\n",
    "axes[0].hist(metrics_df['deviance_explained'], bins=20)\n",
    "axes[0].axvline(metrics_df['deviance_explained'].median(), linestyle='--')\n",
    "axes[0].set_xlabel('Deviance explained')\n",
    "axes[0].set_ylabel('Number of neurons')\n",
    "axes[0].set_title('Model performance (deviance explained)')\n",
    "\n",
    "# ========== 2. McFadden RÂ² distribution ==========\n",
    "axes[1].hist(metrics_df['mcfadden_R2'], bins=20)\n",
    "axes[1].axvline(metrics_df['mcfadden_R2'].median(), linestyle='--')\n",
    "axes[1].set_xlabel('McFadden $R^2$')\n",
    "axes[1].set_ylabel('Number of neurons')\n",
    "axes[1].set_title('Pseudo-$R^2$ distribution')\n",
    "\n",
    "# ========== 3. Deviance explained vs McFadden RÂ² ==========\n",
    "axes[2].scatter(\n",
    "    metrics_df['deviance_explained'],\n",
    "    metrics_df['mcfadden_R2'],\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[2].set_xlabel('Deviance explained')\n",
    "axes[2].set_ylabel('McFadden $R^2$')\n",
    "axes[2].set_title('Consistency check')\n",
    "\n",
    "# ========== 4. Deviance explained vs null deviance ==========\n",
    "axes[3].scatter(\n",
    "    metrics_df['null_deviance'],\n",
    "    metrics_df['deviance_explained'],\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[3].set_xlabel('Null deviance (rate / variability proxy)')\n",
    "axes[3].set_ylabel('Deviance explained')\n",
    "axes[3].set_title('Dependence on firing statistics')\n",
    "\n",
    "# ========== 5. Log-likelihood improvement ==========\n",
    "axes[4].hist(metrics_df['ll_improvement'], bins=20)\n",
    "axes[4].axvline(0, linestyle='--')\n",
    "axes[4].set_xlabel('Log-likelihood improvement')\n",
    "axes[4].set_ylabel('Number of neurons')\n",
    "axes[4].set_title('Improvement over null model')\n",
    "\n",
    "# ========== 6. LL improvement per observation ==========\n",
    "axes[5].hist(metrics_df['ll_improvement_per_obs'], bins=20)\n",
    "axes[5].axvline(0, linestyle='--')\n",
    "axes[5].set_xlabel('Î” log-likelihood per observation')\n",
    "axes[5].set_ylabel('Number of neurons')\n",
    "axes[5].set_title('Predictive gain (normalized)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_df = report['metrics_df'].copy()\n",
    "\n",
    "# ---- derived quantities ----\n",
    "metrics_df['ll_improvement'] = metrics_df['llf'] - metrics_df['llnull']\n",
    "metrics_df['ll_improvement_per_obs'] = metrics_df['ll_improvement'] / metrics_df['n_obs']\n",
    "\n",
    "# ---- figure layout ----\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# ========== 1. Deviance explained distribution ==========\n",
    "axes[0].hist(metrics_df['deviance_explained'], bins=20)\n",
    "axes[0].axvline(metrics_df['deviance_explained'].median(), linestyle='--')\n",
    "axes[0].set_xlabel('Deviance explained')\n",
    "axes[0].set_ylabel('Number of neurons')\n",
    "axes[0].set_title('Model performance (deviance explained)')\n",
    "\n",
    "# ========== 2. McFadden RÂ² distribution ==========\n",
    "axes[1].hist(metrics_df['mcfadden_R2'], bins=20)\n",
    "axes[1].axvline(metrics_df['mcfadden_R2'].median(), linestyle='--')\n",
    "axes[1].set_xlabel('McFadden $R^2$')\n",
    "axes[1].set_ylabel('Number of neurons')\n",
    "axes[1].set_title('Pseudo-$R^2$ distribution')\n",
    "\n",
    "# ========== 3. Deviance explained vs McFadden RÂ² ==========\n",
    "axes[2].scatter(\n",
    "    metrics_df['deviance_explained'],\n",
    "    metrics_df['mcfadden_R2'],\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[2].set_xlabel('Deviance explained')\n",
    "axes[2].set_ylabel('McFadden $R^2$')\n",
    "axes[2].set_title('Consistency check')\n",
    "\n",
    "# ========== 4. Deviance explained vs null deviance ==========\n",
    "axes[3].scatter(\n",
    "    metrics_df['null_deviance'],\n",
    "    metrics_df['deviance_explained'],\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[3].set_xlabel('Null deviance (rate / variability proxy)')\n",
    "axes[3].set_ylabel('Deviance explained')\n",
    "axes[3].set_title('Dependence on firing statistics')\n",
    "\n",
    "# ========== 5. Log-likelihood improvement ==========\n",
    "axes[4].hist(metrics_df['ll_improvement'], bins=20)\n",
    "axes[4].axvline(0, linestyle='--')\n",
    "axes[4].set_xlabel('Log-likelihood improvement')\n",
    "axes[4].set_ylabel('Number of neurons')\n",
    "axes[4].set_title('Improvement over null model')\n",
    "\n",
    "# ========== 6. LL improvement per observation ==========\n",
    "axes[5].hist(metrics_df['ll_improvement_per_obs'], bins=20)\n",
    "axes[5].axvline(0, linestyle='--')\n",
    "axes[5].set_xlabel('Î” log-likelihood per observation')\n",
    "axes[5].set_ylabel('Number of neurons')\n",
    "axes[5].set_title('Predictive gain (normalized)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## how much data does planning_data_by_point cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total session length\n",
    "pn.planning_data_by_point['time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of data used in planning_data_by_point\n",
    "pn.planning_data_by_point['time'].diff()[pn.planning_data_by_point['time'].diff() < 0.02].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pn.ff_caught_T_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pn.planning_data_by_point['cur_ff_index'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pn.rebinned_y_var['target_index'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "## Select relevant raw features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rebinned_monkey_data['stop'] = (rebinned_monkey_data['stop_id'] > 0)\n",
    "rebinned_monkey_data_sub = rebinned_monkey_data[selected_raw_data_features.selected_kinematics_features]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
