{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from machine_learning.ml_methods import regression_utils, ml_methods_utils, regz_regression_utils, ml_methods_class, classification_utils, ml_plotting_utils\n",
    "from null_behaviors import find_best_arc, curvature_utils, curv_of_traj_utils, opt_arc_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_cv_utils_stage2 import cca_cv_utils2, cca_cv_compare_data\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import pn_feature_selection\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0402\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(opt_arc_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_y_var_lags = True\n",
    "planning_data_by_point_exists_ok = True\n",
    "y_data_exists_ok = True\n",
    "\n",
    "pn = planning_and_neural_class.PlanningAndNeural(raw_data_folder_path=raw_data_folder_path)\n",
    "pn.prep_data_to_analyze_planning(planning_data_by_point_exists_ok=planning_data_by_point_exists_ok)\n",
    "pn.planning_data_by_point, cols_to_drop = general_utils.drop_columns_with_many_nans(\n",
    "    pn.planning_data_by_point)\n",
    "pn.get_x_and_y_data_for_modeling(exists_ok=y_data_exists_ok, reduce_y_var_lags=reduce_y_var_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# CV: one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_cv_utils_stage2 import cca_cv_utils2, cca_cv_compare_data, pinpoint_features\n",
    "\n",
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn_feature_selection.select_features(pn.y_var).copy()\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cca_cv_utils2.plot_cv_cca_overlay(cv_summary, show_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_cv_utils2.plot_cv_cca_violin(cv_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_cv_utils2.plot_cv_cca_lines(cv_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Selected features vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn_feature_selection.select_features(pn.y_var).copy()\n",
    "X2_rest = pn.y_var[[col for col in pn.y_var.columns if col not in X2.columns]].copy()\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cv_summary2 = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2_rest, trial_ids=pn.y_var['segment'].values)\n",
    "\n",
    "label1 = \"Selected Features\"\n",
    "label2 = \"Rest\"\n",
    "cca_cv_compare_data.plot_cv_cca_compare_all(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# # Or call individual plots if you prefer:\n",
    "# cca_cv_compare_data.plot_cv_means_sd(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_all_folds_overlay(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_mean_difference(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_train_test_gap(cv_summary, cv_summary2, labels=(label1, label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Eye features vs rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords once\n",
    "eye_keywords = (\"eye\", \"gaze\", \"LD\", \"RD\")\n",
    "eye_cols = [col for col in pn.y_var.columns if any(k in col for k in eye_keywords)]\n",
    "\n",
    "\n",
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn.y_var[eye_cols].copy()\n",
    "\n",
    "cca_no_lag = cca_class.CCAclass(X1=X1, \n",
    "                                X2=X2, \n",
    "                                lagging_included=False)\n",
    "cca_no_lag.conduct_cca()\n",
    "\n",
    "cca_rest = cca_class.CCAclass(X1=X1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_keywords = (\"eye\", \"gaze\", \"LD\", \"RD\")\n",
    "eye_cols = [col for col in pn.y_var.columns if any(k in col for k in eye_keywords)]\n",
    "\n",
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn.y_var[eye_cols].copy()\n",
    "X2_rest = pn.y_var[[col for col in pn.y_var.columns if col not in X2.columns]].copy()\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cv_summary2 = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2_rest, trial_ids=pn.y_var['segment'].values)\n",
    "\n",
    "label1 = \"Selected Features\"\n",
    "label2 = \"Rest\"\n",
    "cca_cv_compare_data.plot_cv_cca_compare_all(cv_summary, cv_summary2, labels=(label1, label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Selected features vs Eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "\n",
    "eye_keywords = (\"eye\", \"gaze\", \"LD\", \"RD\")\n",
    "eye_cols = [col for col in pn.y_var.columns if any(k in col for k in eye_keywords)]\n",
    "X2 = pn_feature_selection.select_features(pn.y_var).copy()\n",
    "\n",
    "X2_rest = pd.concat([X2, pn.y_var[eye_cols]], axis=1)\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cv_summary2 = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2_rest, trial_ids=pn.y_var['segment'].values)\n",
    "\n",
    "\n",
    "label1 = \"Selected Features\"\n",
    "label2 = \"Selected Features + Eyes\"\n",
    "cca_cv_compare_data.plot_cv_cca_compare_all(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# # Or call individual plots if you prefer:\n",
    "# cca_cv_compare_data.plot_cv_means_sd(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_all_folds_overlay(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_mean_difference(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_train_test_gap(cv_summary, cv_summary2, labels=(label1, label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Selected features vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn_feature_selection.select_features(pn.y_var).copy()\n",
    "\n",
    "X2_rest = pn.y_var.copy()\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cv_summary2 = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2_rest, trial_ids=pn.y_var['segment'].values)\n",
    "\n",
    "\n",
    "label1 = \"Selected Features\"\n",
    "label2 = \"All\"\n",
    "cca_cv_compare_data.plot_cv_cca_compare_all(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# # Or call individual plots if you prefer:\n",
    "# cca_cv_compare_data.plot_cv_means_sd(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_all_folds_overlay(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_mean_difference(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_train_test_gap(cv_summary, cv_summary2, labels=(label1, label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# Selected features + Eyes vs All Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "\n",
    "eye_keywords = (\"eye\", \"gaze\", \"LD\", \"RD\")\n",
    "eye_cols = [col for col in pn.y_var.columns if any(k in col for k in eye_keywords)]\n",
    "X2 = pn_feature_selection.select_features(pn.y_var).copy()\n",
    "X2 = pd.concat([X2, pn.y_var[eye_cols]], axis=1)\n",
    "\n",
    "X2_rest = pn.y_var_reduced.copy()\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cv_summary2 = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2_rest, trial_ids=pn.y_var['segment'].values)\n",
    "\n",
    "\n",
    "label1 = \"Selected Features + Eyes\"\n",
    "label2 = \"All features reduced\"\n",
    "cca_cv_compare_data.plot_cv_cca_compare_all(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# # Or call individual plots if you prefer:\n",
    "# cca_cv_compare_data.plot_cv_means_sd(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_all_folds_overlay(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_mean_difference(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_train_test_gap(cv_summary, cv_summary2, labels=(label1, label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# All vs Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn.y_var.copy()\n",
    "X2_rest = pn.y_var_reduced.copy()\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cv_summary2 = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2_rest, trial_ids=pn.y_var['segment'].values)\n",
    "\n",
    "\n",
    "label1 = \"All features\"\n",
    "label2 = \"All features reduced\"\n",
    "cca_cv_compare_data.plot_cv_cca_compare_all(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# # Or call individual plots if you prefer:\n",
    "# cca_cv_compare_data.plot_cv_means_sd(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_all_folds_overlay(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_mean_difference(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_train_test_gap(cv_summary, cv_summary2, labels=(label1, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn.y_var.copy()\n",
    "X2_rest = pn.y_var_reduced.copy()\n",
    "\n",
    "cv_summary = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2, trial_ids=pn.y_var['segment'].values)\n",
    "cv_summary2 = cca_cv_utils2.conduct_cca_cv(X1_unscaled=X1, X2_unscaled=X2_rest, trial_ids=pn.y_var['segment'].values)\n",
    "\n",
    "\n",
    "label1 = \"All features\"\n",
    "label2 = \"All features reduced\"\n",
    "cca_cv_compare_data.plot_cv_cca_compare_all(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# # Or call individual plots if you prefer:\n",
    "# cca_cv_compare_data.plot_cv_means_sd(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_all_folds_overlay(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_mean_difference(cv_summary, cv_summary2, labels=(label1, label2))\n",
    "# cca_cv_compare_data.plot_cv_train_test_gap(cv_summary, cv_summary2, labels=(label1, label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Pinpoint features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_cv_utils_stage2 import cca_cv_utils2, cca_cv_compare_data, pinpoint_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## CV permutation importance (no retraining per feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "# # X2 = pn.y_var.drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "# X2 = pn.y_var.copy()\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X1_sc, X2_sc = scaler.fit_transform(\n",
    "#     X1), scaler.fit_transform(X2)\n",
    "\n",
    "# # all_names is a list of feature names for the all data set\n",
    "# imp = pinpoint_features.cv_cca_perm_importance(X2_sc, X1_sc, X2.columns,\n",
    "#                              n_components=10, reg=1e-2, n_splits=5,\n",
    "#                              groups=pn.y_var['segment'].values, max_components_for_score=3)\n",
    "# imp.head(20)  # top contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_X1, diag_X1, top_abs, top_pct = pinpoint_features.run_perm_importance_X1(\n",
    "    X2_sc, X1_sc, X2.columns,\n",
    "    n_components=10, reg=1e-2, n_splits=5,\n",
    "    Kfirst=3, top_k=20, verbose=True, make_plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## CV leave-one-out Δρ (re-train per feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-one-out Δρ for all features (re-fit per feature)\n",
    "imp_loo = pinpoint_features.cv_cca_leave1out_delta(\n",
    "    X2_sc, X1_sc, X2.columns,\n",
    "    n_components=10, reg=1e-2,\n",
    "    n_splits=5, random_state=0, groups=pn.y_var['segment'].values,\n",
    "    max_components_for_score=3   # average drop over first K comps\n",
    ")\n",
    "print(imp_loo.head(20))          # top contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## structure coefficients\n",
    "\n",
    "Note: The sign is arbitrary (CCA axes can flip), so focus on magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Held-out structure coefficients: corr(feature_j, X1 canonical comp_k) on test folds\n",
    "sc_df = pinpoint_features.cv_structure_coefficients(\n",
    "    X2_sc, X1_sc, X2.columns,\n",
    "    n_components=10, reg=1e-2,\n",
    "    n_splits=5, random_state=0, groups=pn.y_var['segment'].values,\n",
    ")\n",
    "# Features most aligned with the first canonical mode:\n",
    "print(sc_df.loc[:, [\"feature\", \"SC_comp1\"]].reindex(\n",
    "      sc_df.index,).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc_df is your structure-coefficient table with SC_comp1..SC_compK\n",
    "top = sc_df.assign(abs1=np.abs(sc_df[\"SC_comp1\"])).nlargest(25, \"abs1\")\n",
    "H = top[[c for c in sc_df.columns if c.startswith(\"SC_comp\")]].to_numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.imshow(np.abs(H[:, :5]), aspect=\"auto\")\n",
    "plt.yticks(range(len(top)), top[\"feature\"])\n",
    "plt.xticks(range(5), [f\"Comp {i+1}\" for i in range(5)])\n",
    "plt.colorbar(label=\"|SC|\")\n",
    "plt.title(\"Held-out structure coefficients (top by comp1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# CCA (original class)\n",
    "\n",
    "https://medium.com/@pozdrawiamzuzanna/canonical-correlation-analysis-simple-explanation-and-python-example-a5b8e97648d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If error occurs, try reducing y_var again, and can also try pn.y_var_reduced.corr()[pn.y_var_reduced.corr() > 0.9]\n",
    "\n",
    "\n",
    "X1 = pn.x_var_reduced[[col for col in pn.x_var_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "# X2 = pn.y_var_reduced.drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2 = pn.y_var.copy()\n",
    "cca_no_lag = cca_class.CCAclass(X1=X1, \n",
    "                                X2=X2, \n",
    "                                lagging_included=False)\n",
    "cca_no_lag.conduct_cca()\n",
    "\n",
    "X1_lags = pn.x_var_lags_reduced[[col for col in pn.x_var_lags_reduced.columns if col.startswith('cluster_')]].drop(columns=['bin', 'segment'], errors='ignore').copy()\n",
    "X2_lags = pn.y_var_lags_reduced.copy()\n",
    "cca_lags = cca_class.CCAclass(X1=X1_lags, \n",
    "                              X2=X2_lags, \n",
    "                              lagging_included=True)\n",
    "# for all columns that end with _0, rename them to the column name without the _0\n",
    "cca_lags.X2.columns = cca_lags.X2.columns.str.replace('_0', '')\n",
    "cca_lags.conduct_cca()\n",
    "\n",
    "\n",
    "print(f'pn.x_var_lags.shape: {pn.x_var_lags.shape}')\n",
    "print(f'pn.y_var_lags_reduced.shape: {pn.y_var_lags_reduced.shape}')\n",
    "\n",
    "cca_inst = cca_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## X2 loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_no_lag.plot_X2_loadings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_lags.plot_X2_loadings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# Test lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## compared to baseline model\n",
    "\n",
    "BASE = “baseline design matrix” (all other predictors, no lags for this feature).\n",
    "\n",
    "BASE + best1 = baseline + the single best lag.\n",
    "\n",
    "BASE + all = baseline + the whole lag block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiff_code/methods/neural_data_analysis/neural_analysis_tools/cca_methods/advanced_cca_tools/test_lags_in_cca.py\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.advanced_cca_tools import test_lags_in_cca, partial_cca_test, partition_x_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_test = ['monkey_speeddummy', 'RDz', 'gaze_mky_vew_y_l', 'gaze_mky_vew_y_r'\n",
    "                    'abs_diff_in_angle_to_nxt_ff', 'abs_diff_in_abs_angle_to_nxt_ff',\n",
    "                    'cur_cntr_arc_curv', 'turning_right']\n",
    "\n",
    "for feature in features_to_test:\n",
    "    # find lagged columns in X2_lags\n",
    "    lag_cols = [col for col in X2_lags.columns if feature in col]\n",
    "    if len(lag_cols) == 0:\n",
    "        print(f\"No lagged columns found for {feature}\")\n",
    "        continue\n",
    "    # find their indices in X2_lags\n",
    "    lag_cols_indices = [X2_lags.columns.get_loc(col) for col in lag_cols]\n",
    "\n",
    "\n",
    "    print('===============================================')\n",
    "    print(f'Testing {feature}')\n",
    "    res = test_lags_in_cca.evaluate_lag_block_in_full_model(X2_lags, X1_lags, lag_block_cols=lag_cols_indices, n_splits=5, random_state=1)\n",
    "    print(\"Test cancorr means:\")\n",
    "    print(\"  BASE                :\", res.test_mean_BASE)\n",
    "    print(\"  BASE + best single  :\", res.test_mean_BASE_plus_best1)\n",
    "    print(\"  BASE + all lags     :\", res.test_mean_BASE_plus_all)\n",
    "    print(\"Δ(all - BASE):\", res.delta_all_vs_base, \"  Δ(all - best1):\", res.delta_all_vs_best1)\n",
    "    print(\"Best single lag (per fold):\", res.best_single_indices)\n",
    "    print(\"Partial structure loadings (full model):\", res.partial_loadings_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_full: (n, p) design matrix with ALL features (including the lagged ones)\n",
    "# Y:      (n, q) opposite view\n",
    "# lag_block_cols: list of column indices in X_full for the ONE feature's lags you want to inspect\n",
    "#\n",
    "res = test_lags_in_cca.evaluate_lag_block_in_full_model(X2_lags, X1_lags, lag_block_cols=lag_cols_indices, n_splits=5, random_state=1)\n",
    "print(\"Test cancorr means:\")\n",
    "print(\"  BASE                :\", res.test_mean_BASE)\n",
    "print(\"  BASE + best single  :\", res.test_mean_BASE_plus_best1)\n",
    "print(\"  BASE + all lags     :\", res.test_mean_BASE_plus_all)\n",
    "print(\"Δ(all - BASE):\", res.delta_all_vs_base, \"  Δ(all - best1):\", res.delta_all_vs_best1)\n",
    "print(\"Best single lag (per fold):\", res.best_single_indices)\n",
    "print(\"Partial structure loadings (full model):\", res.partial_loadings_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## plot lag block loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_lag_block_in_full_model(\n",
    "    X_full=pn.y_var_lags_reduced,\n",
    "    Y=pn.x_var_lags_reduced,\n",
    "    lag_block_cols=lag_cols_indices,\n",
    "    n_splits=5, random_state=1\n",
    ")\n",
    "\n",
    "plot_lag_block_loadings(res.partial_loadings_full,\n",
    "                        best_single_indices=res.best_single_indices,\n",
    "                        title=\"MyFeature lag footprint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## Partial CCA incremental test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., columns like: 'speed_lag0', 'speed_lag1', ..., 'speed_lag10'\n",
    "out = partition_x_utils.partition_X_base_block(\n",
    "    X=X2_lags, \n",
    "    block_name_regex=r\"^monkey_speeddummy_\\d+$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = partial_cca_test.partial_cca_incremental_cv(\n",
    "    X2_lags, X1_lags, lag_block_cols=lag_cols_indices,\n",
    "    n_splits=5,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "print(\"Mean TEST partial cancorr:\", res.mean_test_partial_cancorr)\n",
    "print(\"Fold TEST partial cancorr:\", res.fold_test_partial_cancorr)\n",
    "print(\"Mean TRAIN partial cancorr:\", res.mean_train_partial_cancorr)\n",
    "print(\"Notes:\", res.notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## replace with bases\n",
    "\n",
    "(not working yet...might be better to use methods from my design_bases or transform_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neural_data_analysis.neural_analysis_tools.glm_tools.tpg import glm_bases\n",
    "\n",
    "# # Suppose lag_block_cols = indices of this feature’s lags in X_full\n",
    "# X_full = X2_lags\n",
    "# lag_block_cols = lag_cols_indices\n",
    "\n",
    "# X_block = X_full.iloc[:, lag_block_cols].to_numpy()   # shape (n, L)\n",
    "# B, centers = glm_bases.raised_cosine_basis(n_basis=4, n_lags=X_block.shape[1])\n",
    "# X_basis = X_block @ B    # shape (n, 4)\n",
    "\n",
    "# mask_block = np.zeros(X_full[1], dtype=bool)\n",
    "# mask_block[np.asarray(lag_block_cols, dtype=int)] = True\n",
    "    \n",
    "# # Now build a new X_full with raw lag block replaced\n",
    "# X_new = np.concatenate([X_full.iloc[:, ~mask_block].to_numpy(), X_basis], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "# Hyperparam tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import rcca\n",
    "\n",
    "def _pairwise_finite_mask(A, B):\n",
    "    return np.isfinite(A).all(1) & np.isfinite(B).all(1)\n",
    "\n",
    "def _drop_low_variance(X, tol=1e-12):\n",
    "    keep = np.nanvar(X, axis=0) > tol\n",
    "    return X[:, keep], keep\n",
    "\n",
    "def cv_cca_pyrcca_safe(X1, X2, reg=1e-2, n_components=10, n_splits=5, random_state=0, var_tol=1e-12):\n",
    "    # 1) Pairwise finite rows only\n",
    "    mask = _pairwise_finite_mask(X1, X2)\n",
    "    X1, X2 = X1[mask], X2[mask]\n",
    "\n",
    "    # 2) Drop near-constant columns globally\n",
    "    X1, keep1 = _drop_low_variance(X1, tol=var_tol)\n",
    "    X2, keep2 = _drop_low_variance(X2, tol=var_tol)\n",
    "\n",
    "    if X1.shape[1] == 0 or X2.shape[1] == 0 or len(X1) < n_splits:\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    n_components = int(min(n_components, X1.shape[1], X2.shape[1]))\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold_scores = []\n",
    "\n",
    "    for tr, va in kf.split(X1):\n",
    "        X1_tr, X2_tr = X1[tr], X2[tr]\n",
    "        X1_va, X2_va = X1[va], X2[va]\n",
    "\n",
    "        # 3) Re-drop any columns that become zero-variance within this split\n",
    "        X1_tr, k1_tr = _drop_low_variance(X1_tr, tol=var_tol)\n",
    "        X2_tr, k2_tr = _drop_low_variance(X2_tr, tol=var_tol)\n",
    "        X1_va = X1_va[:, k1_tr]\n",
    "        X2_va = X2_va[:, k2_tr]\n",
    "\n",
    "        if X1_tr.shape[1] == 0 or X2_tr.shape[1] == 0:\n",
    "            fold_scores.append(float(\"-inf\"))\n",
    "            continue\n",
    "\n",
    "        cc = min(n_components, X1_tr.shape[1], X2_tr.shape[1])\n",
    "\n",
    "        cca = rcca.CCA(kernelcca=False, reg=reg, numCC=cc)\n",
    "        cca.train([X1_tr, X2_tr])\n",
    "        cca.validate([X1_va, X2_va])  # computes held-out correlations\n",
    "\n",
    "        # 4) Aggregate: pyrcca stores per-view, per-component correlations in cca.corrs\n",
    "        # Guard against NaNs if a component’s std is ~0 on the val fold.\n",
    "        try:\n",
    "            view_means = [np.nanmean(c) for c in cca.corrs]  # list per view\n",
    "            score = float(np.nanmean(view_means))\n",
    "        except Exception:\n",
    "            score = float(\"-inf\")\n",
    "\n",
    "        if not np.isfinite(score):\n",
    "            score = float(\"-inf\")\n",
    "        fold_scores.append(score)\n",
    "\n",
    "    # Mean over folds (if all -inf, return -inf)\n",
    "    finite_scores = [s for s in fold_scores if np.isfinite(s)]\n",
    "    return float(np.mean(finite_scores)) if finite_scores else float(\"-inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pn.x_var_reduced.copy()\n",
    "X2 = pn.y_var_reduced.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import rcca  # or sklearn.cross_decomposition.CCA\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import rcca\n",
    "\n",
    "# def cv_cca_pyrcca(X1, X2, reg, n_components, n_splits=5, random_state=0):\n",
    "#     kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "#     scores = []\n",
    "#     for tr, va in kf.split(X1):\n",
    "#         cca = rcca.CCA(kernelcca=False, reg=reg, numCC=n_components)\n",
    "#         cca.train([X1[tr], X2[tr]])\n",
    "#         cca.validate([X1[va], X2[va]])          # <- pyrcca way\n",
    "#         # cca.corrs is a list (one per view) of per-dimension correlations.\n",
    "#         # Aggregate to a single score (mean across views & dimensions):\n",
    "#         view_means = [np.nanmean(c) for c in cca.corrs]\n",
    "#         scores.append(np.nanmean(view_means))\n",
    "#     return float(np.mean(scores))\n",
    "\n",
    "\n",
    "coarse_regs = np.array([1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1.0, 3.0])\n",
    "def refine_reg_grid(best_reg, k=5, base=np.sqrt(10)):\n",
    "    # builds k values below and above best_reg, plus best_reg itself\n",
    "    downs = best_reg / (base ** np.arange(k, 0, -1))\n",
    "    ups   = best_reg * (base ** np.arange(1, k+1))\n",
    "    return np.unique(np.concatenate([downs, [best_reg], ups]))\n",
    "\n",
    "def components_grid(X1, X2):\n",
    "    rank_max = int(min(X1.shape[1], X2.shape[1], X1.shape[0]-1))\n",
    "    base = [1, 2, 3, 5, 8, 10, 12, 15, 20, 30]\n",
    "    return [k for k in base if k <= rank_max] or [1]\n",
    "\n",
    "\n",
    "# Stage 1: coarse\n",
    "regs = coarse_regs\n",
    "n_comps = components_grid(X1, X2)\n",
    "\n",
    "best = {\"score\": -np.inf, \"reg\": None, \"n\": None}\n",
    "for reg in regs:\n",
    "    for n in n_comps:\n",
    "        s = cv_cca_pyrcca_safe(X1.values, X2.values, reg=reg, n_components=n, n_splits=5)\n",
    "        if s > best[\"score\"]:\n",
    "            best = {\"score\": s, \"reg\": reg, \"n\": n}\n",
    "\n",
    "print(\"Best:\", best)\n",
    "\n",
    "# Stage 2: fine (only around best λ; keep n grid the same)\n",
    "regs_fine = refine_reg_grid(best[\"reg\"], k=3)  # narrower if you like\n",
    "for reg in regs_fine:\n",
    "    for n in n_comps:\n",
    "        s = cv_cca_pyrcca_safe(X1.values, X2.values, reg=reg, n_components=n, n_splits=5)\n",
    "        if s > best[\"score\"]:\n",
    "            best = {\"score\": s, \"reg\": reg, \"n\": n}\n",
    "\n",
    "print(\"Best:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
