{"cells":[{"cell_type":"markdown","id":"8446ba7d","metadata":{"id":"8446ba7d"},"source":["Note: all \".to(device)\" are deleted because Apple M1 chip does does support it."]},{"cell_type":"markdown","id":"b83af57b","metadata":{"id":"b83af57b"},"source":["Would recommend using Google Colab instead because it will be much faster"]},{"cell_type":"markdown","id":"KMRCk6qpFsyH","metadata":{"id":"KMRCk6qpFsyH"},"source":["Source of LSTM codes:\n","https://github.com/quantumiracle/Popular-RL-Algorithms/blob/master/sac_v2_lstm.py"]},{"cell_type":"markdown","id":"e884123b","metadata":{"id":"e884123b","toc":true},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#env\" data-toc-modified-id=\"env-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>env</a></span><ul class=\"toc-item\"><li><span><a href=\"#d22:-no-noise;-fixed-wgain\" data-toc-modified-id=\"d22:-no-noise;-fixed-wgain-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>d22: no noise; fixed wgain</a></span></li></ul></li><li><span><a href=\"#make-LSTM-agent\" data-toc-modified-id=\"make-LSTM-agent-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>make LSTM agent</a></span></li><li><span><a href=\"#TRAIN\" data-toc-modified-id=\"TRAIN-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TRAIN</a></span></li><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Test</a></span><ul class=\"toc-item\"><li><span><a href=\"#test-and-save-variables\" data-toc-modified-id=\"test-and-save-variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>test and save variables</a></span></li></ul></li><li><span><a href=\"#Animation\" data-toc-modified-id=\"Animation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Animation</a></span></li></ul></div>"]},{"cell_type":"markdown","id":"9v84SVugD_4N","metadata":{"id":"9v84SVugD_4N"},"source":["# Set up"]},{"cell_type":"markdown","id":"2zXSUqm6EmCJ","metadata":{"id":"2zXSUqm6EmCJ"},"source":["## install packages"]},{"cell_type":"code","execution_count":null,"id":"KHTF-1PvqrtN","metadata":{"id":"KHTF-1PvqrtN"},"outputs":[],"source":["from google.colab import drive # import drive from google colab\n","drive.mount(\"/content/drive\") \n","!pip install neo\n","!pip install matplotlib_scalebar\n","!pip install ffmpeg\n","!pip install stable_baselines3\n","!pip install optuna"]},{"cell_type":"markdown","id":"93C64_FAEoSJ","metadata":{"id":"93C64_FAEoSJ"},"source":["## import packages"]},{"cell_type":"code","execution_count":null,"id":"06f9c7f3","metadata":{"id":"06f9c7f3","scrolled":true},"outputs":[],"source":["%cd /content/drive/MyDrive/ff_repo/Multifirefly-Project\n","from multiff_analysis.functions.RL import collect_agent_data, LSTM_functions, env\n","from multiff_analysis.functions.data_wrangling import find_patterns\n","from multiff_analysis.functions.data_visualization import animation_func\n","from RL.LSTM_agent_params import *\n","\n","\n","import os\n","import torch\n","import numpy as np\n","import pickle\n","from gym import spaces, Env\n","import torch\n","import optuna\n","from numpy import pi\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from torch.linalg import vector_norm\n","from IPython.display import HTML\n","from functools import partial\n","from optuna.pruners import MedianPruner\n","from optuna.samplers import TPESampler\n","plt.rcParams[\"animation.html\"] = \"html5\"\n","torch.set_printoptions(sci_mode=False)\n","np.set_printoptions(suppress=True)\n","\n","device_idx = 0\n","device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n","## if using Jupyter Notebook\n","# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","log_dir = \"RL_models/LSTM_stored_models/LSTM_Jan_2\"\n","os.makedirs(log_dir, exist_ok=True)\n","PLAYER = \"agent\""]},{"cell_type":"markdown","id":"ksS6tZmRHeBz","metadata":{"id":"ksS6tZmRHeBz"},"source":["## make agent"]},{"cell_type":"code","execution_count":null,"id":"fI0dTXEYKhHx","metadata":{"id":"fI0dTXEYKhHx"},"outputs":[],"source":["replay_buffer_size=100\n","replay_buffer = LSTM_functions.ReplayBufferLSTM2(replay_buffer_size)\n","sac_model=LSTM_functions.SAC_Trainer(replay_buffer, state_space, action_space, hidden_dim=hidden_dim, action_range=action_range,\\\n","                      gamma = gamma, soft_q_lr = soft_q_lr, policy_lr = policy_lr, alpha_lr = alpha_lr, \\\n","                      batch_size = batch_size, update_itr = update_itr, reward_scale = reward_scale, \\\n","                      target_entropy = target_entropy, soft_tau = soft_tau, train_freq = train_freq, device = device)"]},{"cell_type":"markdown","id":"8EXJ_gBhOfXm","metadata":{"id":"8EXJ_gBhOfXm"},"source":["## load agent (optional)"]},{"cell_type":"code","execution_count":null,"id":"p7psub5tOf-Z","metadata":{"id":"p7psub5tOf-Z"},"outputs":[],"source":["# Load agent\n","sac_model.load_model(log_dir)\n","\n","# Load buffer\n","buffer_path = os.path.join(log_dir, 'buffer.pkl')\n","with open(buffer_path, 'rb') as f:\n","  replay_buffer = pickle.load(f)"]},{"cell_type":"markdown","id":"RKfXsLnYEQn2","metadata":{"id":"RKfXsLnYEQn2"},"source":["# Train agent"]},{"cell_type":"code","execution_count":null,"id":"N5YiwnFlonkc","metadata":{"id":"N5YiwnFlonkc"},"outputs":[],"source":["replay_buffer_size=100\n","replay_buffer = LSTM_functions.ReplayBufferLSTM2(replay_buffer_size)\n","sac_model=LSTM_functions.SAC_Trainer(replay_buffer, state_space, action_space, hidden_dim=hidden_dim, action_range=action_range,\\\n","                      gamma = gamma, soft_q_lr = soft_q_lr, policy_lr = policy_lr, alpha_lr = alpha_lr, \\\n","                      batch_size = batch_size, update_itr = update_itr, reward_scale = reward_scale, \\\n","                      target_entropy = target_entropy, soft_tau = soft_tau, train_freq = train_freq, device = device)\n","\n","env = env.AdaptForLSTM()\n","log_dir = \"RL_models/LSTM_stored_models/LSTM_Jan_11\"\n","os.makedirs(log_dir, exist_ok=True)\n","\n","sac_model.soft_q_net1.train()\n","sac_model.soft_q_net2.train()\n","sac_model.policy_net.train()\n","\n","sac_model, best_avg_reward_record = LSTM_functions.train_LSTM_agent(env, sac_model, device, action_dim=2, log_dir = log_dir,\n","                                                                    hidden_dim=128, train_freq=100, batch_size=10, update_itr=1,\n","                                                                    num_train_episodes=10000, eval_freq=15, max_steps=1024, AUTO_ENTROPY=True, \n","                                                                    DETERMINISTIC=False, num_eval_episodes=3, print_episode_reward = True)"]},{"cell_type":"markdown","id":"20598964","metadata":{"id":"20598964"},"source":["# Test agent"]},{"cell_type":"code","execution_count":null,"id":"a70b89f7","metadata":{"id":"a70b89f7"},"outputs":[],"source":["num_epi_for_testing = 5\n","env = env.AdaptForLSTM()\n","env.flash_on_interval = 0.3\n","env.distance2center_cost = 0\n","sac_model.load_model(log_dir)\n","last_action = env.action_space.sample()            \n","hidden_out = (torch.zeros([1, 1, hidden_dim], dtype=torch.float).to(device), torch.zeros([1, 1, hidden_dim], dtype=torch.float).to(device))  \n","total_reward = 0\n","  \n","for eps in range(num_epi_for_testing):\n","    state =  env.reset()\n","    episode_reward = 0\n","    hidden_out = (torch.zeros([1, 1, hidden_dim], dtype=torch.float).to(device), torch.zeros([1, 1, hidden_dim], dtype=torch.float).to(device))  \n","    for step in range(max_steps):\n","        hidden_in = hidden_out\n","        action, hidden_out = sac_model.policy_net.get_action(state, last_action, hidden_in, deterministic = DETERMINISTIC)\n","        next_state, reward, done, _ = env.step(action)   \n","        last_action = action\n","        episode_reward += reward\n","        state=next_state\n","    total_reward += episode_reward\n","    print('Episode: ', eps, '| Episode Reward: ', episode_reward)\n","print(\"Average reward per episode: \", total_reward/num_epi_for_testing)"]},{"cell_type":"markdown","id":"PkFUlYfELK_e","metadata":{"id":"PkFUlYfELK_e"},"source":["# Optuna (LSTM)\n","\n","(my own codes)"]},{"cell_type":"markdown","id":"d0vtL5qnLQ0e","metadata":{"id":"d0vtL5qnLQ0e"},"source":["##### sample_sac_params"]},{"cell_type":"code","execution_count":null,"id":"CM9Yhsb7LQ0e","metadata":{"id":"CM9Yhsb7LQ0e"},"outputs":[],"source":["def sample_sac_params(trial):\n","    \"\"\"\n","    Sampler for SAC hyperparams.\n","    :param trial: (optuna.trial)\n","    :return: (dict)\n","    \"\"\"\n","  \n","    gamma = 1.0 - trial.suggest_float(\"1-gamma\", 1e-4, 0.1, log=True)\n","    soft_q_lr = trial.suggest_float(\"soft_q_lr\", 1e-5, 1, log=True)\n","    policy_lr = trial.suggest_float(\"policy_lr\", 1e-5, 1, log=True)\n","    alpha_lr  = trial.suggest_float(\"alpha_lr\", 1e-5, 1, log=True)\n","    batch_size  = trial.suggest_categorical('batch_size', [5, 10, 15, 20, 25, 30])\n","    update_itr = trial.suggest_categorical('update_itr', [1, 2, 3, 5])\n","    hidden_dim = trial.suggest_categorical('hidden_dim', [16, 32, 64, 100, 150, 200, 256])\n","    reward_scale = trial.suggest_categorical('reward_scale', [1, 3, 5, 10, 15, 20]) # I updated after running\n","    target_entropy = trial.suggest_categorical('target_entropy', [-1, -2, -3, -5, -8, -10]) # I updated after running\n","    soft_tau= trial.suggest_float(\"soft_tau\", 1e-6, 1, log=True)\n","    #activation_fn\n","\n","\n","    return {\n","        'gamma': gamma,\n","        'soft_q_lr':soft_q_lr,\n","        'policy_lr':policy_lr,\n","        'alpha_lr':alpha_lr,\n","        'batch_size': batch_size,\n","        'update_itr':update_itr,\n","        'hidden_dim': hidden_dim,\n","        'reward_scale':reward_scale,\n","        'target_entropy':target_entropy,\n","        'soft_tau':soft_tau\n","    }"]},{"cell_type":"markdown","id":"w8snZtlopA-9","metadata":{"id":"w8snZtlopA-9"},"source":["## put_in_fixed_params"]},{"cell_type":"code","execution_count":null,"id":"1RFcdEk5pAmv","metadata":{"id":"1RFcdEk5pAmv"},"outputs":[],"source":["def put_in_fixed_params():\n","    return {\n","        'log_dir':  None, \n","        'train_freq': 100, \n","        'batch_size': 10, \n","        'update_itr': 1,\n","        'num_train_episodes': 50, \n","        'eval_freq': 10, \n","        'max_steps': 1024, \n","        'AUTO_ENTROPY': True, \n","        'DETERMINISTIC': False, \n","        'num_eval_episodes': 3, \n","        'print_episode_reward':  True}"]},{"cell_type":"markdown","id":"9TMGTKP3LTVV","metadata":{"id":"9TMGTKP3LTVV"},"source":["## objective"]},{"cell_type":"code","execution_count":null,"id":"NhoGtlzHqxKY","metadata":{"id":"NhoGtlzHqxKY"},"outputs":[],"source":["def objective(trial: optuna.Trial) -> float: \n","  try:\n","    # Sample hyperparameters\n","    kwargs = sample_sac_params(trial)\n","    gamma = kwargs['gamma']\n","    soft_q_lr = kwargs['soft_q_lr']\n","    policy_lr = kwargs['policy_lr']\n","    alpha_lr = kwargs['alpha_lr']\n","    batch_size = kwargs['batch_size']\n","    update_itr = kwargs['update_itr']\n","    hidden_dim = kwargs['hidden_dim']\n","    reward_scale = kwargs['reward_scale']\n","    target_entropy = kwargs['target_entropy']\n","    soft_tau = kwargs['soft_tau']\n","\n","\n","    kwargs = put_in_fixed_params()\n","    log_dir = kwargs['log_dir']\n","    train_freq = kwargs['train_freq']\n","    batch_size = kwargs['batch_size'] \n","    update_itr = kwargs['update_itr']\n","    num_train_episodes = kwargs['num_train_episodes'] \n","    eval_freq = kwargs['eval_freq']\n","    max_steps = kwargs['max_steps'] \n","    AUTO_ENTROPY = kwargs['AUTO_ENTROPY'] \n","    DETERMINISTIC = kwargs['DETERMINISTIC'] \n","    num_eval_episodes = kwargs['num_eval_episodes'] \n","    print_episode_reward = kwargs['print_episode_reward']\n","\n","\n","    env = env.AdaptForLSTM()\n","    action_space = env.action_space\n","    state_space = env.observation_space\n","    action_dim = action_space.shape[0]\n","    replay_buffer_size = 100\n","    replay_buffer = LSTM_functions.ReplayBufferLSTM2(replay_buffer_size)\n","    sac_model = LSTM_functions.SAC_Trainer(replay_buffer, state_space, action_space, hidden_dim=hidden_dim, action_range=action_range,\\\n","                            gamma = gamma, soft_q_lr = soft_q_lr, policy_lr = policy_lr, alpha_lr = alpha_lr, \\\n","                            batch_size = batch_size, update_itr = update_itr, reward_scale = reward_scale, \\\n","                            target_entropy = target_entropy, soft_tau = soft_tau, train_freq = train_freq)\n","    sac_model.soft_q_net1.train()\n","    sac_model.soft_q_net2.train()\n","    sac_model.policy_net.train()\n","\n","    sac_model, best_avg_reward_record = LSTM_functions.train_LSTM_agent(env, sac_model, device, log_dir = log_dir, action_dim=action_dim, \n","                                                         hidden_dim=hidden_dim, train_freq=train_freq, batch_size=batch_size, update_itr=update_itr,\n","                                                         num_train_episodes=num_train_episodes, eval_freq=eval_freq, max_steps=max_steps, AUTO_ENTROPY=AUTO_ENTROPY, \n","                                                         DETERMINISTIC=DETERMINISTIC, num_eval_episodes=num_eval_episodes, print_episode_reward=print_episode_reward)\n","\n","  except ValueError as e:\n","    # Sometimes, random hyperparams can generate NaN\n","      print(e)\n","\n","  return best_avg_reward_record"]},{"cell_type":"markdown","id":"zWLQGb9cW2TQ","metadata":{"id":"zWLQGb9cW2TQ"},"source":["## run"]},{"cell_type":"code","execution_count":null,"id":"L4wV8ncwW2TQ","metadata":{"id":"L4wV8ncwW2TQ"},"outputs":[],"source":["N_TRIALS = 100\n","N_STARTUP_TRIALS = 5\n","\n","# Set pytorch num threads to 1 for faster training\n","torch.set_num_threads(1)\n"," \n","sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n","## Do not prune before 1/3 of the max budget is used\n","# pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS 2//3 3)\n","\n","study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n","try:\n","    study.optimize(objective, n_trials=N_TRIALS)\n","except KeyboardInterrupt:\n","    pass\n","\n","print(\"Number of finished trials: \", len(study.trials))\n","\n","print(\"Best trial:\")\n","trial = study.best_trial\n","\n","print(\"  Value: \", trial.value)\n","\n","print(\"  Params: \")\n","for key, value in trial.params.items():\n","    print(\"    {}: {}\".format(key, value))\n","\n","print(\"  User attrs:\")\n","for key, value in trial.user_attrs.items():\n","    print(\"    {}: {}\".format(key, value))"]},{"cell_type":"markdown","id":"QvPXVRFfIbVD","metadata":{"id":"QvPXVRFfIbVD"},"source":["# Animation"]},{"cell_type":"markdown","id":"Z5vjDrdHrSn2","metadata":{"id":"Z5vjDrdHrSn2"},"source":["## collect data"]},{"cell_type":"code","execution_count":null,"id":"yDZgRZMNHnZl","metadata":{"id":"yDZgRZMNHnZl"},"outputs":[],"source":["env = env.CollectInformationLSTM()\n","env.flash_on_interval = 0.3\n","env.distance2center_cost = 0\n","sac_model.load_model(log_dir)\n","\n","\n","\n","monkey_information, ff_flash_sorted, ff_caught_T_sorted, ff_believed_position_sorted, \\\n","           ff_real_position_sorted, ff_life_sorted, ff_flash_end_sorted, caught_ff_num, total_ff_num, \\\n","           obs_ff_unique_identifiers, sorted_indices_all \\\n","           = collect_agent_data.collect_agent_data_func(env, sac_model, n_steps = 2000, LSTM = True, hidden_dim= hidden_dim, device = device, deterministic = False)\n","\n","\n","ff_dataframe = make_ff_dataframe.make_ff_dataframe.make_ff_dataframe_func(monkey_information, ff_caught_T_sorted, ff_flash_sorted,  ff_real_position_sorted, ff_life_sorted, \\\n","                                 player = \"agent\", max_distance = 400, data_folder_name = None, num_missed_index = 0, truncate = False, \\\n","                                 obs_ff_unique_identifiers = obs_ff_unique_identifiers, sorted_indices_all = sorted_indices_all, \\\n","                                 ff_noisy_xy_in_obs = ff_noisy_xy_in_obs)\n","\n","min_point_index, max_point_index = np.min(np.array(ff_dataframe['point_index'])), np.max(np.array(ff_dataframe['point_index']))\n","\n","n_ff_in_a_row = find_patterns.n_ff_in_a_row_func(ff_believed_position_sorted, distance_between_ff = 50)\n","visible_before_last_one_trials = find_patterns.visible_before_last_one_func(ff_dataframe)\n","disappear_latest_trials = find_patterns.disappear_latest_func(ff_dataframe)\n","ignore_sudden_flash_trials, ignore_sudden_flash_indices, ignore_sudden_flash_indices_for_anim, ff_target_pairs = find_patterns.ignore_sudden_flash_func(ff_dataframe, ff_real_position_sorted, max_point_index)\n","try_a_few_times_trials, try_a_few_times_indices, try_a_few_times_indices_for_anim = find_patterns.try_a_few_times_func(ff_caught_T_sorted, monkey_information, ff_believed_position_sorted, PLAYER, max_point_index)\n","give_up_after_trying_trials, give_up_after_trying_indices, give_up_after_trying_indices_for_anim = find_patterns.give_up_after_trying_func(ff_caught_T_sorted, monkey_information, ff_believed_position_sorted, PLAYER, max_point_index)\n","\n","annotation_info = animation_func.make_annotation_info(caught_ff_num, max_point_index, n_ff_in_a_row, visible_before_last_one_trials, disappear_latest_trials, \\\n","                                       ignore_sudden_flash_indices, give_up_after_trying_indices, try_a_few_times_indices)"]},{"cell_type":"markdown","id":"JlxfIO9YFFHe","metadata":{"id":"JlxfIO9YFFHe"},"source":["## prepare for animation"]},{"cell_type":"code","execution_count":null,"id":"6DqTSaOz6s38","metadata":{"id":"6DqTSaOz6s38"},"outputs":[],"source":["currentTrial = 2\n","num_trials = 7\n","k = 1\n","fig, ax = plt.subplots()\n","num_frames, anim_monkey_info, flash_on_ff_dict, alive_ff_dict, believed_ff_dict, new_num_trials, ff_dataframe_anim \\\n","            = animation_func.prepare_for_animation(ff_dataframe, ff_caught_T_sorted, ff_life_sorted, ff_believed_position_sorted, \n","            ff_real_position_sorted, ff_flash_sorted, monkey_information, k=k, currentTrial=currentTrial, num_trials=num_trials)\n","print(\"Number of frames is:\", num_frames)"]},{"cell_type":"markdown","id":"AesCxkpsFbVn","metadata":{"id":"AesCxkpsFbVn"},"source":["## make animation"]},{"cell_type":"code","execution_count":null,"id":"pUcR1X-0-OQo","metadata":{"id":"pUcR1X-0-OQo"},"outputs":[],"source":["animate_func = partial(animation_func.animate, ax=ax, anim_monkey_info=anim_monkey_info, ff_dataframe_anim=ff_dataframe_anim, ff_real_position_sorted=ff_real_position_sorted, \\\n","                         flash_on_ff_dict=flash_on_ff_dict, alive_ff_dict=alive_ff_dict, believed_ff_dict=believed_ff_dict, margin = 400)\n","anim = animation.FuncAnimation(fig, animate_func, frames=num_frames, interval=100, repeat=True) \n","HTML(anim.to_html5_video())"]},{"cell_type":"markdown","id":"-BX7XwsnFc4k","metadata":{"id":"-BX7XwsnFc4k"},"source":["## make animation with annotation"]},{"cell_type":"code","execution_count":null,"id":"aE9lp9YZ-H7c","metadata":{"id":"aE9lp9YZ-H7c"},"outputs":[],"source":["annotation_info = animation_func.make_annotation_info(caught_ff_num+1, max_point_index, n_ff_in_a_row, visible_before_last_one_trials, disappear_latest_trials, \\\n","                                        ignore_sudden_flash_indices, give_up_after_trying_indices, try_a_few_times_indices)\n","animate_annotated_func = partial(animation_func.animate_annotated, ax=ax, anim_monkey_info=anim_monkey_info, margin=margin, ff_dataframe=ff_dataframe, ff_real_position_sorted=ff_real_position_sorted, \\\n","                                   flash_on_ff_dict=flash_on_ff_dict, alive_ff_dict=alive_ff_dict, believed_ff_dict=believed_ff_dict, ff_caught_T_sorted=ff_caught_T_sorted, annotation_info=annotation_info)\n","anim_annotated = animation.FuncAnimation(fig, animate_annotated_func, frames=num_frames, interval=100, repeat=True) \n","HTML(anim_annotated.to_html5_video())"]},{"cell_type":"markdown","id":"h8mO9eLF5U7Y","metadata":{"id":"h8mO9eLF5U7Y"},"source":["# Debug"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1FShUys0iUmi3huyQwtaEdyhGivLG2R_5","timestamp":1681095282536}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"288px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":5}
