{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_folder = '/Users/dusiyi/Documents/Multifirefly-Project'\n",
    "os.chdir(project_folder)\n",
    "sys.path.append(os.path.join(project_folder, 'multiff_analysis', 'methods'))\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from non_behavioral_analysis.neural_data_analysis.get_neural_data import neural_data_processing\n",
    "from non_behavioral_analysis.neural_data_analysis.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from non_behavioral_analysis.neural_data_analysis.model_neural_data import cca_class, pgam_class, neural_data_modeling, reduce_multicollinearity\n",
    "from non_behavioral_analysis.neural_data_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from non_behavioral_analysis.neural_data_analysis.planning_neural import planning_neural_class, planning_neural_utils\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supply_info_of_cluster_to_df(df, ff_real_position_sorted, ff_life_sorted, monkey_information, max_cluster_distance=50):\n",
    "\n",
    "    ff_time = monkey_information.loc[df['point_index'].values, 'time'].values\n",
    "    ff_cluster = cluster_analysis.find_alive_ff_clusters(ff_real_position_sorted[df['ff_index'].values], ff_real_position_sorted, ff_time-10, ff_time+10,\n",
    "                                                         ff_life_sorted, max_distance=max_cluster_distance)\n",
    "    ff_cluster_df = cluster_analysis.turn_list_of_ff_clusters_info_into_dataframe(\n",
    "        ff_cluster, df['point_index'].values)\n",
    "    # new_df = decision_making_utils.find_many_ff_info_anew(ff_cluster_df['ff_index'].values, ff_cluster_df['point_index'].values, ff_real_position_sorted, ff_dataframe_visible, monkey_information)\n",
    "    return ff_cluster_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ff_cluster = cluster_analysis.find_alive_ff_clusters(ff_real_position_sorted[df['ff_index'].values], ff_real_position_sorted, ff_time-10, ff_time+10,\n",
    "                                                         ff_life_sorted, max_distance=max_cluster_distance)\n",
    "    ff_cluster_df = cluster_analysis.turn_list_of_ff_clusters_info_into_dataframe(\n",
    "        ff_cluster, df['point_index'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item.make_or_retrieve_target_clust_last_vis_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## or target cluster_analysis\n",
    "\n",
    "target_cluster_TAFT = target_clust_last_vis_df[target_clust_last_vis_df['target_index'].isin(try_a_few_times_trials)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_target_clust_last_vis_df(ff_dataframe, monkey_information, ff_caught_T_new, ff_real_position_sorted, ff_life_sorted, duration_of_evaluation=3,\n",
    "                                 max_distance_to_target_in_cluster=50, keep_all_rows=False):\n",
    "    ff_indices_of_each_cluster = find_alive_target_clusters(\n",
    "        ff_real_position_sorted, ff_caught_T_new, ff_life_sorted, max_distance=max_distance_to_target_in_cluster)\n",
    "    target_clust_last_vis_df = _get_target_clust_last_vis_df(ff_dataframe, monkey_information, ff_caught_T_new, ff_real_position_sorted,\n",
    "                                                             max_distance_to_target_in_cluster=max_distance_to_target_in_cluster, duration_of_evaluation=duration_of_evaluation)\n",
    "    target_clust_last_vis_df['nearby_alive_ff_indices'] = ff_indices_of_each_cluster\n",
    "    if not keep_all_rows:\n",
    "        # drop the rows whose last_vis_dist is 9999\n",
    "        target_clust_last_vis_df = target_clust_last_vis_df[target_clust_last_vis_df['last_vis_dist'] != 9999].copy(\n",
    "        )\n",
    "        # also drop target_index = 0\n",
    "        target_clust_last_vis_df = target_clust_last_vis_df[target_clust_last_vis_df['target_index'] != 0].copy(\n",
    "        )\n",
    "    else:\n",
    "        target_clust_last_vis_df = target_clust_last_vis_df\n",
    "    return target_clust_last_vis_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ff_real_position_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ff_indices_of_each_cluster \u001b[38;5;241m=\u001b[39m cluster_analysis\u001b[38;5;241m.\u001b[39mfind_alive_target_clusters(\u001b[43mff_real_position_sorted\u001b[49m, ff_caught_T_new, ff_life_sorted, max_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ff_real_position_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "ff_indices_of_each_cluster = cluster_analysis.find_alive_target_clusters(ff_real_position_sorted, ff_caught_T_new, ff_life_sorted, max_distance=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 84 points out of 1338 points that are outside of the reward boundary, which is 6.28% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_caught_T_new is not monotonically increasing. Will make it monotonically increasing.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Bruno/data_0330/ff_dataframe.h5\n",
      "When take out monkey subset for GUAT, 643 clusters out of 856 are too close to the target or the last target. Those clusters are filtered out.\n",
      "The number of new trials that are used to separate stop clusters is 1338\n",
      "Retrieved target_clust_last_vis_df\n"
     ]
    }
   ],
   "source": [
    "## Retrieve monkey data\n",
    "PLAYER = \"monkey\"\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\"\n",
    "data_item = neural_vs_behavioral_class.NeuralVsBehavioralClass(raw_data_folder_path=raw_data_folder_path)\n",
    "data_item.retrieve_or_make_monkey_data()\n",
    "data_item.make_or_retrieve_ff_dataframe(exists_ok=True)\n",
    "data_item.find_patterns()\n",
    "data_item.make_PlotTrials_args()\n",
    "\n",
    "monkey_information = data_item.monkey_information\n",
    "ff_dataframe = data_item.ff_dataframe\n",
    "\n",
    "ff_life_sorted = data_item.ff_life_sorted\n",
    "ff_real_position_sorted = data_item.ff_real_position_sorted\n",
    "ff_believed_position_sorted = data_item.ff_believed_position_sorted\n",
    "cluster_around_target_indices = data_item.cluster_around_target_indices\n",
    "ff_caught_T_new = data_item.ff_caught_T_new\n",
    "caught_ff_num = len(ff_caught_T_new)\n",
    "ff_flash_sorted = data_item.ff_flash_sorted\n",
    "ff_flash_end_sorted = data_item.ff_flash_end_sorted\n",
    "max_point_index = data_item.max_point_index\n",
    "min_point_index = data_item.min_point_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_item.make_or_retrieve_target_clust_last_vis_df()\n",
    "target_clust_last_vis_df = data_item.target_clust_last_vis_df\n",
    "target_clust_last_vis_df['ff_index'] = target_clust_last_vis_df['target_index']\n",
    "\n",
    "\n",
    "PlotTrials_args = (monkey_information, ff_dataframe, ff_life_sorted, ff_real_position_sorted, ff_believed_position_sorted, cluster_around_target_indices, ff_caught_T_new)\n",
    "\n",
    "\n",
    "plot_polar_args = (monkey_information,\n",
    "                    ff_dataframe, \n",
    "                    ff_life_sorted,\n",
    "                    ff_real_position_sorted,\n",
    "                    ff_caught_T_new,\n",
    "                    ff_flash_sorted,)\n",
    "\n",
    "\n",
    "trial_total_num = 2\n",
    "PLAYER = \"monkey\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve right chunk of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved target_clust_last_vis_df\n",
      "Retrieved target_last_vis_df\n"
     ]
    }
   ],
   "source": [
    "exists_ok = True\n",
    "data_item.make_or_retrieve_target_clust_last_vis_df(exists_ok=exists_ok)\n",
    "data_item.make_or_retrieve_target_last_vis_df(exists_ok=True)\n",
    "\n",
    "data_item.target_clust_last_vis_df['nearby_vis_ff_indices'] = data_item.target_clust_last_vis_df['nearby_vis_ff_indices'].apply(\n",
    "    lambda x: [int(i) for i in x.strip('[]').split(',') if i.strip().isdigit()])\n",
    "\n",
    "data_item.target_clust_last_vis_df['num_nearby_vis_ff'] = data_item.target_clust_last_vis_df['nearby_vis_ff_indices'].apply(lambda x: len(x))\n",
    "\n",
    "# add ff_caught_time and ff_caught_point_index\n",
    "data_item.target_clust_last_vis_df['ff_caught_time'] = data_item.ff_caught_T_new[data_item.target_clust_last_vis_df['target_index'].values]\n",
    "data_item.target_clust_last_vis_df['ff_caught_point_index'] = np.searchsorted(data_item.monkey_information['time'], data_item.target_clust_last_vis_df['ff_caught_time'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of targets not in a visible cluster out of all targets 66.4424514200299\n"
     ]
    }
   ],
   "source": [
    "clust_sub = data_item.target_clust_last_vis_df[data_item.target_clust_last_vis_df['num_nearby_vis_ff'] == 1]\n",
    "# print percentage of clust_sub\n",
    "print(\"Percentage of targets not in a visible cluster out of all targets\", len(clust_sub) / len(data_item.target_clust_last_vis_df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need 'last_vis_point_index' and 'ff_caught_point_index' and the point index in between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then...let's see what data is used in neural and planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorpoate ff_caught_T_new converted to data points to clust_sub\n",
    "# and then collect all the points between last visible time and caught time of each target\n",
    "# eventually we would need information such as ff distance, angle, last visible time, etc....(might use information from neural_and_planning)\n",
    "# also, look up how to analyze decoding from neural data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target_index', 'last_vis_point_index', 'last_vis_ff_index',\n",
       "       'nearby_vis_ff_indices', 'time_since_last_vis', 'last_vis_dist',\n",
       "       'last_vis_cum_dist', 'last_vis_ang', 'last_vis_ang_to_bndry',\n",
       "       'last_vis_target_dist', 'last_vis_target_ang',\n",
       "       'last_vis_target_ang_to_bndry', 'abs_last_vis_ang',\n",
       "       'abs_last_vis_ang_to_bndry', 'abs_last_vis_target_ang',\n",
       "       'abs_last_vis_target_ang_to_bndry', 'nearby_alive_ff_indices',\n",
       "       'num_nearby_vis_ff', 'ff_caught_time', 'ff_caught_point_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Move 'new_column' to the front\n",
    "# clust_sub.insert(0, 'new_column', clust_sub.pop('new_column'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
