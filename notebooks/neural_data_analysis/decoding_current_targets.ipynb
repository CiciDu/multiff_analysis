{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r multiff_analysis/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_folder = '/Users/dusiyi/Documents/Multifirefly-Project'\n",
    "os.chdir(project_folder)\n",
    "sys.path.append(os.path.join(project_folder, 'multiff_analysis', 'methods'))\n",
    "\n",
    "from data_wrangling import general_utils, specific_utils, process_monkey_information\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from non_behavioral_analysis.neural_data_analysis.get_neural_data import neural_data_processing\n",
    "from non_behavioral_analysis.neural_data_analysis.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from non_behavioral_analysis.neural_data_analysis.model_neural_data import cca_class, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from non_behavioral_analysis.neural_data_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from non_behavioral_analysis.neural_data_analysis.planning_neural import planning_neural_class, planning_neural_utils\n",
    "from non_behavioral_analysis.neural_data_analysis.decode_targets import behav_features_to_keep, decode_target_class, plot_gpfa_utils, decode_target_utils, fit_gpfa_utils, gpfa_regression_utils\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "from numpy import var\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "# To fit gpfa\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "from elephant.gpfa import GPFA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from elephant.gpfa import gpfa_core, gpfa_util\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0416\"\n",
    "dec = decode_target_class.DecodeTargetClass(raw_data_folder_path=raw_data_folder_path,\n",
    "                                                               bin_width=0.02, window_width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 470 points that are significantly larger than ff_caught_T_sorted, which is 0.21% of the points. Max value of closest_time - capture time is 0.4813680000000886. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 37 points out of 470 points that are outside of the reward boundary, which is 7.87% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Schro/data_0416/ff_dataframe.h5\n",
      "Retrieved target_df\n",
      "Retrieved target_clust_last_vis_df\n",
      "Percentage of targets not in a visible cluster out of all targets 61.48936170212767\n",
      "\n",
      "No NA values found in pursuit_data\n",
      "Window width changed from 0.05 to 0.06 to make it odd\n",
      "Warnings: At least one ff has a lower bound of ff_angle_boundary equal to its upper bound after clipping, meaning that the ff's angle to boundary is greater than 90 degrees. Please check the input.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Deleted instance attributes ['ff_dataframe', 'monkey_information', 'target_df', 'curv_of_traj_df'] to free up memory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>point_index</th>\n",
       "      <th>monkey_speed</th>\n",
       "      <th>monkey_angle</th>\n",
       "      <th>monkey_dw</th>\n",
       "      <th>...</th>\n",
       "      <th>gaze_world_x_r</th>\n",
       "      <th>gaze_world_y_r</th>\n",
       "      <th>target_index</th>\n",
       "      <th>target_x</th>\n",
       "      <th>target_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1161</td>\n",
       "      <td>1393</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>2.25388</td>\n",
       "      <td>-0.00006</td>\n",
       "      <td>...</td>\n",
       "      <td>351.83241</td>\n",
       "      <td>364.51694</td>\n",
       "      <td>1</td>\n",
       "      <td>825.24321</td>\n",
       "      <td>302.26639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1162</td>\n",
       "      <td>1394</td>\n",
       "      <td>86.35241</td>\n",
       "      <td>2.25535</td>\n",
       "      <td>0.08863</td>\n",
       "      <td>...</td>\n",
       "      <td>427.21394</td>\n",
       "      <td>321.36366</td>\n",
       "      <td>1</td>\n",
       "      <td>825.24321</td>\n",
       "      <td>302.26639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1163</td>\n",
       "      <td>1395</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>2.25593</td>\n",
       "      <td>0.03467</td>\n",
       "      <td>...</td>\n",
       "      <td>510.20093</td>\n",
       "      <td>278.03411</td>\n",
       "      <td>1</td>\n",
       "      <td>825.24321</td>\n",
       "      <td>302.26639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin  point_index  monkey_speed  monkey_angle  monkey_dw  ...  \\\n",
       "0  1161         1393     200.00000       2.25388   -0.00006  ...   \n",
       "1  1162         1394      86.35241       2.25535    0.08863  ...   \n",
       "2  1163         1395     200.00000       2.25593    0.03467  ...   \n",
       "\n",
       "   gaze_world_x_r  gaze_world_y_r  target_index  target_x  target_y  \n",
       "0       351.83241       364.51694             1 825.24321 302.26639  \n",
       "1       427.21394       321.36366             1 825.24321 302.26639  \n",
       "2       510.20093       278.03411             1 825.24321 302.26639  \n",
       "\n",
       "[3 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.streamline_making_behav_and_neural_data()\n",
    "dec.get_x_and_y_var()\n",
    "dec._free_up_memory()\n",
    "dec.pursuit_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 470 points that are significantly larger than ff_caught_T_sorted, which is 0.21% of the points. Max value of closest_time - capture time is 0.4813680000000886. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 37 points out of 470 points that are outside of the reward boundary, which is 7.87% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Schro/data_0416/ff_dataframe.h5\n",
      "Retrieved target_df\n",
      "Loaded behav_data_all from all_monkey_data/decoding_targets/monkey_Schro/data_0416/behav_data_all.csv\n",
      "Retrieved target_clust_last_vis_df\n",
      "Percentage of targets not in a visible cluster out of all targets 61.48936170212767\n",
      "Loaded pursuit_data_all from all_monkey_data/decoding_targets/monkey_Schro/data_0416/pursuit_data_all.csv\n",
      "\n",
      "No NA values found in pursuit_data\n",
      "Window width changed from 0.05 to 0.06 to make it odd\n",
      "Wed Jun 11 20:24:44 2025    profile_output\n",
      "\n",
      "         485387 function calls (471865 primitive calls) in 15.032 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 1630 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      300    8.447    0.028    8.447    0.028 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
      "        9    2.756    0.306    2.832    0.315 c_parser_wrapper.py:222(read)\n",
      "        1    0.588    0.588    9.783    9.783 neural_data_processing.py:83(_make_all_binned_spikes)\n",
      "      344    0.343    0.001    0.353    0.001 take.py:120(_take_nd_ndarray)\n",
      "      183    0.246    0.001    0.246    0.001 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "        1    0.200    0.200    0.200    0.200 sorting.py:687(compress_group_index)\n",
      "        6    0.172    0.029    0.175    0.029 astype.py:56(_astype_nansafe)\n",
      "       48    0.139    0.003    0.223    0.005 managers.py:2276(_merge_blocks)\n",
      "      612    0.131    0.000    0.131    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "      118    0.121    0.001    0.122    0.001 necompiler.py:977(re_evaluate)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x310e0b750>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run profiler and save output to file\n",
    "cProfile.run('dec.streamline_making_behav_and_neural_data()', 'profile_output')\n",
    "\n",
    "# Load stats and sort by total time\n",
    "p = pstats.Stats('profile_output')\n",
    "p.strip_dirs().sort_stats('tottime').print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Random listing order was used\n",
      "   List reduced from 1630 to 6 due to restriction <'searchsorted'>\n",
      "\n",
      "Function                                            was called by...\n",
      "                                                        ncalls  tottime  cumtime\n",
      "fromnumeric.py:1332(searchsorted)                   <-       2    0.000    0.012  base_processing_class.py:164(make_ff_caught_T_new)\n",
      "                                                             2    0.000    0.076  curv_of_traj_utils.py:113(_get_point_index_based_on_cum_distance)\n",
      "                                                             1    0.000    0.000  decode_target_utils.py:194(find_single_vis_target_df)\n",
      "                                                             1    0.000    0.085  make_ff_dataframe.py:181(furnish_ff_dataframe)\n",
      "fromnumeric.py:1328(_searchsorted_dispatcher)       <-       2    0.000    0.000  base_processing_class.py:164(make_ff_caught_T_new)\n",
      "                                                             2    0.000    0.000  curv_of_traj_utils.py:113(_get_point_index_based_on_cum_distance)\n",
      "                                                             1    0.000    0.000  decode_target_utils.py:194(find_single_vis_target_df)\n",
      "                                                             1    0.000    0.000  make_ff_dataframe.py:181(furnish_ff_dataframe)\n",
      "{method 'searchsorted' of 'numpy.ndarray' objects}  <-       1    0.000    0.000  algorithms.py:1248(searchsorted)\n",
      "                                                             5    0.173    0.173  fromnumeric.py:53(_wrapfunc)\n",
      "                                                           294    8.273    8.273  histograms.py:454(_search_sorted_inclusive)\n",
      "algorithms.py:1248(searchsorted)                    <-       1    0.000    0.000  base.py:1333(searchsorted)\n",
      "base.py:1333(searchsorted)                          <-       1    0.000    0.000  series.py:3260(searchsorted)\n",
      "series.py:3260(searchsorted)                        <-       1    0.000    0.000  fromnumeric.py:53(_wrapfunc)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x3a83dce10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pstats\n",
    "\n",
    "p = pstats.Stats('profile_output')\n",
    "p.strip_dirs()\n",
    "\n",
    "# Show who called searchsorted\n",
    "p.print_callers('searchsorted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 11 20:14:40 2025    profile_output\n",
      "\n",
      "         150862 function calls (147709 primitive calls) in 13.055 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      297    8.237    0.028    8.237    0.028 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
      "        6    2.314    0.386    2.389    0.398 c_parser_wrapper.py:222(read)\n",
      "        1    0.668    0.668    9.875    9.875 neural_data_processing.py:83(_make_all_binned_spikes)\n",
      "      252    0.273    0.001    0.281    0.001 take.py:120(_take_nd_ndarray)\n",
      "      136    0.222    0.002    0.222    0.002 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "       86    0.108    0.001    8.490    0.099 histograms.py:678(histogram)\n",
      "       30    0.103    0.003    0.204    0.007 managers.py:2276(_merge_blocks)\n",
      "       24    0.099    0.004    0.099    0.004 shape_base.py:219(vstack)\n",
      "       86    0.098    0.001    0.098    0.001 necompiler.py:977(re_evaluate)\n",
      "      147    0.080    0.001    8.241    0.056 histograms.py:454(_search_sorted_inclusive)\n",
      "      482    0.074    0.000    0.074    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "       44    0.052    0.001    0.052    0.001 managers.py:2246(_stack_arrays)\n",
      "      151    0.050    0.000    0.050    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "        1    0.042    0.042    0.042    0.042 neural_data_processing.py:75(_filter_spike_data)\n",
      "        1    0.036    0.036    0.146    0.146 neural_data_processing.py:27(make_spike_df)\n",
      "       86    0.032    0.000    0.036    0.000 histograms.py:360(_get_bin_edges)\n",
      "     1026    0.032    0.000    0.032    0.000 {built-in method _codecs.utf_8_decode}\n",
      "        2    0.030    0.015    0.030    0.015 {built-in method numpy.fromfile}\n",
      "      225    0.028    0.000    0.028    0.000 concat.py:52(concat_compat)\n",
      "       87    0.025    0.000    0.025    0.000 function_base.py:1324(diff)\n",
      "      102    0.024    0.000    0.027    0.000 utils.py:239(maybe_convert_indices)\n",
      "       90    0.024    0.000    0.024    0.000 {built-in method numpy.zeros}\n",
      "        1    0.019    0.019    0.019    0.019 algorithms.py:427(unique_with_mask)\n",
      "      766    0.018    0.000    0.018    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      366    0.018    0.000    0.600    0.002 frame.py:4062(__getitem__)\n",
      "        1    0.014    0.014    0.014    0.014 animation_utils.py:499(find_triangle_to_show_direction)\n",
      "        1    0.013    0.013    2.831    2.831 <string>:2(get_behav_data)\n",
      "        6    0.011    0.002    0.040    0.007 c_parser_wrapper.py:355(_concatenate_chunks)\n",
      "        1    0.010    0.010    0.020    0.020 merge.py:1770(get_join_indexers_non_unique)\n",
      "        1    0.010    0.010    0.010    0.010 merge.py:2398(_factorize_keys)\n",
      "        1    0.009    0.009   10.033   10.033 neural_vs_behavioral_class.py:62(retrieve_neural_data)\n",
      "       25    0.008    0.000    0.009    0.000 missing.py:261(_isna_array)\n",
      "        6    0.008    0.001    2.546    0.424 readers.py:583(_read)\n",
      "      252    0.008    0.000    0.289    0.001 take.py:59(take_nd)\n",
      "28142/27852    0.008    0.000    0.012    0.000 {built-in method builtins.isinstance}\n",
      "       20    0.008    0.000    0.213    0.011 managers.py:1782(_consolidate_inplace)\n",
      "        1    0.007    0.007    0.411    0.411 base_processing_class.py:276(get_curv_of_traj_df)\n",
      "        6    0.007    0.001    0.008    0.001 c_parser_wrapper.py:60(__init__)\n",
      "        3    0.007    0.002    0.036    0.012 merge.py:1692(get_join_indexers)\n",
      "        1    0.007    0.007    0.371    0.371 curv_of_traj_utils.py:74(find_curv_of_traj_df_based_on_distance_window)\n",
      "       62    0.004    0.000    0.005    0.000 base.py:2313(is_unique)\n",
      "      252    0.003    0.000    0.007    0.000 take.py:564(_take_preprocess_indexer_and_fill_value)\n",
      "      511    0.003    0.000    0.015    0.000 construction.py:517(sanitize_array)\n",
      "      106    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        1    0.003    0.003    0.578    0.578 neural_vs_behavioral_class.py:243(_make_or_retrieve_target_df)\n",
      "        8    0.003    0.000    0.148    0.019 construction.py:96(arrays_to_mgr)\n",
      "      225    0.003    0.000    0.003    0.000 cast.py:550(maybe_promote)\n",
      "        1    0.003    0.003    0.167    0.167 curv_of_traj_utils.py:122(find_curv_of_traj_df_based_on_lower_and_upper_ends_of_point_index)\n",
      "  176/170    0.003    0.000    0.022    0.000 series.py:389(__init__)\n",
      "        1    0.003    0.003    0.003    0.003 base.py:389(_left_indexer)\n",
      "      462    0.003    0.000    0.004    0.000 generic.py:6236(__finalize__)\n",
      "     1096    0.003    0.000    0.005    0.000 generic.py:6301(__setattr__)\n",
      "       33    0.003    0.000    0.003    0.000 base.py:3955(_get_indexer)\n",
      "9341/6722    0.002    0.000    0.004    0.000 {built-in method builtins.len}\n",
      "      420    0.002    0.000    0.003    0.000 base.py:5323(__contains__)\n",
      "1666/1471    0.002    0.000    0.008    0.000 {built-in method numpy.asarray}\n",
      "      168    0.002    0.000    0.003    0.000 managers.py:1012(iget)\n",
      "        1    0.002    0.002   13.055   13.055 decode_target_class.py:54(streamline_making_behav_and_neural_data)\n",
      "        1    0.002    0.002    0.017    0.017 monkey_heading_functions.py:39(find_mheading_in_xy)\n",
      "       13    0.002    0.000    0.002    0.000 base.py:2229(is_monotonic_increasing)\n",
      "      496    0.002    0.000    0.002    0.000 generic.py:278(__init__)\n",
      "     1026    0.002    0.000    0.034    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.002    0.002    0.404    0.404 curv_of_traj_utils.py:342(find_curv_of_traj_df_based_on_curv_of_traj_mode)\n",
      "        6    0.002    0.000    0.002    0.000 {method 'update' of 'dict' objects}\n",
      "       86    0.002    0.000    0.006    0.000 necompiler.py:782(validate)\n",
      "      133    0.002    0.000    0.004    0.000 expressions.py:76(_can_use_numexpr)\n",
      "        2    0.002    0.001    0.077    0.039 curv_of_traj_utils.py:113(_get_point_index_based_on_cum_distance)\n",
      "      102    0.002    0.000    0.012    0.000 base.py:475(__new__)\n",
      "      675    0.002    0.000    0.014    0.000 generic.py:6284(__getattr__)\n",
      "       32    0.002    0.000    0.002    0.000 cast.py:1579(construct_1d_object_array_from_listlike)\n",
      "        1    0.002    0.002    0.188    0.188 <string>:2(get_pursuit_data)\n",
      "       95    0.001    0.000    0.009    0.000 range.py:1148(take)\n",
      "      102    0.001    0.000    0.328    0.003 generic.py:4027(take)\n",
      "      112    0.001    0.000    0.295    0.003 managers.py:623(reindex_indexer)\n",
      "     4058    0.001    0.000    0.003    0.000 generic.py:42(_instancecheck)\n",
      "      316    0.001    0.000    0.003    0.000 _dtype.py:346(_name_get)\n",
      "      264    0.001    0.000    0.010    0.000 frame.py:4626(_get_item_cache)\n",
      "        8    0.001    0.000    0.054    0.007 managers.py:2190(_form_blocks)\n",
      "      257    0.001    0.000    0.002    0.000 base.py:649(_simple_new)\n",
      "      226    0.001    0.000    0.290    0.001 blocks.py:1287(take_nd)\n",
      "     4058    0.001    0.000    0.002    0.000 generic.py:37(_check)\n",
      "       45    0.001    0.000    0.001    0.000 base.py:2744(inferred_type)\n",
      "     6814    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
      "      105    0.001    0.000    0.115    0.001 array_ops.py:288(comparison_op)\n",
      "      511    0.001    0.000    0.001    0.000 construction.py:696(_sanitize_ndim)\n",
      "        3    0.001    0.000    0.070    0.023 merge.py:135(merge)\n",
      "      483    0.001    0.000    0.005    0.000 base.py:5437(_can_hold_identifiers_and_holds_name)\n",
      "       47    0.001    0.000    0.073    0.002 managers.py:317(apply)\n",
      "      132    0.001    0.000    0.016    0.000 series.py:6201(_construct_result)\n",
      "      660    0.001    0.000    0.003    0.000 common.py:137(is_object_dtype)\n",
      "       90    0.001    0.000    0.002    0.000 cast.py:1156(maybe_infer_to_datetimelike)\n",
      "       10    0.001    0.000    0.001    0.000 {built-in method _operator.sub}\n",
      "        8    0.001    0.000    0.001    0.000 {built-in method io.open}\n",
      "        5    0.001    0.000    0.001    0.000 algorithms.py:1339(diff)\n",
      "        1    0.001    0.001    0.111    0.111 curv_of_traj_utils.py:18(initialize_curv_of_traj_df)\n",
      "      326    0.001    0.000    0.002    0.000 base.py:5373(__getitem__)\n",
      "      537    0.001    0.000    0.001    0.000 {built-in method numpy.empty}\n",
      "        6    0.001    0.000    0.001    0.000 readers.py:1685(_clean_options)\n",
      "      105    0.001    0.000    0.131    0.001 series.py:6110(_cmp_method)\n",
      "        3    0.001    0.000    0.001    0.000 expressions.py:172(_where_standard)\n",
      "        3    0.001    0.000    0.071    0.024 frame.py:10813(merge)\n",
      "       75    0.001    0.000    0.002    0.000 common.py:231(asarray_tuplesafe)\n",
      "      328    0.001    0.000    0.005    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "      164    0.001    0.000    0.002    0.000 managers.py:1863(from_array)\n",
      "      102    0.001    0.000    0.324    0.003 managers.py:869(take)\n",
      "      429    0.001    0.000    0.001    0.000 indexing.py:2765(check_dict_or_set_indexers)\n",
      "       90    0.001    0.000    0.530    0.006 frame.py:4130(_getitem_bool_array)\n",
      "      132    0.001    0.000    0.115    0.001 array_ops.py:189(_na_arithmetic_op)\n",
      "       21    0.001    0.000    0.037    0.002 managers.py:708(_slice_take_blocks_ax0)\n",
      "     1158    0.001    0.000    0.001    0.000 __init__.py:34(using_copy_on_write)\n",
      "      130    0.001    0.000    0.113    0.001 expressions.py:95(_evaluate_numexpr)\n",
      "      162    0.001    0.000    0.008    0.000 frame.py:3983(_ixs)\n",
      "      108    0.001    0.000    0.005    0.000 utils.py:419(check_array_indexer)\n",
      "      158    0.001    0.000    0.001    0.000 numeric.py:274(full)\n",
      "        1    0.001    0.001    0.008    0.008 prep_target_data.py:56(add_columns_to_target_df)\n",
      "      433    0.001    0.000    0.009    0.000 base.py:7593(ensure_index)\n",
      "      717    0.001    0.000    0.002    0.000 common.py:1434(_is_dtype_type)\n",
      "       68    0.001    0.000    0.001    0.000 base.py:842(_engine)\n",
      "      393    0.001    0.000    0.001    0.000 common.py:572(condition)\n",
      "      102    0.001    0.000    0.330    0.003 generic.py:4142(_take_with_is_copy)\n",
      "      339    0.001    0.000    0.001    0.000 managers.py:180(blknos)\n",
      "       86    0.001    0.000    0.001    0.000 necompiler.py:551(getContext)\n",
      "        7    0.001    0.000    0.001    0.000 {built-in method numpy.arange}\n",
      "       86    0.001    0.000    0.104    0.001 necompiler.py:893(evaluate)\n",
      "      228    0.001    0.000    0.001    0.000 blocks.py:292(make_block_same_class)\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method _operator.mod}\n",
      "        1    0.001    0.001    0.020    0.020 algorithms.py:307(unique)\n",
      "        4    0.001    0.000    0.001    0.000 {built-in method _operator.truediv}\n",
      "      598    0.001    0.000    0.001    0.000 construction.py:481(ensure_wrapped_if_datetimelike)\n",
      "        8    0.001    0.000    0.001    0.000 numeric.py:2378(array_equal)\n",
      "      172    0.001    0.000    0.010    0.000 missing.py:184(_isna)\n",
      "       93    0.001    0.000    0.003    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "      173    0.001    0.000    0.001    0.000 base.py:82(shape)\n",
      "     1007    0.001    0.000    0.001    0.000 inference.py:334(is_hashable)\n",
      "        6    0.001    0.000    0.010    0.002 generic.py:4796(_drop_axis)\n",
      "        3    0.001    0.000    0.001    0.000 nanops.py:76(_f)\n",
      "       91    0.001    0.000    0.256    0.003 managers.py:687(<listcomp>)\n",
      "       14    0.001    0.000    0.001    0.000 interactiveshell.py:3027(write)\n",
      "      108    0.001    0.000    0.007    0.000 indexing.py:2632(check_bool_indexer)\n",
      "     1603    0.001    0.000    0.001    0.000 range.py:999(__len__)\n",
      "      188    0.001    0.000    0.001    0.000 blocks.py:2716(new_block)\n",
      "       26    0.001    0.000    0.003    0.000 cast.py:123(maybe_convert_platform)\n",
      "     1496    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "      123    0.001    0.000    0.001    0.000 managers.py:948(from_blocks)\n",
      "      252    0.001    0.000    0.001    0.000 take.py:325(_get_take_nd_function)\n",
      "      213    0.001    0.000    0.001    0.000 base.py:3777(get_loc)\n",
      "      326    0.001    0.000    0.001    0.000 generic.py:586(_get_axis)\n",
      "      515    0.001    0.000    0.001    0.000 series.py:734(name)\n",
      "     3045    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\n",
      "      164    0.000    0.000    0.002    0.000 common.py:97(is_bool_indexer)\n",
      "        1    0.000    0.000    0.011    0.011 general_utils.py:158(find_rows_with_na)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _operator.add}\n",
      "      132    0.000    0.000    0.139    0.001 common.py:62(new_method)\n",
      "      151    0.000    0.000    0.054    0.000 fromnumeric.py:865(sort)\n",
      "     1026    0.000    0.000    0.000    0.000 <frozen codecs>:331(getstate)\n",
      "      406    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      260    0.000    0.000    0.001    0.000 numerictypes.py:357(issubdtype)\n",
      "      673    0.000    0.000    0.001    0.000 construction.py:416(extract_array)\n",
      "        6    0.000    0.000    2.549    0.425 readers.py:868(read_csv)\n",
      "      308    0.000    0.000    0.001    0.000 series.py:784(name)\n",
      "       10    0.000    0.000    0.001    0.000 blocks.py:1373(setitem)\n",
      "     2498    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "      148    0.000    0.000    0.002    0.000 {built-in method builtins.sorted}\n",
      "      774    0.000    0.000    0.001    0.000 managers.py:1993(dtype)\n",
      "      311    0.000    0.000    0.002    0.000 generic.py:339(_from_mgr)\n",
      "      316    0.000    0.000    0.002    0.000 _dtype.py:330(_name_includes_bit_suffix)\n",
      "      174    0.000    0.000    0.001    0.000 config.py:127(_get_single_key)\n",
      "        6    0.000    0.000    0.002    0.000 blocks.py:398(reduce)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "      245    0.000    0.000    0.001    0.000 blocks.py:2645(maybe_coerce_values)\n",
      "       37    0.000    0.000    0.001    0.000 function_base.py:5369(insert)\n",
      "      158    0.000    0.000    0.003    0.000 frame.py:4608(_box_col_values)\n",
      "       86    0.000    0.000    0.001    0.000 <frozen os>:674(__getitem__)\n",
      "  432/426    0.000    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "      443    0.000    0.000    0.000    0.000 managers.py:2004(internal_values)\n",
      "      520    0.000    0.000    0.001    0.000 numerictypes.py:283(issubclass_)\n",
      "      190    0.000    0.000    0.001    0.000 generic.py:807(_set_axis)\n",
      "       44    0.000    0.000    0.001    0.000 _asarray.py:27(require)\n",
      "       85    0.000    0.000    0.066    0.001 blocks.py:790(copy)\n",
      "        1    0.000    0.000    0.006    0.006 curv_of_traj_utils.py:246(calculate_difference_in_curv_of_traj)\n",
      "       37    0.000    0.000    0.007    0.000 managers.py:1347(insert)\n",
      "      265    0.000    0.000    0.001    0.000 common.py:1596(pandas_dtype)\n",
      "      132    0.000    0.000    0.000    0.000 missing.py:131(dispatch_fill_zeros)\n",
      "      174    0.000    0.000    0.002    0.000 config.py:145(_get_option)\n",
      "      172    0.000    0.000    0.001    0.000 necompiler.py:740(getArguments)\n",
      "      393    0.000    0.000    0.002    0.000 common.py:536(is_string_dtype)\n",
      "      162    0.000    0.000    0.002    0.000 base.py:5552(equals)\n",
      "      243    0.000    0.000    0.001    0.000 common.py:1198(is_bool_dtype)\n",
      "      496    0.000    0.000    0.000    0.000 flags.py:51(__init__)\n",
      "      917    0.000    0.000    0.000    0.000 generic.py:405(flags)\n",
      "      149    0.000    0.000    0.001    0.000 construction.py:769(_try_cast)\n",
      "       37    0.000    0.000    0.004    0.000 base.py:6956(insert)\n",
      "      427    0.000    0.000    0.002    0.000 common.py:1375(_is_dtype)\n",
      "      302    0.000    0.000    0.000    0.000 blocks.py:2674(get_block_type)\n",
      "      174    0.000    0.000    0.000    0.000 config.py:635(_get_root)\n",
      "        1    0.000    0.000    0.015    0.015 time_calib_utils.py:21(find_smr_markers_start_and_end_time)\n",
      "       33    0.000    0.000    0.008    0.000 base.py:3820(get_indexer)\n",
      "      222    0.000    0.000    0.001    0.000 c_parser_wrapper.py:367(<listcomp>)\n",
      "      130    0.000    0.000    0.000    0.000 warnings.py:467(__enter__)\n",
      "      244    0.000    0.000    0.001    0.000 inference.py:195(is_array_like)\n",
      "        1    0.000    0.000    0.006    0.006 base_processing_class.py:208(make_or_retrieve_target_clust_last_vis_df)\n",
      "      311    0.000    0.000    0.001    0.000 common.py:1571(validate_all_hashable)\n",
      "      195    0.000    0.000    0.001    0.000 series.py:978(__array__)\n",
      "      260    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "      139    0.000    0.000    0.001    0.000 common.py:81(get_op_result_name)\n",
      "      456    0.000    0.000    0.000    0.000 flags.py:87(allows_duplicate_labels)\n",
      "      126    0.000    0.000    0.001    0.000 frame.py:659(_constructor_from_mgr)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "       89    0.000    0.000    0.128    0.001 arraylike.py:38(__eq__)\n",
      "      284    0.000    0.000    0.001    0.000 base.py:7688(maybe_extract_name)\n",
      "      443    0.000    0.000    0.001    0.000 series.py:831(_values)\n",
      "      118    0.000    0.000    0.000    0.000 generic.py:592(_get_block_manager_axis)\n",
      "        3    0.000    0.000    0.036    0.012 merge.py:1119(_get_join_indexers)\n",
      "       86    0.000    0.000    0.001    0.000 utils.py:238(set)\n",
      "       48    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "      154    0.000    0.000    0.001    0.000 generic.py:511(_validate_dtype)\n",
      "    52/38    0.000    0.000    0.015    0.000 frame.py:4271(__setitem__)\n",
      "       74    0.000    0.000    0.000    0.000 function_base.py:5563(append)\n",
      "      418    0.000    0.000    0.000    0.000 common.py:529(is_string_or_object_np_dtype)\n",
      "       86    0.000    0.000    0.003    0.000 fromnumeric.py:2322(any)\n",
      "      162    0.000    0.000    0.001    0.000 frame.py:678(_constructor_sliced_from_mgr)\n",
      "     1427    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "      774    0.000    0.000    0.001    0.000 series.py:707(dtype)\n",
      "      531    0.000    0.000    0.000    0.000 generic.py:572(_get_axis_number)\n",
      "      333    0.000    0.000    0.004    0.000 _methods.py:55(_any)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:6219(_raise_if_missing)\n",
      "       97    0.000    0.000    0.001    0.000 blocks.py:225(_consolidate_key)\n",
      "      740    0.000    0.000    0.000    0.000 base.py:909(__len__)\n",
      "        8    0.000    0.000    0.003    0.000 construction.py:596(_homogenize)\n",
      "      136    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "      107    0.000    0.000    0.000    0.000 common.py:992(is_numeric_v_string_like)\n",
      "       27    0.000    0.000    0.007    0.000 base.py:1371(_arith_method)\n",
      "      131    0.000    0.000    0.114    0.001 expressions.py:226(evaluate)\n",
      "       86    0.000    0.000    0.003    0.000 histograms.py:283(_ravel_and_check_weights)\n",
      "        6    0.000    0.000    0.002    0.000 common.py:664(get_handle)\n",
      "      586    0.000    0.000    0.000    0.000 generic.py:667(_info_axis)\n",
      "      470    0.000    0.000    0.001    0.000 decode_target_utils.py:198(<lambda>)\n",
      "       70    0.000    0.000    0.001    0.000 blocks.py:2703(new_block_2d)\n",
      "      480    0.000    0.000    0.000    0.000 common.py:372(apply_if_callable)\n",
      "      470    0.000    0.000    0.000    0.000 decode_target_utils.py:198(<listcomp>)\n",
      "       45    0.000    0.000    0.008    0.000 frame.py:4481(_set_item_mgr)\n",
      "       14    0.000    0.000    0.174    0.012 generic.py:6662(copy)\n",
      "      599    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x104ca55f8}\n",
      "     1315    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "      174    0.000    0.000    0.000    0.000 config.py:676(_translate_key)\n",
      "        8    0.000    0.000    0.159    0.020 construction.py:423(dict_to_mgr)\n",
      "        9    0.000    0.000    0.160    0.018 frame.py:694(__init__)\n",
      "      103    0.000    0.000    0.001    0.000 base.py:5170(_get_engine_target)\n",
      "       41    0.000    0.000    0.003    0.000 base.py:674(_with_infer)\n",
      "      294    0.000    0.000    0.000    0.000 blocks.py:1253(iget)\n",
      "        1    0.000    0.000    9.877    9.877 neural_data_processing.py:103(prepare_binned_spikes_df)\n",
      "      660    0.000    0.000    0.000    0.000 common.py:121(classes)\n",
      "       86    0.000    0.000    0.001    0.000 <frozen _collections_abc>:778(__contains__)\n",
      "        6    0.000    0.000    0.001    0.000 generic.py:4361(_slice)\n",
      "      670    0.000    0.000    0.000    0.000 common.py:1399(_get_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _operator.gt}\n",
      "      511    0.000    0.000    0.000    0.000 construction.py:735(_sanitize_str_dtypes)\n",
      "       14    0.000    0.000    0.001    0.000 iostream.py:655(write)\n",
      "      351    0.000    0.000    0.000    0.000 __init__.py:42(warn_copy_on_write)\n",
      "      190    0.000    0.000    0.001    0.000 managers.py:236(set_axis)\n",
      "       37    0.000    0.000    0.001    0.000 numeric.py:1393(moveaxis)\n",
      "       11    0.000    0.000    0.205    0.019 managers.py:2259(_consolidate)\n",
      "      222    0.000    0.000    0.000    0.000 c_parser_wrapper.py:369(<setcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _operator.mul}\n",
      "      142    0.000    0.000    0.000    0.000 blocks.py:2795(extend_blocks)\n",
      "        3    0.000    0.000    0.063    0.021 merge.py:882(get_result)\n",
      "        3    0.000    0.000    0.002    0.001 blocks.py:1524(where)\n",
      "      158    0.000    0.000    0.000    0.000 series.py:1471(_set_as_cached)\n",
      "        2    0.000    0.000    0.001    0.000 algorithms.py:1667(map_array)\n",
      "       24    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "      622    0.000    0.000    0.000    0.000 common.py:1590(<genexpr>)\n",
      "      660    0.000    0.000    0.000    0.000 common.py:123(<lambda>)\n",
      "      408    0.000    0.000    0.001    0.000 common.py:568(require_length_match)\n",
      "      172    0.000    0.000    0.010    0.000 missing.py:101(isna)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _operator.pow}\n",
      "        1    0.000    0.000    0.000    0.000 arraylike.py:253(array_ufunc)\n",
      "      190    0.000    0.000    0.000    0.000 base.py:86(_validate_set_axis)\n",
      "      375    0.000    0.000    0.000    0.000 managers.py:1837(__init__)\n",
      "        9    0.000    0.000    0.002    0.000 blocks.py:387(apply)\n",
      "       36    0.000    0.000    0.000    0.000 base.py:7723(_unpack_nested_dtype)\n",
      "        1    0.000    0.000    0.001    0.001 frame.py:11575(_reduce_axis1)\n",
      "      511    0.000    0.000    0.000    0.000 construction.py:758(_maybe_repeat)\n",
      "      504    0.000    0.000    0.001    0.000 base.py:84(<genexpr>)\n",
      "       86    0.000    0.000    0.000    0.000 {method 'set' of '_contextvars.ContextVar' objects}\n",
      "        2    0.000    0.000    0.004    0.002 frame.py:11435(_reduce)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _operator.lt}\n",
      "        6    0.000    0.000    0.003    0.001 base.py:7031(drop)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:623(send)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:66(mask_missing)\n",
      "      162    0.000    0.000    0.000    0.000 base.py:791(is_)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "        6    0.000    0.000    0.000    0.000 missing.py:305(_isna_string_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:968(_pad_2d)\n",
      "      127    0.000    0.000    0.001    0.000 {built-in method builtins.any}\n",
      "       38    0.000    0.000    0.001    0.000 warnings.py:131(filterwarnings)\n",
      "       86    0.000    0.000    0.000    0.000 necompiler.py:877(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1796(concat_horizontal)\n",
      "      174    0.000    0.000    0.000    0.000 config.py:617(_select_options)\n",
      "     1251    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "      406    0.000    0.000    0.001    0.000 <frozen abc>:117(__instancecheck__)\n",
      "       56    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "       26    0.000    0.000    0.192    0.007 managers.py:557(copy)\n",
      "       28    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "       14    0.000    0.000    0.000    0.000 managers.py:1778(<listcomp>)\n",
      "      644    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "       45    0.000    0.000    0.006    0.000 frame.py:5242(_sanitize_column)\n",
      "       56    0.000    0.000    0.000    0.000 common.py:1081(is_numeric_dtype)\n",
      "      124    0.000    0.000    0.004    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "      496    0.000    0.000    0.000    0.000 multiarray.py:153(concatenate)\n",
      "      204    0.000    0.000    0.000    0.000 common.py:1331(is_ea_or_datetimelike_dtype)\n",
      "       74    0.000    0.000    0.000    0.000 numeric.py:1330(normalize_axis_tuple)\n",
      "      130    0.000    0.000    0.000    0.000 warnings.py:441(__init__)\n",
      "        3    0.000    0.000    0.005    0.002 merge.py:737(__init__)\n",
      "       18    0.000    0.000    0.001    0.000 base.py:1146(take)\n",
      "       93    0.000    0.000    0.000    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "      190    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "      172    0.000    0.000    0.000    0.000 necompiler.py:699(getType)\n",
      "      258    0.000    0.000    0.000    0.000 utils.py:290(__getitem__)\n",
      "        9    0.000    0.000    0.011    0.001 nanops.py:389(new_func)\n",
      "      318    0.000    0.000    0.000    0.000 common.py:152(cast_scalar_indexer)\n",
      "        6    0.000    0.000    2.527    0.421 readers.py:1907(read)\n",
      "       98    0.000    0.000    0.004    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "       56    0.000    0.000    0.000    0.000 warnings.py:182(_add_filter)\n",
      "      130    0.000    0.000    0.000    0.000 warnings.py:488(__exit__)\n",
      "      491    0.000    0.000    0.000    0.000 managers.py:1392(<genexpr>)\n",
      "      234    0.000    0.000    0.000    0.000 range.py:553(equals)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1233(dedup_names)\n",
      "      668    0.000    0.000    0.000    0.000 base.py:3809(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:549(find)\n",
      "      477    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "      225    0.000    0.000    0.000    0.000 concat.py:73(<listcomp>)\n",
      "     1187    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "      166    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "      258    0.000    0.000    0.000    0.000 utils.py:249(get)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _operator.le}\n",
      "       37    0.000    0.000    0.001    0.000 managers.py:1412(_insert_update_blklocs_and_blknos)\n",
      "      189    0.000    0.000    0.000    0.000 blocks.py:214(is_extension)\n",
      "       10    0.000    0.000    0.006    0.001 indexing.py:882(__setitem__)\n",
      "    32/24    0.000    0.000    0.007    0.000 indexing.py:1176(__getitem__)\n",
      "       18    0.000    0.000    0.000    0.000 managers.py:1066(iset)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:115(__init__)\n",
      "       36    0.000    0.000    0.002    0.000 base.py:6394(_should_compare)\n",
      "        6    0.000    0.000    0.000    0.000 function_base.py:5173(delete)\n",
      "       37    0.000    0.000    0.000    0.000 managers.py:1402(_insert_update_mgr_locs)\n",
      "       45    0.000    0.000    0.014    0.000 frame.py:4514(_set_item)\n",
      "       38    0.000    0.000    0.000    0.000 __init__.py:272(_compile)\n",
      "      102    0.000    0.000    0.000    0.000 base.py:591(_ensure_array)\n",
      "      282    0.000    0.000    0.000    0.000 base.py:831(_reset_identity)\n",
      "        3    0.000    0.000    0.026    0.009 merge.py:825(_reindex_and_concat)\n",
      "      316    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
      "       54    0.000    0.000    0.000    0.000 _ufunc_config.py:33(seterr)\n",
      "        6    0.000    0.000    0.010    0.002 readers.py:1848(_make_engine)\n",
      "      108    0.000    0.000    0.000    0.000 base.py:74(__len__)\n",
      "      734    0.000    0.000    0.000    0.000 range.py:376(dtype)\n",
      "      105    0.000    0.000    0.000    0.000 generic.py:4379(_set_is_copy)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:987(_backfill_2d)\n",
      "        8    0.000    0.000    0.001    0.000 base.py:4323(reindex)\n",
      "       27    0.000    0.000    0.000    0.000 array_ops.py:507(maybe_prepare_scalar_for_op)\n",
      "       37    0.000    0.000    0.000    0.000 managers.py:2311(_fast_count_smallints)\n",
      "       86    0.000    0.000    0.000    0.000 <frozen os>:756(encode)\n",
      "      120    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "      175    0.000    0.000    0.000    0.000 config.py:649(_get_deprecated_option)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2421(all)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:6916(delete)\n",
      "       67    0.000    0.000    0.000    0.000 frame.py:1643(__len__)\n",
      "     1037    0.000    0.000    0.000    0.000 typing.py:2287(cast)\n",
      "        8    0.000    0.000    0.007    0.001 base.py:6186(_get_indexer_strict)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        8    0.000    0.000    0.142    0.018 managers.py:2121(create_block_manager_from_column_arrays)\n",
      "       15    0.000    0.000    0.001    0.000 indexing.py:1719(_getitem_axis)\n",
      "      132    0.000    0.000    0.000    0.000 dispatch.py:17(should_extension_dispatch)\n",
      "       10    0.000    0.000    0.005    0.000 indexing.py:1946(_setitem_with_indexer_split_path)\n",
      "       55    0.000    0.000    0.000    0.000 blocks.py:2811(ensure_block_shape)\n",
      "      124    0.000    0.000    0.000    0.000 __init__.py:55(using_pyarrow_string_dtype)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:3569(_intersection_via_get_indexer)\n",
      "       56    0.000    0.000    0.000    0.000 cast.py:1760(np_can_hold_element)\n",
      "       56    0.000    0.000    0.000    0.000 inference.py:273(is_dict_like)\n",
      "       98    0.000    0.000    0.004    0.000 _methods.py:61(_all)\n",
      "        3    0.000    0.000    0.002    0.001 blocks.py:1643(fillna)\n",
      "      351    0.000    0.000    0.000    0.000 managers.py:1940(_block)\n",
      "      461    0.000    0.000    0.000    0.000 flags.py:55(allows_duplicate_labels)\n",
      "       54    0.000    0.000    0.000    0.000 _ufunc_config.py:132(geterr)\n",
      "      258    0.000    0.000    0.000    0.000 {built-in method sys._getframe}\n",
      "       92    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        6    0.000    0.000    0.011    0.002 readers.py:1575(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 parse.py:374(urlparse)\n",
      "        6    0.000    0.000    0.011    0.002 generic.py:4757(drop)\n",
      "        2    0.000    0.000    0.031    0.016 npyio.py:282(load)\n",
      "       27    0.000    0.000    0.004    0.000 array_ops.py:240(arithmetic_op)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:1627(_get_options_with_defaults)\n",
      "       24    0.000    0.000    0.000    0.000 managers.py:2285(<listcomp>)\n",
      "      456    0.000    0.000    0.000    0.000 generic.py:363(attrs)\n",
      "        6    0.000    0.000    0.000    0.000 range.py:137(__new__)\n",
      "      152    0.000    0.000    0.000    0.000 generic.py:696(ndim)\n",
      "      194    0.000    0.000    0.001    0.000 managers.py:2264(<lambda>)\n",
      "      320    0.000    0.000    0.000    0.000 managers.py:196(blklocs)\n",
      "       68    0.000    0.000    0.000    0.000 base.py:456(_engine_type)\n",
      "        1    0.000    0.000   13.055   13.055 {built-in method builtins.exec}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _operator.ge}\n",
      "       11    0.000    0.000    0.001    0.000 managers.py:287(get_dtypes)\n",
      "       10    0.000    0.000    0.002    0.000 indexing.py:2111(_setitem_single_column)\n",
      "      124    0.000    0.000    0.004    0.000 _methods.py:39(_amax)\n",
      "       52    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "       14    0.000    0.000    0.001    0.000 missing.py:466(array_equivalent)\n",
      "       27    0.000    0.000    0.077    0.003 fromnumeric.py:53(_wrapfunc)\n",
      "      612    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        6    0.000    0.000    0.001    0.000 generic.py:1870(_get_label_or_level_values)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:304(_get_filepath_or_buffer)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen posixpath>:71(join)\n",
      "        1    0.000    0.000    0.009    0.009 decode_target_utils.py:194(find_single_vis_target_df)\n",
      "       25    0.000    0.000    0.000    0.000 range.py:201(_simple_new)\n",
      "      225    0.000    0.000    0.000    0.000 managers.py:2177(_grouping_func)\n",
      "      222    0.000    0.000    0.000    0.000 c_parser_wrapper.py:370(<setcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:958(fast_xs)\n",
      "       20    0.000    0.000    0.000    0.000 managers.py:1772(_consolidate_check)\n",
      "      780    0.000    0.000    0.000    0.000 base.py:363(ndim)\n",
      "        3    0.000    0.000    0.020    0.007 concat.py:622(get_result)\n",
      "      102    0.000    0.000    0.000    0.000 base.py:609(_dtype_to_subclass)\n",
      "      161    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "        8    0.000    0.000    0.000    0.000 construction.py:487(<listcomp>)\n",
      "        3    0.000    0.000    0.001    0.000 nanops.py:455(newfunc)\n",
      "       74    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "       53    0.000    0.000    0.000    0.000 missing.py:673(na_value_for_dtype)\n",
      "       24    0.000    0.000    0.000    0.000 shape_base.py:81(atleast_2d)\n",
      "        3    0.000    0.000    0.001    0.000 merge.py:1232(_get_merge_keys)\n",
      "        9    0.000    0.000    0.005    0.001 indexing.py:1032(_getitem_lowerdim)\n",
      "       10    0.000    0.000    0.005    0.000 indexing.py:1785(_setitem_with_indexer)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
      "       17    0.000    0.000    0.006    0.000 indexing.py:1397(_getitem_axis)\n",
      "        2    0.000    0.000    0.000    0.000 format.py:587(_read_array_header)\n",
      "      312    0.000    0.000    0.000    0.000 blocks.py:718(dtype)\n",
      "      511    0.000    0.000    0.000    0.000 base.py:5144(_values)\n",
      "       27    0.000    0.000    0.007    0.000 series.py:6133(_arith_method)\n",
      "       33    0.000    0.000    0.000    0.000 base.py:3996(_check_indexing_method)\n",
      "       35    0.000    0.000    0.000    0.000 base.py:6324(_maybe_downcast_for_indexing)\n",
      "       44    0.000    0.000    0.000    0.000 _asarray.py:108(<setcomp>)\n",
      "        2    0.000    0.000    0.030    0.015 format.py:738(read_array)\n",
      "        4    0.000    0.000    0.000    0.000 take.py:353(wrapper)\n",
      "      321    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "       10    0.000    0.000    0.001    0.000 indexing.py:744(_get_setitem_indexer)\n",
      "        1    0.000    0.000    0.014    0.014 decode_target_class.py:309(_find_single_vis_target_df)\n",
      "      124    0.000    0.000    0.000    0.000 blocks.py:219(_can_consolidate)\n",
      "       24    0.000    0.000    0.000    0.000 fromnumeric.py:1025(argsort)\n",
      "       10    0.000    0.000    0.001    0.000 managers.py:1298(column_setitem)\n",
      "       74    0.000    0.000    0.000    0.000 fromnumeric.py:1768(ravel)\n",
      "      300    0.000    0.000    0.000    0.000 common.py:1270(is_1d_only_ea_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:1002(_maybe_add_join_keys)\n",
      "       72    0.000    0.000    0.000    0.000 common.py:1040(needs_i8_conversion)\n",
      "      260    0.000    0.000    0.000    0.000 base.py:1671(name)\n",
      "       38    0.000    0.000    0.000    0.000 managers.py:1850(from_blocks)\n",
      "        1    0.000    0.000    0.000    0.000 astype.py:56(_astype_nansafe)\n",
      "       37    0.000    0.000    0.000    0.000 base.py:5295(_validate_fill_value)\n",
      "        6    0.000    0.000    0.000    0.000 merge.py:1012(<genexpr>)\n",
      "       12    0.000    0.000    0.011    0.001 series.py:6418(_reduce)\n",
      "       53    0.000    0.000    0.000    0.000 blocks.py:253(fill_value)\n",
      "       45    0.000    0.000    0.004    0.000 expressions.py:67(_evaluate_standard)\n",
      "        2    0.000    0.000    0.004    0.002 base.py:4557(join)\n",
      "        6    0.000    0.000    0.001    0.000 indexing.py:2348(_align_series)\n",
      "        6    0.000    0.000    0.002    0.000 series.py:607(_init_dict)\n",
      "        3    0.000    0.000    0.003    0.001 base.py:176(isna)\n",
      "      185    0.000    0.000    0.000    0.000 inference.py:300(<genexpr>)\n",
      "        6    0.000    0.000    0.001    0.000 {built-in method builtins.print}\n",
      "       14    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        9    0.000    0.000    0.006    0.001 indexing.py:1365(_getitem_tuple)\n",
      "       19    0.000    0.000    0.007    0.000 base.py:6162(get_indexer_for)\n",
      "       28    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        3    0.000    0.000    0.004    0.001 generic.py:1931(_drop_labels_or_levels)\n",
      "       79    0.000    0.000    0.000    0.000 utils.py:62(is_list_like_indexer)\n",
      "       93    0.000    0.000    0.000    0.000 range.py:315(step)\n",
      "      221    0.000    0.000    0.000    0.000 base.py:974(dtype)\n",
      "        1    0.000    0.000    0.003    0.003 generic.py:12498(sum)\n",
      "       22    0.000    0.000    0.000    0.000 base.py:773(_view)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:301(maybe_iterable_to_list)\n",
      "       91    0.000    0.000    0.001    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "       86    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.001    0.001 frame.py:11603(any)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:1204(is_potential_multi_index)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:2133(_refine_defaults_read)\n",
      "      358    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "      141    0.000    0.000    0.000    0.000 managers.py:913(__init__)\n",
      "       51    0.000    0.000    0.000    0.000 generic.py:4402(_check_setitem_copy)\n",
      "       20    0.000    0.000    0.001    0.000 indexing.py:1452(_convert_to_indexer)\n",
      "        9    0.000    0.000    0.007    0.001 nanops.py:253(_get_values)\n",
      "       43    0.000    0.000    0.000    0.000 enum.py:193(__get__)\n",
      "       91    0.000    0.000    0.001    0.000 _methods.py:43(_amin)\n",
      "       25    0.000    0.000    0.002    0.000 frame.py:12675(_reindex_for_setitem)\n",
      "       20    0.000    0.000    0.000    0.000 managers.py:1764(is_consolidated)\n",
      "       12    0.000    0.000    0.000    0.000 generic.py:1740(_is_level_reference)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:558(__exit__)\n",
      "       13    0.000    0.000    0.000    0.000 managers.py:303(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:829(_ensure_listlike_indexer)\n",
      "        6    0.000    0.000    0.000    0.000 missing.py:564(_array_equivalent_object)\n",
      "      470    0.000    0.000    0.000    0.000 decode_target_utils.py:201(<lambda>)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:535(_check_cacher)\n",
      "       48    0.000    0.000    0.000    0.000 frame.py:4623(_clear_item_cache)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:191(_validate_parse_dates_presence)\n",
      "       18    0.000    0.000    0.000    0.000 algorithms.py:1131(take)\n",
      "       21    0.000    0.000    0.000    0.000 managers.py:2320(_preprocess_slice_or_indexer)\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:1265(_iset_single)\n",
      "        1    0.000    0.000    0.000    0.000 roperator.py:10(radd)\n",
      "        7    0.000    0.000    0.005    0.001 frame.py:4360(_iset_not_inplace)\n",
      "        1    0.000    0.000    0.021    0.021 neural_data_processing.py:59(_load_spike_times)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:405(__init__)\n",
      "       50    0.000    0.000    0.000    0.000 missing.py:728(is_valid_na_for_dtype)\n",
      "        3    0.000    0.000    0.019    0.006 concat.py:202(_maybe_reindex_columns_na_proxy)\n",
      "        6    0.000    0.000    0.000    0.000 series.py:6459(any)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:1165(_is_binary_mode)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _operator.eq}\n",
      "        3    0.000    0.000    0.001    0.000 base.py:3449(intersection)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:1216(_get_rows_with_mask)\n",
      "        6    0.000    0.000    0.001    0.000 generic.py:4883(_update_inplace)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:1798(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:4201(_convert_slice_indexer)\n",
      "       27    0.000    0.000    0.000    0.000 _ufunc_config.py:430(__enter__)\n",
      "      178    0.000    0.000    0.000    0.000 fromnumeric.py:3176(ndim)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:836(__iter__)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
      "      162    0.000    0.000    0.000    0.000 managers.py:246(items)\n",
      "        3    0.000    0.000    0.037    0.012 merge.py:1129(_get_join_info)\n",
      "        1    0.000    0.000    0.000    0.000 neural_vs_behavioral_class.py:35(get_basic_data)\n",
      "       19    0.000    0.000    0.000    0.000 common.py:103(_maybe_match_name)\n",
      "      113    0.000    0.000    0.000    0.000 base.py:1176(_maybe_disallow_fill)\n",
      "       22    0.000    0.000    0.000    0.000 managers.py:583(copy_func)\n",
      "       16    0.000    0.000    0.000    0.000 blocks.py:2827(external_values)\n",
      "        2    0.000    0.000    0.001    0.000 generic.py:1070(_rename)\n",
      "      117    0.000    0.000    0.000    0.000 function.py:64(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:237(ndarray_to_mgr)\n",
      "        7    0.000    0.000    0.000    0.000 api.py:386(default_index)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:324(slice_block_columns)\n",
      "      106    0.000    0.000    0.000    0.000 series.py:914(__len__)\n",
      "       18    0.000    0.000    0.000    0.000 warnings.py:166(simplefilter)\n",
      "        6    0.000    0.000    0.011    0.002 generic.py:12362(_stat_function)\n",
      "        2    0.000    0.000    0.000    0.000 astype.py:191(astype_array_safe)\n",
      "        1    0.000    0.000    0.003    0.003 time_calib_utils.py:62(find_offset_neural_txt_const)\n",
      "      631    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
      "       23    0.000    0.000    0.000    0.000 series.py:664(_constructor_from_mgr)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:935(_verify_integrity)\n",
      "       36    0.000    0.000    0.000    0.000 base.py:6415(_is_comparable_dtype)\n",
      "       22    0.000    0.000    0.000    0.000 base.py:1010(view)\n",
      "        6    0.000    0.000    0.000    0.000 c_parser_wrapper.py:330(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 neural_vs_behavioral_class.py:41(make_relevant_paths)\n",
      "       74    0.000    0.000    0.000    0.000 numeric.py:1380(<listcomp>)\n",
      "        3    0.000    0.000    0.001    0.000 merge.py:2697(_items_overlap_with_suffix)\n",
      "       43    0.000    0.000    0.000    0.000 enum.py:1257(value)\n",
      "       20    0.000    0.000    0.000    0.000 blocks.py:274(make_block)\n",
      "       12    0.000    0.000    0.000    0.000 generic.py:5598(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:550(infer_compression)\n",
      "        1    0.000    0.000    0.023    0.023 monkey_heading_functions.py:98(add_monkey_heading_info_to_curv_of_traj_df)\n",
      "       38    0.000    0.000    0.000    0.000 __init__.py:225(compile)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:638(_extract_index)\n",
      "      316    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "       54    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
      "        3    0.000    0.000    0.021    0.007 concat.py:157(concat)\n",
      "        6    0.000    0.000    0.000    0.000 c_parser_wrapper.py:194(close)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:259(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:1697(_validate_names)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:494(_clean_keys_and_objs)\n",
      "       68    0.000    0.000    0.000    0.000 base.py:6312(_index_as_unique)\n",
      "        6    0.000    0.000    0.000    0.000 c_parser_wrapper.py:201(_set_noconvert_columns)\n",
      "        6    0.000    0.000    0.001    0.000 generic.py:5343(reindex)\n",
      "        1    0.000    0.000   13.055   13.055 <string>:1(<module>)\n",
      "        6    0.000    0.000    0.001    0.000 generic.py:4342(_getitem_slice)\n",
      "        1    0.000    0.000    0.001    0.001 blocks.py:1021(replace_list)\n",
      "       93    0.000    0.000    0.000    0.000 range.py:280(start)\n",
      "        6    0.000    0.000    0.000    0.000 c_parser_wrapper.py:212(<dictcomp>)\n",
      "        3    0.000    0.000    0.002    0.001 generic.py:7142(fillna)\n",
      "       57    0.000    0.000    0.000    0.000 common.py:131(<lambda>)\n",
      "       74    0.000    0.000    0.000    0.000 frame.py:1030(axes)\n",
      "       16    0.000    0.000    0.000    0.000 managers.py:2000(external_values)\n",
      "       25    0.000    0.000    0.004    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "       87    0.000    0.000    0.000    0.000 function_base.py:1320(_diff_dispatcher)\n",
      "       24    0.000    0.000    0.000    0.000 shape_base.py:215(_vhstack_dispatcher)\n",
      "        9    0.000    0.000    0.002    0.000 nanops.py:1499(_maybe_null_out)\n",
      "        6    0.000    0.000    0.011    0.002 nanops.py:111(f)\n",
      "       15    0.000    0.000    0.000    0.000 nanops.py:79(<genexpr>)\n",
      "       28    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        6    0.000    0.000    0.001    0.000 series.py:5136(reindex)\n",
      "        6    0.000    0.000    0.011    0.002 nanops.py:1083(reduction)\n",
      "      160    0.000    0.000    0.000    0.000 multiarray.py:1080(copyto)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:160(is_url)\n",
      "       27    0.000    0.000    0.000    0.000 _ufunc_config.py:435(__exit__)\n",
      "        9    0.000    0.000    0.000    0.000 generic.py:1771(_is_label_reference)\n",
      "       26    0.000    0.000    0.000    0.000 indexing.py:305(loc)\n",
      "       84    0.000    0.000    0.000    0.000 base.py:2776(_is_multi)\n",
      "        2    0.000    0.000    0.001    0.001 apply.py:1482(apply_standard)\n",
      "       31    0.000    0.000    0.000    0.000 _validators.py:226(validate_bool_kwarg)\n",
      "        4    0.000    0.000    0.000    0.000 getlimits.py:685(__init__)\n",
      "        9    0.000    0.000    0.000    0.000 indexing.py:1251(_is_scalar_access)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:871(_do_date_conversions)\n",
      "       10    0.000    0.000    0.001    0.000 managers.py:372(setitem)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.003    0.003 generic.py:12459(_min_count_stat_function)\n",
      "       39    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:1622(close)\n",
      "        2    0.000    0.000    0.001    0.001 series.py:4789(apply)\n",
      "      213    0.000    0.000    0.000    0.000 base.py:6672(_maybe_cast_indexer)\n",
      "      108    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
      "       10    0.000    0.000    0.001    0.000 generic.py:6432(dtypes)\n",
      "       14    0.000    0.000    0.001    0.000 generic.py:4159(xs)\n",
      "      151    0.000    0.000    0.000    0.000 fromnumeric.py:861(_sort_dispatcher)\n",
      "       27    0.000    0.000    0.000    0.000 array_ops.py:594(_bool_arith_check)\n",
      "       27    0.000    0.000    0.000    0.000 series.py:6137(_align_for_op)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
      "       57    0.000    0.000    0.000    0.000 common.py:126(_classes_and_not_datetimelike)\n",
      "       93    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "       24    0.000    0.000    0.000    0.000 managers.py:2294(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:6537(<listcomp>)\n",
      "       11    0.000    0.000    0.000    0.000 managers.py:937(<genexpr>)\n",
      "      146    0.000    0.000    0.000    0.000 series.py:660(_constructor)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:136(ones)\n",
      "        2    0.000    0.000    0.001    0.000 blocks.py:1706(pad_or_backfill)\n",
      "        3    0.000    0.000    0.001    0.000 nanops.py:604(nansum)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:1027(safe_eval)\n",
      "       24    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        2    0.000    0.000    0.001    0.001 generic.py:12169(_logical_func)\n",
      "      178    0.000    0.000    0.000    0.000 fromnumeric.py:3172(_ndim_dispatcher)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:1363(_maybe_coerce_merge_keys)\n",
      "        6    0.000    0.000    0.011    0.002 frame.py:5433(drop)\n",
      "        6    0.000    0.000    0.002    0.000 nanops.py:1547(check_below_min_count)\n",
      "       45    0.000    0.000    0.000    0.000 frame.py:4585(_ensure_valid_index)\n",
      "       24    0.000    0.000    0.000    0.000 base.py:1765(_get_names)\n",
      "       22    0.000    0.000    0.000    0.000 base.py:238(construct_from_string)\n",
      "      108    0.000    0.000    0.000    0.000 blocks.py:266(mgr_locs)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:248(stringify_path)\n",
      "      222    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}\n",
      "       33    0.000    0.000    0.002    0.000 base.py:6679(_maybe_cast_listlike_indexer)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:131(close)\n",
      "       18    0.000    0.000    0.000    0.000 common.py:188(_expand_user)\n",
      "      182    0.000    0.000    0.000    0.000 series.py:1480(_clear_item_cache)\n",
      "       25    0.000    0.000    0.004    0.000 _methods.py:47(_sum)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:7885(replace)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:5651(identical)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:1801(_is_label_or_level_reference)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:1269(_process_date_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 neural_data_processing.py:120(calculate_window_parameters)\n",
      "       18    0.000    0.000    0.000    0.000 <frozen posixpath>:229(expanduser)\n",
      "        6    0.000    0.000    0.000    0.000 c_parser_wrapper.py:326(<listcomp>)\n",
      "        2    0.000    0.000    0.002    0.001 managers.py:1483(reduce)\n",
      "     17/2    0.000    0.000    0.000    0.000 ast.py:84(_convert)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:601(_set_noconvert_dtype_columns)\n",
      "       15    0.000    0.000    0.000    0.000 indexing.py:1667(_validate_integer)\n",
      "        2    0.000    0.000    0.000    0.000 ast.py:54(literal_eval)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:38(is_valid_positional_slice)\n",
      "        5    0.000    0.000    0.001    0.000 series.py:3035(diff)\n",
      "       13    0.000    0.000    0.000    0.000 blocks.py:259(_standardize_fill_value)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:2582(array_values)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:782(_maybe_mask_setitem_value)\n",
      "        6    0.000    0.000    0.000    0.000 parse.py:119(_coerce_args)\n",
      "        2    0.000    0.000    0.001    0.000 numpy_.py:245(_pad_or_backfill)\n",
      "       86    0.000    0.000    0.000    0.000 fromnumeric.py:2317(_any_dispatcher)\n",
      "        6    0.000    0.000    0.000    0.000 copy.py:66(copy)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:1123(_make_date_converter)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:1826(_check_label_or_level_ambiguity)\n",
      "        8    0.000    0.000    0.000    0.000 frame.py:4470(_iset_item_mgr)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:4440(_maybe_preserve_names)\n",
      "       10    0.000    0.000    0.001    0.000 utils.py:290(length_of_indexer)\n",
      "       14    0.000    0.000    0.000    0.000 iostream.py:577(_schedule_flush)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen genericpath>:16(exists)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:502(enter_context)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:3535(_intersection)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:480(_get_ndims)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.mkdir}\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1954(get_rows_with_mask)\n",
      "       57    0.000    0.000    0.000    0.000 indexing.py:2772(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 managers.py:288(<listcomp>)\n",
      "        1    0.000    0.000    0.011    0.011 neural_data_processing.py:67(_load_spike_clusters)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:292(is_fsspec_url)\n",
      "       14    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:5425(_getitem_slice)\n",
      "        7    0.000    0.000    0.005    0.001 frame.py:4320(_setitem_array)\n",
      "       32    0.000    0.000    0.000    0.000 construction.py:688(_sanitize_non_ordered)\n",
      "        3    0.000    0.000    0.000    0.000 range.py:488(copy)\n",
      "        2    0.000    0.000    0.001    0.000 generic.py:5663(_reindex_with_indexers)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:545(_get_sample_object)\n",
      "       27    0.000    0.000    0.000    0.000 indexing.py:1181(<genexpr>)\n",
      "        7    0.000    0.000    0.002    0.000 indexing.py:1205(_getbool_axis)\n",
      "       86    0.000    0.000    0.000    0.000 histograms.py:673(_histogram_dispatcher)\n",
      "       25    0.000    0.000    0.000    0.000 indexing.py:161(iloc)\n",
      "        3    0.000    0.000    0.019    0.006 concat.py:94(concatenate_managers)\n",
      "        9    0.000    0.000    0.000    0.000 range.py:483(_view)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:1935(delete)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:2167(__array_ufunc__)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:5491(_concat)\n",
      "        7    0.000    0.000    0.000    0.000 function.py:413(validate_func)\n",
      "        6    0.000    0.000    0.000    0.000 c_parser_wrapper.py:213(<listcomp>)\n",
      "       16    0.000    0.000    0.000    0.000 series.py:789(values)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:91(ensure_python_int)\n",
      "       10    0.000    0.000    0.001    0.000 indexing.py:985(_convert_tuple)\n",
      "       18    0.000    0.000    0.000    0.000 inference.py:373(is_sequence)\n",
      "       24    0.000    0.000    0.000    0.000 common.py:1229(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 managers.py:586(<listcomp>)\n",
      "        6    0.000    0.000    0.011    0.002 generic.py:12397(max)\n",
      "        2    0.000    0.000    0.001    0.000 generic.py:6463(astype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:207(validate_header_arg)\n",
      "       69    0.000    0.000    0.000    0.000 multiarray.py:1131(putmask)\n",
      "       10    0.000    0.000    0.001    0.000 indexing.py:989(<listcomp>)\n",
      "        2    0.000    0.000    0.004    0.002 base.py:269(join)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:723(astype)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:362(_make_index)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:195(any_not_none)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:5455(append)\n",
      "       68    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 format.py:223(read_magic)\n",
      "       24    0.000    0.000    0.000    0.000 managers.py:241(is_single_block)\n",
      "       57    0.000    0.000    0.000    0.000 indexing.py:2781(<genexpr>)\n",
      "        1    0.000    0.000    0.411    0.411 decode_target_class.py:280(_get_curv_of_traj_df)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:774(infer_dtype_from_scalar)\n",
      "       18    0.000    0.000    0.000    0.000 indexing.py:2738(is_label_like)\n",
      "        2    0.000    0.000    0.000    0.000 numpy_.py:95(__init__)\n",
      "        6    0.000    0.000    0.001    0.000 frame.py:11458(blk_func)\n",
      "        8    0.000    0.000    0.001    0.000 range.py:1009(__getitem__)\n",
      "       42    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:3995(_maybe_update_cacher)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5224(_from_join_target)\n",
      "        2    0.000    0.000    0.000    0.000 astype.py:157(astype_array)\n",
      "       30    0.000    0.000    0.000    0.000 indexing.py:903(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 frozen.py:76(__getitem__)\n",
      "       37    0.000    0.000    0.000    0.000 numeric.py:1455(<listcomp>)\n",
      "        6    0.000    0.000    0.001    0.000 arraylike.py:98(__add__)\n",
      "       90    0.000    0.000    0.000    0.000 common.py:511(f)\n",
      "       12    0.000    0.000    0.000    0.000 nanops.py:482(nanany)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
      "        9    0.000    0.000    0.000    0.000 blocks.py:414(_split_op_result)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "        9    0.000    0.000    0.000    0.000 construction.py:196(mgr_to_mgr)\n",
      "        2    0.000    0.000    0.001    0.000 frame.py:5636(rename)\n",
      "       64    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:858(pad_or_backfill_inplace)\n",
      "       12    0.000    0.000    0.000    0.000 merge.py:2684(_validate_operand)\n",
      "       14    0.000    0.000    0.000    0.000 frame.py:4367(igetitem)\n",
      "       16    0.000    0.000    0.000    0.000 blocks.py:249(external_values)\n",
      "       23    0.000    0.000    0.000    0.000 indexing.py:1165(_check_deprecated_callable_usage)\n",
      "       32    0.000    0.000    0.000    0.000 common.py:311(is_null_slice)\n",
      "       12    0.000    0.000    0.000    0.000 indexing.py:1226(_validate_key)\n",
      "        9    0.000    0.000    0.000    0.000 indexing.py:974(_is_nested_tuple_indexer)\n",
      "        3    0.000    0.000    0.001    0.000 concat.py:702(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3766(_convert_can_do_setop)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:1426(_validate_parse_dates_arg)\n",
      "        6    0.000    0.000    0.011    0.002 series.py:6509(max)\n",
      "        1    0.000    0.000    0.020    0.020 series.py:2344(unique)\n",
      "        9    0.000    0.000    0.000    0.000 generic.py:580(_get_axis_name)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:958(_maybe_restore_index_levels)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:266(index_labels_to_array)\n",
      "       15    0.000    0.000    0.000    0.000 <frozen posixpath>:41(_get_sep)\n",
      "        2    0.000    0.000    0.000    0.000 apply.py:1377(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:534(_push_cm_exit)\n",
      "        3    0.000    0.000    0.000    0.000 api.py:72(get_objs_combined_axis)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1192(is_alive)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:707(_get_comb_axis)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:2794(_na_value)\n",
      "       24    0.000    0.000    0.000    0.000 base.py:540(<genexpr>)\n",
      "        3    0.000    0.000    0.003    0.001 frame.py:6488(isna)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3760(_assert_can_do_setop)\n",
      "       74    0.000    0.000    0.000    0.000 function_base.py:5559(_append_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:262(_get_hashtable_algo)\n",
      "        2    0.000    0.000    0.000    0.000 py3k.py:49(isfileobj)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:481(<listcomp>)\n",
      "       74    0.000    0.000    0.000    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "       19    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:341(setitem_inplace)\n",
      "       10    0.000    0.000    0.002    0.000 arraylike.py:192(__sub__)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "        3    0.000    0.000    0.001    0.000 concat.py:717(_get_concat_axis)\n",
      "       44    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        3    0.000    0.000    0.002    0.001 base.py:180(fillna)\n",
      "       10    0.000    0.000    0.000    0.000 blocks.py:1269(set_inplace)\n",
      "       12    0.000    0.000    0.000    0.000 inference.py:105(is_file_like)\n",
      "       34    0.000    0.000    0.000    0.000 common.py:1122(<lambda>)\n",
      "        6    0.000    0.000    0.000    0.000 format.py:951(_read_bytes)\n",
      "        9    0.000    0.000    0.007    0.001 nanops.py:209(_maybe_get_mask)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:188(all_none)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:1095(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:12678(_inplace_method)\n",
      "        2    0.000    0.000    0.000    0.000 dtypes.py:1305(construct_from_string)\n",
      "        4    0.000    0.000    0.000    0.000 getlimits.py:696(min)\n",
      "        8    0.000    0.000    0.000    0.000 indexing.py:1379(_get_label)\n",
      "        4    0.000    0.000    0.000    0.000 blocks.py:363(_can_hold_element)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "       20    0.000    0.000    0.000    0.000 indexing.py:992(_validate_key_length)\n",
      "        6    0.000    0.000    0.001    0.000 generic.py:8693(isna)\n",
      "        3    0.000    0.000    0.000    0.000 api.py:106(_get_distinct_objs)\n",
      "       74    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen os>:200(makedirs)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5036(_wrap_joined_index)\n",
      "       27    0.000    0.000    0.000    0.000 indexing.py:981(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:6520(_transform_index)\n",
      "        2    0.000    0.000    0.000    0.000 dtypes.py:342(construct_from_string)\n",
      "        2    0.000    0.000    0.001    0.000 generic.py:7061(_pad_or_backfill)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:279(_extract_multi_indexer_columns)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:1554(_validate_left_right_on)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1117(_maybe_memory_map)\n",
      "        6    0.000    0.000    0.000    0.000 putmask.py:101(validate_putmask)\n",
      "        3    0.000    0.000    0.001    0.000 concat.py:699(new_axes)\n",
      "        8    0.000    0.000    0.000    0.000 missing.py:157(clean_fill_method)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1604(maybe_cast_to_integer_array)\n",
      "        2    0.000    0.000    0.004    0.002 base.py:4983(_join_monotonic)\n",
      "       47    0.000    0.000    0.000    0.000 managers.py:344(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 merge.py:2588(_convert_arrays_and_get_rizer_klass)\n",
      "        4    0.000    0.000    0.000    0.000 getlimits.py:709(max)\n",
      "        2    0.000    0.000    0.001    0.000 base.py:891(_map_values)\n",
      "        2    0.000    0.000    0.004    0.002 indexing.py:1334(_getitem_iterable)\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        6    0.000    0.000    0.000    0.000 base.py:3035(unique)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:893(_check_data_length)\n",
      "       13    0.000    0.000    0.000    0.000 managers.py:291(arrays)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:1990(__exit__)\n",
      "        1    0.000    0.000    0.001    0.001 indexing.py:1004(_getitem_tuple_same_dim)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen posixpath>:100(split)\n",
      "       27    0.000    0.000    0.000    0.000 _ufunc_config.py:426(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 apply.py:121(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:567(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:280(_check_object_for_strings)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:4436(_wrap_reindex_result)\n",
      "        3    0.000    0.000    0.000    0.000 api.py:120(_get_combined_index)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:123(check_setitem_lengths)\n",
      "        5    0.000    0.000    0.000    0.000 generic.py:2077(__contains__)\n",
      "        3    0.000    0.000    0.076    0.025 fromnumeric.py:1332(searchsorted)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:6270(<genexpr>)\n",
      "        2    0.000    0.000    0.001    0.000 base.py:299(pad_or_backfill)\n",
      "        3    0.000    0.000    0.000    0.000 _validators.py:271(validate_fillna_kwargs)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:1262(_slice)\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:2979(prod)\n",
      "        9    0.000    0.000    0.000    0.000 generic.py:6277(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:515(get_compression_method)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "        6    0.000    0.000    0.001    0.000 series.py:5773(isna)\n",
      "       62    0.000    0.000    0.000    0.000 {built-in method sys.getrefcount}\n",
      "       11    0.000    0.000    0.000    0.000 series.py:1073(_ixs)\n",
      "        3    0.000    0.000    0.000    0.000 range.py:1032(_getitem_slice)\n",
      "        9    0.000    0.000    0.000    0.000 putmask.py:115(extract_bool_array)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup_error}\n",
      "        2    0.000    0.000    0.000    0.000 format.py:282(descr_to_dtype)\n",
      "       39    0.000    0.000    0.000    0.000 missing.py:1073(clean_reindex_fill_method)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:1674(_check_file_or_buffer)\n",
      "        1    0.000    0.000    0.003    0.003 frame.py:11661(sum)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        6    0.000    0.000    0.001    0.000 arraylike.py:54(__gt__)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:935(_expand_ellipsis)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:184(_reconstruct_data)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
      "       18    0.000    0.000    0.000    0.000 indexing.py:2398(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 replace.py:31(should_use_regex)\n",
      "       37    0.000    0.000    0.000    0.000 function_base.py:5365(_insert_dispatcher)\n",
      "       30    0.000    0.000    0.000    0.000 indexing.py:902(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 merge.py:2680(_any)\n",
      "       14    0.000    0.000    0.000    0.000 displaypub.py:150(is_publishing)\n",
      "       27    0.000    0.000    0.000    0.000 indexing.py:1180(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:533(_maybe_downcast)\n",
      "        2    0.000    0.000    0.000    0.000 numpy_.py:492(to_numpy)\n",
      "       12    0.000    0.000    0.000    0.000 indexing.py:2376(ravel)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:761(infer_dtype_from)\n",
      "       12    0.000    0.000    0.000    0.000 blocks.py:1249(shape)\n",
      "        2    0.000    0.000    0.003    0.001 indexing.py:1532(_get_listlike_indexer)\n",
      "       35    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1277(is_extension_array_dtype)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:295(maybe_make_list)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1216(_iset_split_block)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:267(replace_list)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:1903(<listcomp>)\n",
      "       37    0.000    0.000    0.000    0.000 multiarray.py:892(bincount)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:2381(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 curv_of_traj_utils.py:378(get_curv_of_traj_trace_name)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1125(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.round}\n",
      "       10    0.000    0.000    0.000    0.000 base.py:332(array)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:1439(_indexed_same)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:742(_get_axes)\n",
      "        2    0.000    0.000    0.000    0.000 arraylike.py:50(__le__)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:5676(<genexpr>)\n",
      "       12    0.000    0.000    0.000    0.000 nanops.py:72(check)\n",
      "        6    0.000    0.000    0.000    0.000 <string>:2(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:12590(values)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:2056(_clean_na_values)\n",
      "        3    0.000    0.000    0.001    0.000 concat.py:777(_concat_indexes)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:230(_can_hold_na)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:918(new_func)\n",
      "        2    0.000    0.000    0.000    0.000 dtypes.py:831(construct_from_string)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:421(astype)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5204(_get_join_target)\n",
      "       30    0.000    0.000    0.000    0.000 indexing.py:941(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
      "        1    0.000    0.000    0.000    0.000 arraylike.py:345(_reconstruct)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:1073(<genexpr>)\n",
      "        1    0.000    0.000    0.020    0.020 base.py:1019(unique)\n",
      "       18    0.000    0.000    0.000    0.000 base_parser.py:1447(is_index_col)\n",
      "       37    0.000    0.000    0.000    0.000 numeric.py:1389(_moveaxis_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:984(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1633(as_array)\n",
      "       24    0.000    0.000    0.000    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:336(_na_ok_dtype)\n",
      "       19    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:1698(<listcomp>)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:1441(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:2365(_validate_skipfooter)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:472(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:794(_set_axis_nocheck)\n",
      "       10    0.000    0.000    0.000    0.000 blocks.py:369(should_store)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen genericpath>:39(isdir)\n",
      "        3    0.000    0.000    0.001    0.000 expressions.py:177(_where_numexpr)\n",
      "       14    0.000    0.000    0.000    0.000 displayhook.py:118(is_active)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:350(_maybe_make_multi_index_columns)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:751(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 c_parser_wrapper.py:392(ensure_dtype_objs)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "        4    0.000    0.000    0.001    0.000 arraylike.py:208(__truediv__)\n",
      "        5    0.000    0.000    0.001    0.000 arraylike.py:46(__lt__)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        3    0.000    0.000    0.000    0.000 api.py:102(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:2331(_ensure_iterable_column_indexer)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        1    0.000    0.000    0.000    0.000 curv_of_traj_utils.py:332(find_traj_curv_descr)\n",
      "        2    0.000    0.000    0.000    0.000 ast.py:33(parse)\n",
      "       17    0.000    0.000    0.000    0.000 base.py:692(_constructor)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:237(_data)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:2021(setitem_inplace)\n",
      "        3    0.000    0.000    0.000    0.000 nanops.py:324(_get_dtype_max)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3439(_wrap_setop_result)\n",
      "        2    0.000    0.000    0.001    0.001 apply.py:1409(apply)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:106(_ensure_data)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       19    0.000    0.000    0.000    0.000 contextlib.py:440(__init__)\n",
      "       19    0.000    0.000    0.000    0.000 contextlib.py:446(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:505(get_rename_function)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:5486(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:187(_get_fill_value)\n",
      "        4    0.000    0.000    0.000    0.000 cast.py:1722(can_hold_element)\n",
      "        2    0.000    0.000    0.000    0.000 dtypes.py:1054(construct_from_string)\n",
      "        6    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:7484(ffill)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:1333(searchsorted)\n",
      "        1    0.000    0.000    0.000    0.000 base_processing_class.py:97(make_or_retrieve_ff_dataframe)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:782(_rename)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:1169(_replace_coerce)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2095(create_block_manager_from_blocks)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method sys.exc_info}\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:2140(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:122(_reset_cache)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:1962(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 config.py:688(_warn_if_deprecated)\n",
      "        6    0.000    0.000    0.000    0.000 frame.py:1047(shape)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:828(replace)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 base_processing_class.py:236(retrieve_or_make_monkey_data)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1432(find_common_type)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        3    0.000    0.000    0.000    0.000 arraylike.py:58(__ge__)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:2721(is_nested_tuple)\n",
      "       28    0.000    0.000    0.000    0.000 managers.py:1828(ndim)\n",
      "        6    0.000    0.000    0.000    0.000 _validators.py:450(check_dtype_backend)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:389(item)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.generic' objects}\n",
      "       14    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:1793(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:7652(ensure_has_len)\n",
      "        3    0.000    0.000    0.001    0.000 arraylike.py:200(__mul__)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:255(_has_complex_date_col)\n",
      "       24    0.000    0.000    0.000    0.000 shape_base.py:77(_atleast_2d_dispatcher)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:235(<setcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:2674(_should_fill)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:378(interleaved_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:2082(empty)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:5058(_can_use_libjoin)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:3260(searchsorted)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:199(<genexpr>)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:343(is_full_slice)\n",
      "        7    0.000    0.000    0.000    0.000 fromnumeric.py:1980(shape)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:2267(_extract_dialect)\n",
      "        2    0.000    0.000    0.000    0.000 inference.py:141(is_re)\n",
      "        3    0.000    0.000    0.001    0.000 expressions.py:246(where)\n",
      "        2    0.000    0.000    0.000    0.000 string_.py:140(construct_from_string)\n",
      "        1    0.000    0.000    0.000    0.000 arraylike.py:188(__radd__)\n",
      "       19    0.000    0.000    0.000    0.000 contextlib.py:443(__enter__)\n",
      "        9    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       10    0.000    0.000    0.000    0.000 common.py:323(is_empty_slice)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:5495(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2692(max)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:986(_validate_usecols_arg)\n",
      "        1    0.000    0.000    0.001    0.001 algorithms.py:1248(searchsorted)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:756(_shallow_copy)\n",
      "        2    0.000    0.000    0.000    0.000 dtypes.py:2228(construct_from_string)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       12    0.000    0.000    0.000    0.000 common.py:192(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3565(_wrap_intersection_result)\n",
      "        2    0.000    0.000    0.000    0.000 dtypes.py:1835(construct_from_string)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:178(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:957(_validate_tuple_indexer)\n",
      "       10    0.000    0.000    0.000    0.000 blocks.py:805(_maybe_copy)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5088(values)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_io._IOBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:1066(get_fill_func)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1285(_multi_take_opportunity)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:1045(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:693(_get_result_dim)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:174(not_none)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:7677(bfill)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:12721(__isub__)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:12716(__iadd__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'bytes' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "       12    0.000    0.000    0.000    0.000 readers.py:527(validate_integer)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:539(_push_exit_callback)\n",
      "        3    0.000    0.000    0.000    0.000 putmask.py:129(setitem_datetimelike_compat)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:865(_references)\n",
      "       14    0.000    0.000    0.000    0.000 base.py:1979(nlevels)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:4518(_check_inplace_and_allows_duplicate_labels)\n",
      "        2    0.000    0.000    0.000    0.000 dtypes.py:1454(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:1975(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:1255(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:1973(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 generic.py:7045(_deprecate_downcast)\n",
      "        2    0.000    0.000    0.000    0.000 arraylike.py:240(__pow__)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:559(_validate_names)\n",
      "        4    0.000    0.000    0.000    0.000 multiarray.py:346(where)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 format.py:652(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:12199(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2416(_all_dispatcher)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:56(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 arraylike.py:338(reconstruct)\n",
      "        8    0.000    0.000    0.000    0.000 numeric.py:2374(_array_equal_dispatcher)\n",
      "        6    0.000    0.000    0.000    0.000 range.py:231(_constructor)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:166(is_re_compilable)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:669(range_to_ndarray)\n",
      "        2    0.000    0.000    0.000    0.000 format.py:196(_check_version)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:575(is_set)\n",
      "       10    0.000    0.000    0.000    0.000 indexing.py:1248(_has_valid_setitem_indexer)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:462(_create_exit_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:902(_fillna_prep)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3211(_validate_sort_keyword)\n",
      "        6    0.000    0.000    0.000    0.000 range.py:216(_validate_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 config.py:273(__call__)\n",
      "        3    0.000    0.000    0.000    0.000 concat.py:770(_maybe_check_integrity)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:217(_ensure_arraylike)\n",
      "        6    0.000    0.000    0.000    0.000 function_base.py:5169(_delete_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\n",
      "        7    0.000    0.000    0.000    0.000 fromnumeric.py:1976(_shape_dispatcher)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:1256(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:405(_check_values_indices_shape_match)\n",
      "        1    0.000    0.000    0.000    0.000 arraylike.py:301(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:633(is_integer_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 base_parser.py:247(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 parse.py:108(_noop)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:2974(_prod_dispatcher)\n",
      "        6    0.000    0.000    0.000    0.000 copy.py:107(_copy_immutable)\n",
      "        2    0.000    0.000    0.000    0.000 numpy_.py:226(isna)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
      "        2    0.000    0.000    0.000    0.000 arraylike.py:398(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:448(size)\n",
      "        6    0.000    0.000    0.000    0.000 readers.py:1987(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 fromnumeric.py:1328(_searchsorted_dispatcher)\n",
      "        1    0.000    0.000    0.001    0.001 arraylike.py:224(__mod__)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:1847(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 arraylike.py:332(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:585(_ensure_2d)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:1303(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:7683(_validate_join_method)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:209(is_object)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:814(_get_refs_and_copy)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1128(value_getitem)\n",
      "        1    0.000    0.000    0.000    0.000 arraylike.py:418(_standardize_out_kwarg)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:7750(_maybe_try_sort)\n",
      "        2    0.000    0.000    0.000    0.000 numpy_.py:146(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:33(_fill_zeros)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:298(stop)\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:821(_validate_tolerance)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:320(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:1063(axes)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.deque' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "        2    0.000    0.000    0.000    0.000 arraylike.py:300(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1989(index)\n",
      "        3    0.000    0.000    0.000    0.000 {function FrozenList.__getitem__ at 0x1284c9800}\n",
      "        3    0.000    0.000    0.000    0.000 merge.py:815(_maybe_require_matching_dtypes)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:555(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:1318(shares_memory)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:886(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:323(_consolidate_inplace)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x10a898910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.strip_dirs().sort_stats('tottime').print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings: At least one ff has a lower bound of ff_angle_boundary equal to its upper bound after clipping, meaning that the ff's angle to boundary is greater than 90 degrees. Please check the input.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Wed Jun 11 20:36:48 2025    profile_output\n",
      "\n",
      "         267494 function calls (262694 primitive calls) in 23.427 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 1319 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    6.719    3.359    7.661    3.830 missing.py:968(_pad_2d)\n",
      "        2    6.164    3.082   21.063   10.531 neural_data_processing.py:157(add_lags_to_each_feature)\n",
      "        2    3.134    1.567    4.297    2.148 missing.py:987(_backfill_2d)\n",
      "       55    2.362    0.043    2.362    0.043 missing.py:261(_isna_array)\n",
      "      815    1.948    0.002    1.948    0.002 {method 'copy' of 'numpy.ndarray' objects}\n",
      "      783    0.838    0.001    0.851    0.001 take.py:120(_take_nd_ndarray)\n",
      "      859    0.433    0.001    0.435    0.001 numeric.py:274(full)\n",
      "       10    0.220    0.022    0.223    0.022 multi.py:758(_values)\n",
      "        2    0.198    0.099    0.325    0.163 managers.py:1707(_interleave)\n",
      "     28/6    0.107    0.004    0.107    0.018 {built-in method _abc._abc_subclasscheck}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x3a5e411d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run profiler and save output to file\n",
    "cProfile.run('dec.get_x_and_y_var()', 'profile_output')\n",
    "\n",
    "# Load stats and sort by total time\n",
    "p = pstats.Stats('profile_output')\n",
    "p.strip_dirs().sort_stats('tottime').print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings: At least one ff has a lower bound of ff_angle_boundary equal to its upper bound after clipping, meaning that the ff's angle to boundary is greater than 90 degrees. Please check the input.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Wed Jun 11 20:46:17 2025    profile_output\n",
      "\n",
      "         262057 function calls (257421 primitive calls) in 17.702 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 1224 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    5.044    2.522   15.675    7.837 neural_data_processing.py:157(add_lags_to_each_feature)\n",
      "        2    3.328    1.664    4.527    2.263 missing.py:987(_backfill_2d)\n",
      "        2    3.300    1.650    3.936    1.968 missing.py:968(_pad_2d)\n",
      "       53    2.057    0.039    2.057    0.039 missing.py:261(_isna_array)\n",
      "      798    1.172    0.001    1.172    0.001 {method 'copy' of 'numpy.ndarray' objects}\n",
      "      768    0.814    0.001    0.820    0.001 take.py:120(_take_nd_ndarray)\n",
      "      853    0.377    0.000    0.379    0.000 numeric.py:274(full)\n",
      "       10    0.317    0.032    0.320    0.032 multi.py:758(_values)\n",
      "        2    0.261    0.131    0.409    0.204 managers.py:1707(_interleave)\n",
      "      302    0.125    0.000    0.125    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x343b0eb50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run profiler and save output to file\n",
    "cProfile.run('dec.get_x_and_y_var_lags()', 'profile_output')\n",
    "\n",
    "# Load stats and sort by total time\n",
    "p = pstats.Stats('profile_output')\n",
    "p.strip_dirs().sort_stats('tottime').print_stats(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.reduce_y_var_lags(filter_vif_by_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecodeTargetClass' object has no attribute 'y_var_lags_reduced'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n",
      "\u001b[32m      1\u001b[39m subset_key_words, all_column_subsets = dec.get_subset_key_words_and_all_column_subsets_for_vif(\n",
      "\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m             \u001b[43mdec\u001b[49m\u001b[43m.\u001b[49m\u001b[43my_var_lags_reduced\u001b[49m)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: 'DecodeTargetClass' object has no attribute 'y_var_lags_reduced'"
     ]
    }
   ],
   "source": [
    "subset_key_words, all_column_subsets = dec.get_subset_key_words_and_all_column_subsets_for_vif(\n",
    "            dec.y_var_lags_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 59 features are processed for VIF.\n",
      "10 out of 59 features are processed for VIF.\n",
      "20 out of 59 features are processed for VIF.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m vif_df_dict = {}\n",
      "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, column_subset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_column_subsets):\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     vif_df_dict[subset_key_words[i]] = \u001b[43mdrop_high_vif_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_vif_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_subset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:83\u001b[39m, in \u001b[36mget_vif_df\u001b[39m\u001b[34m(var_df, verbose)\u001b[39m\n",
      "\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(var_df.shape[\u001b[32m1\u001b[39m]):\n",
      "\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# check for RuntimeWarning; print the column name that causes the warning\u001b[39;00m\n",
      "\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         vif_values.append(\u001b[43mvariance_inflation_factor\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvar_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[32m     86\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRuntimeWarning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:196\u001b[39m, in \u001b[36mvariance_inflation_factor\u001b[39m\u001b[34m(exog, exog_idx)\u001b[39m\n",
      "\u001b[32m    194\u001b[39m mask = np.arange(k_vars) != exog_idx\n",
      "\u001b[32m    195\u001b[39m x_noti = exog[:, mask]\n",
      "\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m r_squared_i = \u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_noti\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.rsquared\n",
      "\u001b[32m    197\u001b[39m vif = \u001b[32m1.\u001b[39m / (\u001b[32m1.\u001b[39m - r_squared_i)\n",
      "\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vif\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:333\u001b[39m, in \u001b[36mRegressionModel.fit\u001b[39m\u001b[34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[39m\n",
      "\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpinv\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n",
      "\u001b[32m    330\u001b[39m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnormalized_cov_params\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n",
      "\u001b[32m    331\u001b[39m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m)):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m         \u001b[38;5;28mself\u001b[39m.pinv_wexog, singular_values = \u001b[43mpinv_extended\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwexog\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    334\u001b[39m         \u001b[38;5;28mself\u001b[39m.normalized_cov_params = np.dot(\n",
      "\u001b[32m    335\u001b[39m             \u001b[38;5;28mself\u001b[39m.pinv_wexog, np.transpose(\u001b[38;5;28mself\u001b[39m.pinv_wexog))\n",
      "\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# Cache these singular values for use later.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/tools/tools.py:264\u001b[39m, in \u001b[36mpinv_extended\u001b[39m\u001b[34m(x, rcond)\u001b[39m\n",
      "\u001b[32m    262\u001b[39m x = np.asarray(x)\n",
      "\u001b[32m    263\u001b[39m x = x.conjugate()\n",
      "\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m u, s, vt = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    265\u001b[39m s_orig = np.copy(s)\n",
      "\u001b[32m    266\u001b[39m m = u.shape[\u001b[32m0\u001b[39m]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/numpy/linalg/linalg.py:1681\u001b[39m, in \u001b[36msvd\u001b[39m\u001b[34m(a, full_matrices, compute_uv, hermitian)\u001b[39m\n",
      "\u001b[32m   1678\u001b[39m         gufunc = _umath_linalg.svd_n_s\n",
      "\u001b[32m   1680\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->DdD\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->ddd\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m u, s, vh = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1682\u001b[39m u = u.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m   1683\u001b[39m s = s.astype(_realType(result_t), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "vif_df_dict = {}\n",
    "for i, column_subset in enumerate(all_column_subsets):\n",
    "    vif_df_dict[subset_key_words[i]] = drop_high_vif_vars.get_vif_df(df[column_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop',\n",
       " 'speed_OR_ddv_OR_dw_OR_delta_OR_traj',\n",
       " 'LD_or_RD_or_gaze_or_view',\n",
       " 'distance',\n",
       " 'angle',\n",
       " 'frozen',\n",
       " 'dummy',\n",
       " 'num_or_any_or_rate']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subset_key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'LD_or_RD_or_gaze_or_view'\n",
    "exclude: gave_mky_view_x and y\n",
    "'LD_or_RD_or_gave_mky_view_angle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get rid of \n",
    "frozen\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_visible_ff_5</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_visible_ff_-5</td>\n",
       "      <td>5.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_alive_ff_5</td>\n",
       "      <td>5.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any_ff_visible_5</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>any_ff_visible_-5</td>\n",
       "      <td>2.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature     vif\n",
       "3   num_visible_ff_5 6.00000\n",
       "0  num_visible_ff_-5 5.70000\n",
       "2     num_alive_ff_5 5.60000\n",
       "4   any_ff_visible_5 3.00000\n",
       "1  any_ff_visible_-5 2.50000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vif = vif_df_dict['num_or_any_or_rate']\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp on reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(decode_target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================Dropping lags of features with high correlation for each feature====================\n",
      "Processing feature 1/59\n",
      "10 columns of *monkey_x* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *target_rel_x* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *cum_distance_since_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "10 columns of *min_abs_ff_angle_boundary* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "Processing feature 11/59\n",
      "10 columns of *point_index* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *min_abs_visible_ff_angle* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *min_abs_ff_angle* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *min_ff_distance* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *d_heading_since_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_last_seen_distance* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "Processing feature 21/59\n",
      "9 columns of *target_last_seen_angle* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "8 columns of *target_opt_arc_dheading* dropped: [-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_rel_y* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_last_seen_angle_to_boundary* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *any_ff_visible* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "10 columns of *monkey_angle* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "Processing feature 31/59\n",
      "9 columns of *target_distance* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "8 columns of *target_angle* dropped: [-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "8 columns of *target_angle_to_boundary* dropped: [-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *time_since_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *distance_from_monkey_pos_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *traj_curv* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *time_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *monkey_y_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "Processing feature 41/59\n",
      "9 columns of *target_y* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *valid_view_point_l* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "10 columns of *monkey_y* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *min_visible_ff_distance* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "10 columns of *num_alive_ff* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *target_index* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *num_visible_ff* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *valid_view_point_r* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "Processing feature 51/59\n",
      "10 columns of *time_since_last_capture* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *monkey_speeddummy* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *monkey_x_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_x* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *min_abs_visible_ff_angle_boundary* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "\n",
      "Dropped 337 out of 632 columns (53.32%) after removing lags of features with high correlation.\n",
      "Dropped columns: ['monkey_angle_-4', 'target_rel_y_3', 'target_last_seen_angle_to_boundary_1', 'monkey_speeddummy_2', 'time_since_target_last_seen_-4', 'target_x_3', 'target_index_-5', 'time_since_last_capture_4', 'monkey_speeddummy_-1', 'monkey_x_target_last_seen_-5', 'valid_view_point_r_2', 'traj_curv_-2', 'target_last_seen_angle_-3', 'distance_from_monkey_pos_target_last_seen_-4', 'target_distance_-5', 'target_rel_x_-2', 'valid_view_point_r_4', 'min_abs_ff_angle_2', 'time_since_target_last_seen_-1', 'target_index_-4', 'target_rel_x_-3', 'distance_from_monkey_pos_target_last_seen_-3', 'target_opt_arc_dheading_-3', 'min_abs_ff_angle_boundary_-3', 'target_distance_2', 'min_ff_distance_2', 'valid_view_point_l_1', 'distance_from_monkey_pos_target_last_seen_-1', 'min_visible_ff_distance_1', 'monkey_y_target_last_seen_2', 'monkey_y_target_last_seen_-3', 'any_ff_visible_3', 'target_last_seen_distance_2', 'point_index_-3', 'monkey_speeddummy_0', 'cum_distance_since_target_last_seen_-5', 'target_y_-4', 'min_abs_visible_ff_angle_-4', 'point_index_2', 'min_ff_distance_-4', 'target_last_seen_angle_2', 'cum_distance_since_target_last_seen_1', 'traj_curv_2', 'point_index_-4', 'target_last_seen_angle_3', 'target_opt_arc_dheading_1', 'target_last_seen_angle_1', 'target_rel_x_4', 'time_since_target_last_seen_2', 'target_angle_to_boundary_4', 'min_abs_visible_ff_angle_boundary_4', 'monkey_x_target_last_seen_-1', 'target_last_seen_distance_-3', 'target_angle_3', 'num_visible_ff_-3', 'target_rel_x_1', 'd_heading_since_target_last_seen_-3', 'target_last_seen_angle_4', 'min_abs_visible_ff_angle_1', 'monkey_y_-1', 'time_since_last_capture_-5', 'min_abs_ff_angle_boundary_0', 'min_abs_visible_ff_angle_-1', 'min_abs_visible_ff_angle_boundary_-4', 'monkey_y_target_last_seen_4', 'target_opt_arc_dheading_-2', 'target_angle_1', 'valid_view_point_l_-3', 'min_visible_ff_distance_2', 'min_visible_ff_distance_-4', 'min_visible_ff_distance_0', 'valid_view_point_r_-2', 'min_ff_distance_-1', 'monkey_speeddummy_4', 'valid_view_point_r_-4', 'num_alive_ff_1', 'time_since_target_last_seen_-3', 'monkey_x_1', 'monkey_angle_-1', 'target_distance_-3', 'target_distance_-1', 'valid_view_point_r_-3', 'min_abs_ff_angle_boundary_1', 'min_visible_ff_distance_3', 'min_ff_distance_-2', 'min_visible_ff_distance_-2', 'target_angle_-1', 'valid_view_point_l_-4', 'point_index_-5', 'min_visible_ff_distance_-3', 'monkey_angle_-3', 'point_index_4', 'min_visible_ff_distance_-1', 'any_ff_visible_2', 'point_index_0', 'distance_from_monkey_pos_target_last_seen_-2', 'target_last_seen_angle_-2', 'min_abs_visible_ff_angle_-2', 'monkey_x_target_last_seen_-4', 'monkey_speeddummy_-2', 'target_angle_4', 'time_target_last_seen_-1', 'target_rel_y_-4', 'target_angle_to_boundary_3', 'monkey_x_4', 'monkey_y_1', 'valid_view_point_l_-1', 'monkey_x_0', 'target_rel_x_-5', 'any_ff_visible_-2', 'target_last_seen_distance_-4', 'num_alive_ff_-1', 'target_y_4', 'num_visible_ff_1', 'monkey_angle_2', 'time_since_target_last_seen_-5', 'any_ff_visible_-3', 'valid_view_point_r_1', 'monkey_y_-5', 'num_visible_ff_0', 'monkey_speeddummy_-4', 'cum_distance_since_target_last_seen_-2', 'target_x_2', 'monkey_y_2', 'target_x_1', 'min_abs_ff_angle_4', 'min_abs_ff_angle_-3', 'monkey_angle_0', 'valid_view_point_l_4', 'target_rel_y_-2', 'target_last_seen_angle_to_boundary_-5', 'min_abs_visible_ff_angle_boundary_-3', 'min_abs_visible_ff_angle_boundary_0', 'monkey_x_-5', 'target_angle_2', 'target_opt_arc_dheading_2', 'target_index_-2', 'num_visible_ff_4', 'target_index_3', 'min_abs_visible_ff_angle_3', 'd_heading_since_target_last_seen_1', 'min_abs_ff_angle_boundary_-1', 'cum_distance_since_target_last_seen_-3', 'time_since_last_capture_-2', 'target_angle_to_boundary_-4', 'target_distance_-2', 'min_ff_distance_3', 'num_visible_ff_2', 'num_alive_ff_0', 'min_abs_visible_ff_angle_boundary_1', 'target_index_1', 'traj_curv_-3', 'monkey_x_target_last_seen_2', 'target_last_seen_angle_-4', 'time_since_target_last_seen_-2', 'target_angle_-2', 'monkey_x_3', 'time_since_last_capture_-1', 'num_alive_ff_-3', 'min_abs_ff_angle_1', 'target_rel_y_-3', 'target_rel_x_2', 'any_ff_visible_0', 'target_opt_arc_dheading_3', 'any_ff_visible_1', 'monkey_angle_1', 'target_index_-3', 'target_rel_x_-4', 'time_target_last_seen_-3', 'time_since_last_capture_0', 'monkey_x_target_last_seen_4', 'monkey_x_target_last_seen_3', 'cum_distance_since_target_last_seen_2', 'target_angle_-4', 'time_target_last_seen_1', 'target_index_-1', 'min_abs_visible_ff_angle_-3', 'target_last_seen_distance_-2', 'target_angle_to_boundary_1', 'min_abs_visible_ff_angle_4', 'target_y_-5', 'distance_from_monkey_pos_target_last_seen_-5', 'time_since_last_capture_2', 'min_visible_ff_distance_4', 'num_alive_ff_-5', 'target_last_seen_distance_-5', 'valid_view_point_l_2', 'target_y_3', 'min_abs_visible_ff_angle_2', 'monkey_x_-1', 'point_index_3', 'time_since_last_capture_-3', 'target_rel_y_-1', 'distance_from_monkey_pos_target_last_seen_4', 'time_since_target_last_seen_1', 'min_abs_visible_ff_angle_boundary_3', 'target_distance_3', 'target_last_seen_distance_1', 'min_abs_ff_angle_boundary_2', 'monkey_x_target_last_seen_-3', 'traj_curv_-4', 'min_abs_ff_angle_boundary_3', 'target_last_seen_angle_to_boundary_-1', 'traj_curv_0', 'any_ff_visible_-4', 'traj_curv_3', 'any_ff_visible_-1', 'target_angle_to_boundary_-1', 'num_alive_ff_4', 'valid_view_point_r_3', 'point_index_1', 'target_angle_to_boundary_-2', 'target_last_seen_angle_to_boundary_-4', 'cum_distance_since_target_last_seen_3', 'monkey_y_target_last_seen_-1', 'target_last_seen_angle_to_boundary_3', 'time_target_last_seen_-2', 'target_angle_to_boundary_-3', 'min_abs_ff_angle_boundary_-5', 'monkey_x_2', 'monkey_angle_4', 'target_last_seen_angle_to_boundary_4', 'monkey_x_-4', 'min_abs_ff_angle_-1', 'min_ff_distance_4', 'monkey_y_target_last_seen_-2', 'time_since_target_last_seen_4', 'target_x_4', 'time_target_last_seen_-4', 'target_last_seen_angle_-5', 'monkey_y_4', 'monkey_y_3', 'target_opt_arc_dheading_-4', 'monkey_x_-3', 'monkey_angle_-5', 'monkey_y_-3', 'target_rel_y_1', 'target_distance_-4', 'monkey_y_target_last_seen_-4', 'min_abs_ff_angle_boundary_-4', 'monkey_y_target_last_seen_3', 'target_last_seen_angle_to_boundary_-2', 'min_abs_ff_angle_-2', 'target_last_seen_distance_3', 'num_visible_ff_3', 'target_rel_x_3', 'target_rel_x_-1', 'target_x_-4', 'target_rel_y_-5', 'd_heading_since_target_last_seen_4', 'time_target_last_seen_-5', 'target_distance_1', 'target_last_seen_distance_-1', 'monkey_angle_-2', 'num_visible_ff_-2', 'num_visible_ff_-1', 'target_x_-5', 'min_abs_ff_angle_3', 'target_x_-1', 'd_heading_since_target_last_seen_3', 'd_heading_since_target_last_seen_-4', 'cum_distance_since_target_last_seen_4', 'valid_view_point_r_-1', 'min_abs_ff_angle_0', 'target_angle_-3', 'target_last_seen_angle_to_boundary_-3', 'traj_curv_1', 'target_y_-1', 'monkey_x_target_last_seen_-2', 'target_last_seen_angle_-1', 'valid_view_point_l_3', 'monkey_speeddummy_1', 'd_heading_since_target_last_seen_-2', 'distance_from_monkey_pos_target_last_seen_2', 'target_index_2', 'target_y_-3', 'target_last_seen_angle_to_boundary_2', 'target_x_-3', 'monkey_y_target_last_seen_1', 'monkey_y_-4', 'target_x_-2', 'distance_from_monkey_pos_target_last_seen_3', 'traj_curv_-1', 'min_abs_ff_angle_boundary_-2', 'monkey_speeddummy_-3', 'target_rel_y_4', 'num_alive_ff_-4', 'min_abs_ff_angle_-4', 'target_angle_to_boundary_2', 'monkey_x_target_last_seen_1', 'num_visible_ff_-4', 'time_target_last_seen_2', 'monkey_y_target_last_seen_-5', 'valid_view_point_l_0', 'monkey_speeddummy_3', 'monkey_x_-2', 'min_abs_visible_ff_angle_boundary_-2', 'valid_view_point_r_0', 'point_index_-2', 'min_ff_distance_0', 'traj_curv_4', 'target_y_-2', 'time_since_target_last_seen_3', 'min_abs_ff_angle_boundary_4', 'monkey_y_0', 'num_alive_ff_-2', 'cum_distance_since_target_last_seen_-4', 'num_alive_ff_3', 'target_last_seen_distance_4', 'monkey_angle_3', 'distance_from_monkey_pos_target_last_seen_1', 'd_heading_since_target_last_seen_-5', 'time_target_last_seen_4', 'target_index_4', 'num_alive_ff_2', 'target_rel_y_2', 'min_abs_visible_ff_angle_boundary_2', 'monkey_y_-2', 'target_opt_arc_dheading_4', 'min_abs_visible_ff_angle_0', 'valid_view_point_l_-2', 'target_y_1', 'time_since_last_capture_-4', 'time_target_last_seen_3', 'time_since_last_capture_3', 'point_index_-1', 'target_distance_4', 'any_ff_visible_4', 'min_ff_distance_1', 'd_heading_since_target_last_seen_-1', 'time_since_last_capture_1', 'min_ff_distance_-3', 'cum_distance_since_target_last_seen_-1', 'd_heading_since_target_last_seen_2', 'min_abs_visible_ff_angle_boundary_-1', 'target_opt_arc_dheading_-1', 'target_y_2']\n",
      "====================Dropping lags of features with high correlation in specific subsets of features====================\n",
      "Processing subset 1 of 7 with features that contain \"_x\", 48 features in total.\n",
      "2 columns out of 48 dropped: ['monkey_x_5', 'monkey_x_target_last_seen_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 2 of 7 with features that contain \"_y\", 48 features in total.\n",
      "2 columns out of 48 dropped: ['monkey_y_5', 'monkey_y_target_last_seen_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 3 of 7 with features that contain \"angle\", 36 features in total.\n",
      "3 columns out of 36 dropped: ['min_abs_visible_ff_angle_-5', 'min_abs_ff_angle_5', 'min_abs_visible_ff_angle_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 4 of 7 with features that contain \"distance\", 19 features in total.\n",
      "1 columns out of 19 dropped: ['distance_from_monkey_pos_target_last_seen_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 5 of 7 with features that contain \"ff_or_target\", 50 features in total.\n",
      "10 columns out of 50 dropped: ['target_distance_5', 'target_index', 'min_abs_visible_ff_angle_5', 'distance_from_monkey_pos_target_last_seen_5', 'monkey_y_target_last_seen_5', 'time_since_target_last_seen_5', 'min_abs_ff_angle_5', 'time_target_last_seen_5', 'min_abs_visible_ff_angle_-5', 'monkey_x_target_last_seen_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 6 of 7 with features that contain \"speeddummy_OR_monkey_dw_OR_delta_OR_traj\", 26 features in total.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 7 of 7 with features that contain \"LD_or_RD_or_gave_mky_view_angle\", 44 features in total.\n",
      "\n",
      "18 out of 295 (6.10%) are dropped after dropping lags of features with high correlation in subsets of features\n",
      "====================Dropping lags of features with high correlation in all columns====================\n",
      "Processing subset 1 of 1, 283 features in total.\n",
      "42 columns out of 283 dropped: ['LDy_1', 'point_index_5', 'LDy_-1', 'RDy_-5', 'gaze_mky_view_y_r_0', 'LDy_-2', 'LDy_5', 'LDy_-5', 'LDy_-4', 'RDy_-1', 'bin', 'RDy_-3', 'monkey_speed_5', 'gaze_mky_view_y_r_2', 'LDy_3', 'monkey_speed_3', 'RDy_3', 'gaze_mky_view_y_r_3', 'monkey_speed_-2', 'RDy_5', 'monkey_speed_-5', 'monkey_speed_1', 'monkey_speed_-3', 'monkey_speed_2', 'gaze_mky_view_y_r_5', 'RDy_2', 'RDy_0', 'gaze_mky_view_y_r_4', 'monkey_speed_0', 'gaze_mky_view_y_r_1', 'monkey_speed_-4', 'LDy_4', 'RDy_1', 'gaze_mky_view_y_r_-1', 'RDy_4', 'LDy_-3', 'RDy_-4', 'LDy_2', 'LDy_0', 'monkey_speed_4', 'RDy_-2', 'monkey_speed_-1']\n",
      "\n",
      "42 out of 283 (14.84%) are dropped after dropping lags of features with high correlation in subsets of features\n",
      "\n",
      "** Summary: 391 out of 632 (61.87%) are dropped after calling drop_columns_with_high_corr. 241 features are left. **\n",
      "\n",
      "====================Dropping lags with high VIF in subsets of features in an iterative manner====================\n",
      "Processing subset 1 of 8 with features that contain \"stop\", 11 features in total.\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is whether_new_distinct_stop_0 with VIF 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 2 of 8 with features that contain \"speed_OR_ddv_OR_dw_OR_delta_OR_traj\", 59 features in total.\n",
      "0 out of 59 features are processed for VIF.\n",
      "10 out of 59 features are processed for VIF.\n",
      "20 out of 59 features are processed for VIF.\n",
      "30 out of 59 features are processed for VIF.\n",
      "40 out of 59 features are processed for VIF.\n",
      "50 out of 59 features are processed for VIF.\n",
      "Iter 1: Dropped monkey_speeddummy_5 (VIF: 13.5)\n",
      "0 out of 58 features are processed for VIF.\n",
      "10 out of 58 features are processed for VIF.\n",
      "20 out of 58 features are processed for VIF.\n",
      "30 out of 58 features are processed for VIF.\n",
      "40 out of 58 features are processed for VIF.\n",
      "50 out of 58 features are processed for VIF.\n",
      "Iter 2: Dropped delta_distance_0 (VIF: 11.7)\n",
      "0 out of 57 features are processed for VIF.\n",
      "10 out of 57 features are processed for VIF.\n",
      "20 out of 57 features are processed for VIF.\n",
      "30 out of 57 features are processed for VIF.\n",
      "40 out of 57 features are processed for VIF.\n",
      "50 out of 57 features are processed for VIF.\n",
      "Iter 3: Dropped delta_distance_2 (VIF: 10.1)\n",
      "0 out of 56 features are processed for VIF.\n",
      "10 out of 56 features are processed for VIF.\n",
      "20 out of 56 features are processed for VIF.\n",
      "30 out of 56 features are processed for VIF.\n",
      "40 out of 56 features are processed for VIF.\n",
      "50 out of 56 features are processed for VIF.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_y_var_lags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_vif_by_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mfilter_vif_by_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/decode_targets/decode_target_class.py:222\u001b[39m, in \u001b[36mreduce_y_var_lags\u001b[39m\u001b[34m(self, corr_threshold_for_lags_of_a_feature, vif_threshold_for_initial_subset, vif_threshold, verbose, filter_corr_by_feature, filter_corr_by_subsets, filter_corr_by_all_columns, filter_vif_by_feature, filter_vif_by_subsets, filter_vif_by_all_columns)\u001b[39m\n\u001b[32m    207\u001b[39m         self.y_var_lags = self.y_var_lags.merge(\n\u001b[32m    208\u001b[39m             self.y_var[['bin', 'target_index']], on='bin', how='left')\n\u001b[32m    209\u001b[39m     self.y_var_lags = decode_target_utils.add_lagged_target_columns(\n\u001b[32m    210\u001b[39m         self.y_var_lags, target_df_lags, self.max_y_lag_number, target_columns=self.target_columns)\n\u001b[32m    212\u001b[39m def reduce_y_var_lags(self, corr_threshold_for_lags_of_a_feature=0.85,\n\u001b[32m    213\u001b[39m                       vif_threshold_for_initial_subset=5,\n\u001b[32m    214\u001b[39m                       vif_threshold=5,\n\u001b[32m    215\u001b[39m                       verbose=True,\n\u001b[32m    216\u001b[39m                       filter_corr_by_feature=True,\n\u001b[32m    217\u001b[39m                       filter_corr_by_subsets=True,\n\u001b[32m    218\u001b[39m                       filter_corr_by_all_columns=True,\n\u001b[32m    219\u001b[39m                       filter_vif_by_feature=True,\n\u001b[32m    220\u001b[39m                       filter_vif_by_subsets=False,\n\u001b[32m    221\u001b[39m                       filter_vif_by_all_columns=False\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m                       ):\n\u001b[32m    224\u001b[39m     super().reduce_y_var_lags(corr_threshold_for_lags_of_a_feature=corr_threshold_for_lags_of_a_feature,\n\u001b[32m    225\u001b[39m                               vif_threshold_for_initial_subset=vif_threshold_for_initial_subset,\n\u001b[32m    226\u001b[39m                               vif_threshold=vif_threshold,\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m                               filter_vif_by_subsets=filter_vif_by_subsets,\n\u001b[32m    233\u001b[39m                               filter_vif_by_all_columns=filter_vif_by_all_columns)\n\u001b[32m    235\u001b[39m def _get_x_var(self):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/neural_vs_behavioral/neural_vs_behavioral_class.py:130\u001b[39m, in \u001b[36mNeuralVsBehavioralClass.reduce_y_var_lags\u001b[39m\u001b[34m(self, corr_threshold_for_lags_of_a_feature, vif_threshold_for_initial_subset, vif_threshold, verbose, filter_corr_by_feature, filter_corr_by_subsets, filter_corr_by_all_columns, filter_vif_by_feature, filter_vif_by_subsets, filter_vif_by_all_columns)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce_y_var_lags\u001b[39m(\u001b[38;5;28mself\u001b[39m, corr_threshold_for_lags_of_a_feature=\u001b[32m0.85\u001b[39m,\n\u001b[32m    112\u001b[39m                       vif_threshold_for_initial_subset=\u001b[32m5\u001b[39m, vif_threshold=\u001b[32m5\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    113\u001b[39m                       filter_corr_by_feature=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# Call the function to iteratively drop lags with high correlation for each feature\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28mself\u001b[39m.y_var_lags_reduced_corr = drop_high_corr_vars.drop_columns_with_high_corr(\u001b[38;5;28mself\u001b[39m.y_var_lags,\n\u001b[32m    123\u001b[39m                                                                                    corr_threshold_for_lags=corr_threshold_for_lags_of_a_feature,\n\u001b[32m    124\u001b[39m                                                                                    verbose=verbose,\n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m                                                                                    filter_by_all_columns=filter_corr_by_all_columns,\n\u001b[32m    128\u001b[39m                                                                                    get_column_subsets_func=\u001b[38;5;28mself\u001b[39m.get_subset_key_words_and_all_column_subsets_for_corr)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28mself\u001b[39m.y_var_lags_reduced = \u001b[43mdrop_high_vif_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop_columns_with_high_vif\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_var_lags_reduced_corr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mvif_threshold_for_initial_subset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold_for_initial_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mfilter_by_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mfilter_by_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_subsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mfilter_by_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mget_column_subsets_func\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_subset_key_words_and_all_column_subsets_for_vip\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:53\u001b[39m, in \u001b[36mdrop_columns_with_high_vif\u001b[39m\u001b[34m(y_var_lags, vif_threshold, vif_threshold_for_initial_subset, verbose, filter_by_feature, filter_by_subsets, filter_by_all_columns, get_column_subsets_func)\u001b[39m\n\u001b[32m     51\u001b[39m         subset_key_words = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     52\u001b[39m         all_column_subsets = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     y_var_lags_reduced, columns_dropped = \u001b[43mfilter_specific_subset_of_y_var_lags_by_vif\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_var_lags_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_column_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_column_subsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filter_by_all_columns:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m====================Dropping columns with the highest VIF in an iterative manner====================\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:203\u001b[39m, in \u001b[36mfilter_specific_subset_of_y_var_lags_by_vif\u001b[39m\u001b[34m(y_var_lags, vif_threshold, verbose, subset_key_words, all_column_subsets)\u001b[39m\n\u001b[32m    185\u001b[39m     subset_key_words = [\u001b[33m'\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mspeed_or_ddv\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLD_or_RD_or_gaze\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    186\u001b[39m                         \u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mangle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfrozen\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdummy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnum_or_any_or_rate\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    188\u001b[39m     all_column_subsets = [\n\u001b[32m    189\u001b[39m         [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m y_var_lags.columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col],\n\u001b[32m    190\u001b[39m         [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m y_var_lags.columns \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33many\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mrate\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col)],\n\u001b[32m    201\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m df_reduced, columns_dropped = \u001b[43mdrop_high_corr_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter_subsets_of_var_df_lags_by_corr_or_vif\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_var_lags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_vif_instead_of_corr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mall_column_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_column_subsets\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df_reduced, columns_dropped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_corr_vars.py:214\u001b[39m, in \u001b[36mfilter_subsets_of_var_df_lags_by_corr_or_vif\u001b[39m\u001b[34m(var_df_lags, use_vif_instead_of_corr, corr_threshold, vif_threshold, verbose, subset_key_words, all_column_subsets)\u001b[39m\n\u001b[32m    212\u001b[39m     temp_columns_to_drop = high_corr_pair_df[\u001b[33m'\u001b[39m\u001b[33mvar_1\u001b[39m\u001b[33m'\u001b[39m].values.tolist()\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     _, temp_columns_to_drop, _ = \u001b[43mdrop_high_vif_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43miteratively_drop_column_w_highest_vif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_df_lags\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_subset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m                                                                                          \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp_columns_to_drop) > \u001b[32m0\u001b[39m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# get unique columns dropped\u001b[39;00m\n\u001b[32m    219\u001b[39m     temp_columns_to_drop = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(temp_columns_to_drop))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:133\u001b[39m, in \u001b[36miteratively_drop_column_w_highest_vif\u001b[39m\u001b[34m(df, vif_threshold, verbose)\u001b[39m\n\u001b[32m    131\u001b[39m     df.drop(columns=column_to_drop, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    132\u001b[39m     columns_dropped.append(column_to_drop)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     vif_df = \u001b[43mget_vif_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m final_vif_df = vif_df\n\u001b[32m    135\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    136\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAfter iterative dropping, the column with the highest VIF of the dataframe or subset is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvif_df[\u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m].values[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with VIF \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvif_df[\u001b[33m\"\u001b[39m\u001b[33mvif\u001b[39m\u001b[33m\"\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:83\u001b[39m, in \u001b[36mget_vif_df\u001b[39m\u001b[34m(var_df, verbose)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(var_df.shape[\u001b[32m1\u001b[39m]):\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# check for RuntimeWarning; print the column name that causes the warning\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         vif_values.append(\u001b[43mvariance_inflation_factor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvar_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     86\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRuntimeWarning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:196\u001b[39m, in \u001b[36mvariance_inflation_factor\u001b[39m\u001b[34m(exog, exog_idx)\u001b[39m\n\u001b[32m    194\u001b[39m mask = np.arange(k_vars) != exog_idx\n\u001b[32m    195\u001b[39m x_noti = exog[:, mask]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m r_squared_i = \u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_noti\u001b[49m\u001b[43m)\u001b[49m.fit().rsquared\n\u001b[32m    197\u001b[39m vif = \u001b[32m1.\u001b[39m / (\u001b[32m1.\u001b[39m - r_squared_i)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vif\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:921\u001b[39m, in \u001b[36mOLS.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    919\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mAn exception will be raised in the next version.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    920\u001b[39m     warnings.warn(msg, ValueWarning)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_keys:\n\u001b[32m    924\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_keys.remove(\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:746\u001b[39m, in \u001b[36mWLS.__init__\u001b[39m\u001b[34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     weights = weights.squeeze()\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m nobs = \u001b[38;5;28mself\u001b[39m.exog.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    749\u001b[39m weights = \u001b[38;5;28mself\u001b[39m.weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:200\u001b[39m, in \u001b[36mRegressionModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mself\u001b[39m.pinv_wexog: Float64Array | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_attr.extend([\u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwendog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/model.py:270\u001b[39m, in \u001b[36mLikelihoodModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/model.py:95\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m missing = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     94\u001b[39m hasconst = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mhasconst\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                              \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[38;5;28mself\u001b[39m.data.k_constant\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m.exog = \u001b[38;5;28mself\u001b[39m.data.exog\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/model.py:135\u001b[39m, in \u001b[36mModel._handle_data\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     data = \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/data.py:675\u001b[39m, in \u001b[36mhandle_data\u001b[39m\u001b[34m(endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    672\u001b[39m     exog = np.asarray(exog)\n\u001b[32m    674\u001b[39m klass = handle_data_class_factory(endog, exog)\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m             \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/data.py:88\u001b[39m, in \u001b[36mModelData.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.const_idx = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m._check_integrity()\n\u001b[32m     90\u001b[39m \u001b[38;5;28mself\u001b[39m._cache = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/data.py:177\u001b[39m, in \u001b[36mModelData._handle_constant\u001b[39m\u001b[34m(self, hasconst)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_implicit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hasconst:\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# look for implicit constant\u001b[39;00m\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# Compute rank of augmented matrix\u001b[39;00m\n\u001b[32m    175\u001b[39m     augmented_exog = np.column_stack(\n\u001b[32m    176\u001b[39m                 (np.ones(\u001b[38;5;28mself\u001b[39m.exog.shape[\u001b[32m0\u001b[39m]), \u001b[38;5;28mself\u001b[39m.exog))\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     rank_augm = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_exog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     rank_orig = np.linalg.matrix_rank(\u001b[38;5;28mself\u001b[39m.exog)\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[38;5;28mint\u001b[39m(rank_orig == rank_augm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/numpy/linalg/linalg.py:1922\u001b[39m, in \u001b[36mmatrix_rank\u001b[39m\u001b[34m(A, tol, hermitian)\u001b[39m\n\u001b[32m   1920\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.ndim < \u001b[32m2\u001b[39m:\n\u001b[32m   1921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(A==\u001b[32m0\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1922\u001b[39m S = \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhermitian\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhermitian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1924\u001b[39m     tol = S.max(axis=-\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m) * \u001b[38;5;28mmax\u001b[39m(A.shape[-\u001b[32m2\u001b[39m:]) * finfo(S.dtype).eps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/numpy/linalg/linalg.py:1693\u001b[39m, in \u001b[36msvd\u001b[39m\u001b[34m(a, full_matrices, compute_uv, hermitian)\u001b[39m\n\u001b[32m   1690\u001b[39m     gufunc = _umath_linalg.svd_n\n\u001b[32m   1692\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->d\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1693\u001b[39m s = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1694\u001b[39m s = s.astype(_realType(result_t), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dec.reduce_y_var_lags(filter_vif_by_feature=False,\n",
    "                      filter_vif_by_subsets=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec.reduce_y_var_lags(filter_vif_by_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_key_words, all_column_subsets = dec.get_subset_key_words_and_all_column_subsets_for_vif(\n",
    "#             dec.y_var_lags)\n",
    "\n",
    "subset_key_words, all_column_subsets = dec.get_subset_key_words_and_all_column_subsets_for_vif(\n",
    "            dec.y_var_lags_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_column_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(decode_target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df_dict = {}\n",
    "for i, column_subset in enumerate(all_column_subsets):\n",
    "    vif_df_dict[subset_key_words[i]] = drop_high_vif_vars.get_vif_df(df[column_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = vif_df_dict['ff_or_target']\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target columns lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec._make_or_retrieve_target_df(exists_ok=True, fill_na=False)\n",
    "# dec.get_basic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dec.y_var_lags\n",
    "na_rows, na_cols = general_utils.find_rows_with_na(df)\n",
    "duplicate_rows = general_utils.find_duplicate_rows(df, column_subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data for GPFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.single_vis_target_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.prepare_spikes_for_gpfa()\n",
    "\n",
    "print(len(dec.spiketrains))\n",
    "print(len(dec.spiketrains[0]))\n",
    "print(len(dec.spiketrains[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit gpfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dec.spiketrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.get_gpfa_traj(latent_dimensionality=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gpfa_utils.plot_gpfa_traj_3d_uniform_color()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, enable interactive mode in your notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# Create the interactive plot\n",
    "fig, ax = plot_gpfa_utils.plot_gpfa_traj_3d(\n",
    "    trajectories=dec.trajectories,\n",
    "    figsize=(15, 5),\n",
    "    linewidth_single_trial=0.75,\n",
    "    alpha_single_trial=0.3,\n",
    "    linewidth_trial_average=2,\n",
    "    title='Latent dynamics extracted by GPFA',\n",
    "    view_azim=-5,\n",
    "    view_elev=60\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_gpfa_utils.plot_gpfa_traj_3d_plotly(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find variance explained by each latent dimension\n",
    "traj_stack = np.stack(dec.trajectories, axis=0)  # shape: (n_trials, 3, T)\n",
    "var_by_dim = var(traj_stack, axis=(0, 2))    # variance across trials and time\n",
    "var_by_dim /= var_by_dim.sum()               # normalize to get explained variance ratio\n",
    "print(\"Variance explained by each latent dimension:\", var_by_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.set_title('Latent dynamics extracted by GPFA')\n",
    "ax.set_xlabel('Time [s]')\n",
    "\n",
    "average_trajectory = np.mean(, axis=0)\n",
    "time = np.arange(len(average_trajectory[0])) * 0.02  # assuming all trajectories have the same length\n",
    "\n",
    "for i, x in enumerate(average_trajectory):\n",
    "    ax.plot(time, x, label=f'Dim {i+1}')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.common_t_stop = max(dec.spike_segs_df['t_duration']) * pq.s + dec.bin_width_w_unit        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.get_gpfa_and_behav_data_for_all_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_timepoints = int(1.5/0.02)\n",
    "scores_by_time, times = gpfa_regression_utils.time_resolved_regression_variable_length(dec.gpfa_trials, dec.behavior_trials, time_step=0.02, cv_folds=5, max_timepoints=max_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_labels = dec.pursuit_data_by_trial.drop(columns=['segment']).columns\n",
    "len(behavior_labels)\n",
    "scores_by_time_df = pd.DataFrame(scores_by_time, columns=behavior_labels)\n",
    "# see the percentage of 1 of this dummy variable\n",
    "dec.pursuit_data_by_trial[['whether_new_distinct_stop']].sum()/len(dec.pursuit_data_by_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpfa_regression_utils.plot_time_resolved_scores(scores_by_time, times, behavior_labels=behavior_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_counts = np.array([sum(latent.shape[0] > t for latent in gpfa_trials)\n",
    "                         for t in range(scores_by_time.shape[0])])\n",
    "plt.plot(times, trial_counts)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Trials with data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce columns in lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(decode_target_class)\n",
    "reload(decode_target_utils)\n",
    "reload(drop_high_corr_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec.reduce_x_var_lags()  # currently not needed bc of the low correlations between neural clusters\n",
    "dec.reduce_y_var_lags(filter_vif_by_subsets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = drop_high_vif_vars.get_vif_df(dec.y_var_lags_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# behav features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find set difference between dec.behav_data_all.columns and dec.behav_data.columns\n",
    "diff_columns = set(dec.behav_data_all.columns) - set(dec.behav_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check result of reducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also check correlations between x vars without lags\n",
    "high_corr_pair_df, top_n_corr_df = drop_high_corr_vars.get_pairs_of_columns_w_high_corr(\n",
    "            dec.x_var, corr_threshold=0.8)\n",
    "top_n_corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression (didn't modify yet)\n",
    "\n",
    "Regressing the behavioral variables individually (as y_var) against all neural activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## put results in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec.make_or_retrieve_y_var_lr_resault_df(exists_ok=True)\n",
    "dec.y_var_lr_result_df = neural_data_modeling.get_y_var_lr_result_df(\n",
    "                dec.x_var_lags_reduced, dec.y_var)\n",
    "dec.y_var_lr_result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  plot all neural clusters vs one behavioral var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop existing columns involving bin (most likely there's only one or zero after being reduced, because different lags of bins can have very high correlations)\n",
    "bin_cols = [col for col in dec.y_var_lags_reduced.columns if 'bin' in col]\n",
    "dec.y_var_lags_reduced.drop(columns=bin_cols, inplace=True)\n",
    "\n",
    "# then we add the variable bin (so that only the 0 lag is used)\n",
    "dec.y_var_lags_reduced['bin'] = dec.y_var_lags['bin_0'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# conduct linear regression on X and y\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "bins_to_plot = dec.y_var_lags_reduced['bin'].values\n",
    "for i, column in enumerate(dec.y_var_lags_reduced.columns):\n",
    "\n",
    "    plot_neural_data.plot_regression(dec.y_var_lags_reduced, column, dec.x_var_lags_reduced, bins_to_plot=bins_to_plot, min_r_squared_to_plot=0.3)\n",
    "    # if i == 3:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  plot one neural cluster vs one behavioral var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one neural cluster against one behavioral variable\n",
    "cluster_num, behavioral_column = 6, 'monkey_speed'\n",
    "bins_to_plot = range(1000, 1200)\n",
    "x_values = dec.binned_spikes_df.loc[bins_to_plot, f'unit_{cluster_num}'].values\n",
    "y_values = dec.pursuit_data[behavioral_column][bins_to_plot]\n",
    "reg = LinearRegression().fit(x_values.reshape(-1, 1), y_values)\n",
    "\n",
    "plt.scatter(x_values, y_values, color='blue', s=1)\n",
    "plt.plot(x_values, reg.predict(x_values.reshape(-1, 1)), color='red', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA\n",
    "\n",
    "https://medium.com/@pozdrawiamzuzanna/canonical-correlation-analysis-simple-explanation-and-python-example-a5b8e97648d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No lagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_no_lag = cca_class.CCAclass(X1=dec.x_var, X2=dec.y_var_reduced, lagging_included=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_no_lag.conduct_cca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_lags = cca_class.CCAclass(X1=dec.x_var_lags, X2=dec.y_var_lags_reduced, lagging_included=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var_lags_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_lags.conduct_cca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare lag vs no lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canon_df = pd.DataFrame(cca_no_lag.canon_corr, columns = ['no_lag'])\n",
    "canon_df[f'lag_{dec.max_lag_number}'] = cca_lags.canon_corr\n",
    "canon_df['component'] = [f'CC {i+1}' for i in range(cca_lags.n_components)]\n",
    "# convert canon_df to long format\n",
    "canon_df_long = pd.melt(canon_df, id_vars=['component'], var_name='lag', value_name='canon_coeff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sns bar plot on canon_df_long\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='component', y='canon_coeff', data=canon_df_long, hue='lag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cca_inst (choose one between lags and no lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose lags\n",
    "cca_inst = cca_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose no lag\n",
    "cca_inst = cca_no_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X1', squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X2', squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## squared loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## abs weights ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights(X1_or_X2='X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot real weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights(abs_value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights(X1_or_X2='X2', abs_value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribution of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.X2_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_sc_df = pd.DataFrame(cca_inst.X2_sc, columns = cca_inst.X2.columns)\n",
    "X2_sc_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X2_sc_df.columns:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    sns.boxplot(X2_sc_df[column], orient='h')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heatmap of weights\n",
    "raw canonical coefficients are interpreted in a manner analogous to interpreting regression coefficients. For example: a one unit increase in reading leads to a .0446 decrease in the first canonical variate of set 2 when all of the other variables are held constant (in some other data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = cca_inst.X2_weight_df.copy()\n",
    "weight_df = weight_df.set_index('feature').drop(columns='feature_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 25))\n",
    "sns.heatmap(weight_df.iloc[:20, :10], cmap='coolwarm', annot=True, linewidths=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, test1, train2, test2 = train_test_split(cca_inst.X1_sc, cca_inst.X2_sc, test_size=0.3, random_state=42)\n",
    "# use training and testing set\n",
    "nComponents = 10\n",
    "cca2 = rcca.CCA(kernelcca = False, reg = 0., numCC = nComponents)\n",
    "cca2.train([train1, train2])\n",
    "testcorrs = cca2.validate([test1, test2])\n",
    "testcorrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca2.compute_ev([test1, test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_cca = CanCorr(cca_inst.X1_sc, cca_inst.X2_sc)\n",
    "print(stats_cca.corr_test().summary())\n",
    "neural_data_modeling.print_weights('X', stats_cca.x_cancoef)\n",
    "neural_data_modeling.print_weights('Z', stats_cca.y_cancoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGAM (unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorize variables\n",
    "dec.y_var_reduced.columns\n",
    "temporal_vars = ['time_rel_to_stop',\n",
    " 'time_when_nxt_ff_first_seen_rel_to_stop',\n",
    " 'time_when_cur_ff_first_seen_rel_to_stop',\n",
    " 'time_when_nxt_ff_last_seen_rel_to_stop',\n",
    " 'time_when_cur_ff_last_seen_rel_to_stop',\n",
    " ]\n",
    "\n",
    "spatial_vars = [x for x in dec.y_var_reduced.columns if x not in temporal_vars]\n",
    "spatial_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sparsity of neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.binned_spikes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect neural data\n",
    "\n",
    "bins = dec.binned_spikes_df\n",
    "\n",
    "# Calculate percentage of non-zero rows for each column\n",
    "non_zero_percentages = (bins != 0).mean() * 100\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "non_zero_df = pd.DataFrame({\n",
    "    'Column': non_zero_percentages.index,\n",
    "    'Percent_Non_Zero': non_zero_percentages.values\n",
    "})\n",
    "\n",
    "# Sort by percentage in descending order\n",
    "non_zero_df = non_zero_df.sort_values('Percent_Non_Zero', ascending=False)\n",
    "\n",
    "print(\"Percentage of non-zero values in each column:\")\n",
    "print(non_zero_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins.drop(columns='bin').mean(axis=1).describe()\n",
    "\n",
    "# plot the percentile of values of mean firing rates across neurons at each time bin\n",
    "mean_rates = bins.drop(columns='bin').mean(axis=1)\n",
    "\n",
    "# Calculate percentiles from 0 to 100\n",
    "percentiles = np.arange(0, 101, 1)\n",
    "percentile_values = np.percentile(mean_rates, percentiles)\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(percentiles, percentile_values)\n",
    "plt.xlabel('Percentile')\n",
    "plt.ylabel('Mean Firing Rate')\n",
    "plt.title('Distribution of Mean Firing Rates Across Neurons')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y var (behavioral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_vif = drop_high_vif_vars.get_vif_df(dec.y_var)\n",
    "print(y_var_vif.head(8))\n",
    "\n",
    "# calculate the correlation coefficient among the columns with VIF > 5\n",
    "# specific_columns = vif_df[vif_df['vif'] > 5].feature.values\n",
    "specific_columns = y_var_vif.feature.values[:10]\n",
    "corr_coeff = dec.y_var[specific_columns].corr()\n",
    "#plt.figure(figsize = (6, 6))\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.heatmap(corr_coeff, cmap='coolwarm', annot=True, linewidths=1, vmin=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try y_var_reduced\n",
    "\n",
    "y_var_vif = drop_high_vif_vars.get_vif_df(dec.y_var_reduced)\n",
    "print(y_var_vif.head(8))\n",
    "\n",
    "# calculate the correlation coefficient among the columns with VIF > 5\n",
    "# specific_columns = vif_df[vif_df['vif'] > 5].feature.values\n",
    "specific_columns = y_var_vif.feature.values[:10]\n",
    "corr_coeff = dec.y_var[specific_columns].corr()\n",
    "#plt.figure(figsize = (6, 6))\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.heatmap(corr_coeff, cmap='coolwarm', annot=True, linewidths=1, vmin=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot trial segments in pursuit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.matplotlib_tools import plot_trials,\n",
    "dec.make_PlotTrials_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]                     \n",
    "\n",
    "max_plot_to_make = 2\n",
    "plot_counter = 0\n",
    "\n",
    "for index, row in dec.single_vis_target_df.iloc[2:].iterrows():\n",
    "\n",
    "    duration = [row['last_vis_time'], row['ff_caught_time']]\n",
    "\n",
    "    returned_info = plot_trials.PlotTrials(\n",
    "                duration, \n",
    "                *dec.PlotTrials_args,  \n",
    "                adjust_xy_limits=True,       \n",
    "                minimal_margin=50,\n",
    "                show_reward_boundary=True,\n",
    "                show_alive_fireflies=False,\n",
    "                show_visible_fireflies=True,\n",
    "                show_in_memory_fireflies=True,\n",
    "                show_believed_target_positions=True,\n",
    "                )\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plot_counter += 1\n",
    "    if plot_counter >= max_plot_to_make:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check target_rel_x and y\n",
    "(The look correct after checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pursuit_sub = dec.pursuit_data.loc[dec.pursuit_data['target_index']==65].copy()\n",
    "pursuit_sub['target_angle_deg'] = pursuit_sub['target_angle'] * 180/pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pursuit_sub[['point_index', 'target_angle_deg', 'target_distance', 'target_rel_x', 'target_rel_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows, na_cols = general_utils.find_rows_with_na(dec.y_var)\n",
    "duplicate_rows = general_utils.find_duplicate_rows(dec.y_var, column_subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See sizes of biggest variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "\n",
    "sizes = []\n",
    "for attr in dir(dec):\n",
    "    if attr.startswith('__') and attr.endswith('__'):\n",
    "        continue  # skip dunder attributes\n",
    "    try:\n",
    "        val = getattr(dec, attr)\n",
    "        size = asizeof.asizeof(val)\n",
    "        sizes.append((attr, size))\n",
    "    except Exception:\n",
    "        pass  # ignore any errors\n",
    "\n",
    "# Sort and display largest attributes in MB\n",
    "for name, size in sorted(sizes, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {size / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import warnings\n",
    "from pympler import asizeof\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "filtered = {\n",
    "    k: v for k, v in globals().items()\n",
    "    if not isinstance(v, types.ModuleType)\n",
    "}\n",
    "\n",
    "sizes = []\n",
    "for name, val in filtered.items():\n",
    "    try:\n",
    "        sizes.append((name, asizeof.asizeof(val)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for name, size in sorted(sizes, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(f\"{name}: {size / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more columns (possibly get in the future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get also get: (but to be honest, it doesn't make that much sense to get them....so let's skip for now.)\n",
    "'distance traversed since target last visible',\n",
    "'d angle since target last visible', 'target_at_right',\n",
    "'time_till_capture', 'time from last visible to capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there might be multicollinearity. For example, duration from last visible to capture = time since target last visible + time till capture\n",
    "\n",
    "Similarly, target angle = target angle last seen frozen - d angle since target last visible\n",
    "\n",
    "(For distance it's not exactly the same because of the difference between distance and distance traversed, but it's still similar)\n",
    "\n",
    "The multicollinearity is fine in linear regression (when each feature here is a y var), but need to be dealt with in cca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should i actually align each section, as if they are trials???\n",
    "maybe i can try both that and continuous time... both can shed light on different behavioral variables\n",
    "but for aligning trials, it may require alignment or warping since trial durations vary.\n",
    "\n",
    "btw, what does it mean stitch data?\n",
    "\n",
    "also, what does it look like to use RNN to model it?\n",
    "I thought about the paper that Noah presented on\n",
    "\n",
    "\n",
    "btw.......IME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why ratio of bin/target_index approaches constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_lengths = dec.pursuit_data[['target_index', 'bin']].groupby('target_index').count()\n",
    "trial_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = dec.y_var_reduced[['time', 'bin', 'target_index']]\n",
    "sub['factor'] = dec.y_var_reduced['bin']/dec.y_var_reduced['target_index']\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.diff(dec.ff_caught_T_sorted), bins=30)\n",
    "plt.xlabel('Time difference')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of time differences between caught events')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.ff_caught_T_sorted/np.arange(len(dec.ff_caught_T_sorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compared with neural_data_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = neural_vs_behavioral_class.NeuralVsBehavioralClass(raw_data_folder_path=raw_data_folder_path)\n",
    "dec.streamline_preparing_neural_and_behavioral_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.final_behavioral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in dec.y_var.columns if col not in dec.y_var_reduced.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in dec.y_var_reduced.columns if col not in dec.y_var.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check gpfa's binned spikes vs my own binned spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_segs_df = fit_gpfa_utils.make_spike_segs_df(dec.spike_df, dec.single_vis_target_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get binned spikes (seqs) from gpfa_utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_index = 9\n",
    "cluster_index = 12\n",
    "seg = dec.spiketrain_corr_segs[seg_index]\n",
    "cluster = dec.spike_segs_df.cluster.unique()[cluster_index]\n",
    "\n",
    "spiketrain = dec.spiketrains[seg_index][cluster_index]\n",
    "seqs = gpfa_util.get_seqs([spiketrain], dec.bin_width_w_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take out my own binned spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sub = dec.pursuit_data_all[dec.pursuit_data_all['segment']==seg]\n",
    "binned_spikes_sub = dec.binned_spikes_df[dec.binned_spikes_df['bin'].isin(p_sub['bin'])].copy()\n",
    "binned_spikes_sub['bin'] = binned_spikes_sub.index\n",
    "binned_spikes_sub2 = binned_spikes_sub.merge(p_sub[['bin', 'time']], on='bin', how='left')\n",
    "binned_spikes_sub3 = binned_spikes_sub2[['bin', 'time', f'unit_{cluster}']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_length = len(binned_spikes_sub3)\n",
    "if dec.align_at_beginning:\n",
    "    binned_spikes_sub3['gpfa'] = seqs[0][1][0][trial_length:]\n",
    "else:\n",
    "    binned_spikes_sub3['gpfa'] = seqs[0][1][0][-trial_length:] # when getting latent dimension for neural data, [-trial_length:] was also used\n",
    "binned_spikes_sub3['same'] = binned_spikes_sub3[f'unit_{cluster}'] == binned_spikes_sub3['gpfa']\n",
    "binned_spikes_sub3[binned_spikes_sub3['same']!=True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find out why there are rows of NA in dec.y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows, na_cols = general_utils.find_rows_with_na(dec.y_var)\n",
    "duplicate_rows = general_utils.find_duplicate_rows(dec.y_var, column_subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.behav_data_all.loc[118189:118195, ['bin', 'time', 'target_rel_x', 'target_rel_y','time_since_target_last_seen', 'target_last_seen_distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare old and new target df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df_ori = pd.read_csv('/Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/patterns_and_features/monkey_Schro/data_0416/target_df_ori.csv')\n",
    "df = target_df_ori[['target_index', 'point_index', 'time']].copy()\n",
    "for col in ['target_distance', 'time_since_target_last_seen']:\n",
    "    df[f'old_{col}'] = target_df_ori[col]   \n",
    "    df[f'new_{col}'] = dec.target_df[col]  \n",
    "\n",
    "df['old_target_last_seen_distance'] = target_df_ori['target_last_seen_distance_frozen']\n",
    "df['new_target_last_seen_distance'] = dec.target_df['target_last_seen_distance']\n",
    "\n",
    "df2 = df.loc[10068:]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[df2['point_index']>= 139910]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "139913"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
