{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r multiff_analysis/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_folder = '/Users/dusiyi/Documents/Multifirefly-Project'\n",
    "os.chdir(project_folder)\n",
    "sys.path.append(os.path.join(project_folder, 'multiff_analysis', 'methods'))\n",
    "\n",
    "from data_wrangling import general_utils, specific_utils, process_monkey_information\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from non_behavioral_analysis.neural_data_analysis.get_neural_data import neural_data_processing\n",
    "from non_behavioral_analysis.neural_data_analysis.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from non_behavioral_analysis.neural_data_analysis.model_neural_data import cca_class, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from non_behavioral_analysis.neural_data_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from non_behavioral_analysis.neural_data_analysis.planning_neural import planning_neural_class, planning_neural_utils\n",
    "from non_behavioral_analysis.neural_data_analysis.decode_targets import behav_features_to_keep, decode_target_class, plot_gpfa_utils, decode_target_utils, fit_gpfa_utils, gpfa_regression_utils\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "from numpy import var\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "# To fit gpfa\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "from elephant.gpfa import GPFA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from elephant.gpfa import gpfa_core, gpfa_util\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0416\"\n",
    "dec = decode_target_class.DecodeTargetClass(raw_data_folder_path=raw_data_folder_path,\n",
    "                                                               bin_width=0.02, window_width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 470 points that are significantly larger than ff_caught_T_sorted, which is 0.21% of the points. Max value of closest_time - capture time is 0.4813680000000886. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 37 points out of 470 points that are outside of the reward boundary, which is 7.87% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Schro/data_0416/ff_dataframe.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/neural_vs_behavioral/prep_monkey_data.py:52: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  monkey_info_in_bins = monkey_info_in_bins.bfill(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved target_df\n",
      "Warnings: At least one ff has a lower bound of ff_angle_boundary equal to its upper bound after clipping, meaning that the ff's angle to boundary is greater than 90 degrees. Please check the input.\n",
      "Warning: max_big_angle is 179.999741856538 when ff is to the left. There is a problem here. We will adjust them by making them a little less than 90.\n",
      "Warning: 8415 arc out of 180875 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 179.999741856538. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "\n",
      "================================================================================\n",
      "NA Values Analysis for behav_data_all (179,947 rows)\n",
      "================================================================================\n",
      "\n",
      "Columns with NA values:\n",
      "------------------------------------------------------------\n",
      "time_since_target_last_seen               123,681 (  68.7%)\n",
      "target_last_seen_distance                 123,681 (  68.7%)\n",
      "time_target_last_seen                     123,681 (  68.7%)\n",
      "target_last_seen_angle                    123,681 (  68.7%)\n",
      "target_last_seen_angle_to_boundary        123,681 (  68.7%)\n",
      "monkey_x_target_last_seen                 123,681 (  68.7%)\n",
      "monkey_y_target_last_seen                 123,681 (  68.7%)\n",
      "monkey_angle_target_last_seen             123,681 (  68.7%)\n",
      "cum_distance_when_target_last_seen        123,681 (  68.7%)\n",
      "distance_from_monkey_pos_target_last_seen  123,681 (  68.7%)\n",
      "cum_distance_since_target_last_seen       123,681 (  68.7%)\n",
      "d_heading_since_target_last_seen          123,681 (  68.7%)\n",
      "------------------------------------------------------------\n",
      "Retrieved target_clust_last_vis_df\n",
      "Percentage of targets not in a visible cluster out of all targets 61.48936170212767\n",
      "10752 rows of 179947 rows (6.0%) of behav_data_all are preserved after taking out chunks between target last-seen time and capture time\n",
      "0 segments (0.0%) out of 289 segments have 0 duration. They are dropped from pursuit data\n",
      "\n",
      "No NA values found in pursuit_data\n",
      "Window width changed from 0.05 to 0.06 to make it odd\n",
      "Warnings: At least one ff has a lower bound of ff_angle_boundary equal to its upper bound after clipping, meaning that the ff's angle to boundary is greater than 90 degrees. Please check the input.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Deleted instance attributes ['ff_dataframe', 'monkey_information', 'target_df', 'curv_of_traj_df', 'curv_df'] to free up memory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>point_index</th>\n",
       "      <th>monkey_speed</th>\n",
       "      <th>monkey_angle</th>\n",
       "      <th>monkey_dw</th>\n",
       "      <th>...</th>\n",
       "      <th>gaze_world_x_r</th>\n",
       "      <th>gaze_world_y_r</th>\n",
       "      <th>target_index</th>\n",
       "      <th>target_x</th>\n",
       "      <th>target_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1161</td>\n",
       "      <td>1393</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>2.25388</td>\n",
       "      <td>-0.00006</td>\n",
       "      <td>...</td>\n",
       "      <td>351.83241</td>\n",
       "      <td>364.51694</td>\n",
       "      <td>1</td>\n",
       "      <td>825.24321</td>\n",
       "      <td>302.26639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1162</td>\n",
       "      <td>1394</td>\n",
       "      <td>86.35241</td>\n",
       "      <td>2.25535</td>\n",
       "      <td>0.08863</td>\n",
       "      <td>...</td>\n",
       "      <td>427.21394</td>\n",
       "      <td>321.36366</td>\n",
       "      <td>1</td>\n",
       "      <td>825.24321</td>\n",
       "      <td>302.26639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1163</td>\n",
       "      <td>1395</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>2.25593</td>\n",
       "      <td>0.03467</td>\n",
       "      <td>...</td>\n",
       "      <td>510.20093</td>\n",
       "      <td>278.03411</td>\n",
       "      <td>1</td>\n",
       "      <td>825.24321</td>\n",
       "      <td>302.26639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin  point_index  monkey_speed  monkey_angle  monkey_dw  ...  \\\n",
       "0  1161         1393     200.00000       2.25388   -0.00006  ...   \n",
       "1  1162         1394      86.35241       2.25535    0.08863  ...   \n",
       "2  1163         1395     200.00000       2.25593    0.03467  ...   \n",
       "\n",
       "   gaze_world_x_r  gaze_world_y_r  target_index  target_x  target_y  \n",
       "0       351.83241       364.51694             1 825.24321 302.26639  \n",
       "1       427.21394       321.36366             1 825.24321 302.26639  \n",
       "2       510.20093       278.03411             1 825.24321 302.26639  \n",
       "\n",
       "[3 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.streamline_making_behav_and_neural_data()\n",
    "dec.get_x_and_y_var()\n",
    "dec._free_up_memory()\n",
    "dec.pursuit_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target columns lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec._make_or_retrieve_target_df(exists_ok=True, fill_na=False)\n",
    "# dec.get_basic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No NA values found in DataFrame\n",
      "\n",
      "================================================================================\n",
      "🔍 Duplicate Rows Analysis:\n",
      "================================================================================\n",
      "No duplicate rows found in the dataframe\n"
     ]
    }
   ],
   "source": [
    "df = dec.y_var_lags\n",
    "na_rows, na_cols = general_utils.find_rows_with_na(df)\n",
    "duplicate_rows = general_utils.find_duplicate_rows(df, column_subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data for GPFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target_index', 'last_vis_point_index', 'last_vis_ff_index',\n",
       "       'nearby_vis_ff_indices', 'time_since_last_vis', 'last_vis_dist',\n",
       "       'last_vis_cum_dist', 'last_vis_ang', 'last_vis_ang_to_bndry',\n",
       "       'last_vis_target_dist', 'last_vis_target_ang',\n",
       "       'last_vis_target_ang_to_bndry', 'abs_last_vis_ang',\n",
       "       'abs_last_vis_ang_to_bndry', 'abs_last_vis_target_ang',\n",
       "       'abs_last_vis_target_ang_to_bndry', 'nearby_alive_ff_indices',\n",
       "       'num_nearby_vis_ff', 'ff_caught_time', 'ff_caught_point_index',\n",
       "       'last_vis_time', 'segment', 'seg_start_time', 'seg_end_time',\n",
       "       'seg_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.single_vis_target_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "86\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "dec.prepare_spikes_for_gpfa()\n",
    "\n",
    "print(len(dec.spiketrains))\n",
    "print(len(dec.spiketrains[0]))\n",
    "print(len(dec.spiketrains[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit gpfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dec.spiketrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GPFA.__init__() got an unexpected keyword argument 'bin_width_w_unit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_gpfa_traj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_dimensionality\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/decode_targets/decode_target_class.py:324\u001b[39m, in \u001b[36mDecodeTargetClass.get_gpfa_traj\u001b[39m\u001b[34m(self, latent_dimensionality)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_gpfa_traj\u001b[39m(\u001b[38;5;28mself\u001b[39m, latent_dimensionality=\u001b[32m10\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     gpfa_3dim = \u001b[43mGPFA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_width_w_unit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbin_width_w_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mx_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlatent_dimensionality\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28mself\u001b[39m.trajectories = gpfa_3dim.fit_transform(\u001b[38;5;28mself\u001b[39m.spiketrains)\n",
      "\u001b[31mTypeError\u001b[39m: GPFA.__init__() got an unexpected keyword argument 'bin_width_w_unit'"
     ]
    }
   ],
   "source": [
    "dec.get_gpfa_traj(latent_dimensionality=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gpfa_utils.plot_gpfa_traj_3d_uniform_color()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, enable interactive mode in your notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# Create the interactive plot\n",
    "fig, ax = plot_gpfa_utils.plot_gpfa_traj_3d(\n",
    "    trajectories=dec.trajectories,\n",
    "    figsize=(15, 5),\n",
    "    linewidth_single_trial=0.75,\n",
    "    alpha_single_trial=0.3,\n",
    "    linewidth_trial_average=2,\n",
    "    title='Latent dynamics extracted by GPFA',\n",
    "    view_azim=-5,\n",
    "    view_elev=60\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_gpfa_utils.plot_gpfa_traj_3d_plotly(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find variance explained by each latent dimension\n",
    "traj_stack = np.stack(dec.trajectories, axis=0)  # shape: (n_trials, 3, T)\n",
    "var_by_dim = var(traj_stack, axis=(0, 2))    # variance across trials and time\n",
    "var_by_dim /= var_by_dim.sum()               # normalize to get explained variance ratio\n",
    "print(\"Variance explained by each latent dimension:\", var_by_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.set_title('Latent dynamics extracted by GPFA')\n",
    "ax.set_xlabel('Time [s]')\n",
    "\n",
    "average_trajectory = np.mean(, axis=0)\n",
    "time = np.arange(len(average_trajectory[0])) * 0.02  # assuming all trajectories have the same length\n",
    "\n",
    "for i, x in enumerate(average_trajectory):\n",
    "    ax.plot(time, x, label=f'Dim {i+1}')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.common_t_stop = max(dec.spike_segs_df['t_duration']) * pq.s + dec.bin_width_w_unit        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.get_gpfa_and_behav_data_for_all_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_timepoints = int(1.5/0.02)\n",
    "scores_by_time, times = gpfa_regression_utils.time_resolved_regression_variable_length(dec.gpfa_trials, dec.behavior_trials, time_step=0.02, cv_folds=5, max_timepoints=max_timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_labels = dec.pursuit_data_by_trial.drop(columns=['segment']).columns\n",
    "len(behavior_labels)\n",
    "scores_by_time_df = pd.DataFrame(scores_by_time, columns=behavior_labels)\n",
    "# see the percentage of 1 of this dummy variable\n",
    "dec.pursuit_data_by_trial[['whether_new_distinct_stop']].sum()/len(dec.pursuit_data_by_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpfa_regression_utils.plot_time_resolved_scores(scores_by_time, times, behavior_labels=behavior_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_counts = np.array([sum(latent.shape[0] > t for latent in gpfa_trials)\n",
    "                         for t in range(scores_by_time.shape[0])])\n",
    "plt.plot(times, trial_counts)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Trials with data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce columns in lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'non_behavioral_analysis.neural_data_analysis.model_neural_data.drop_high_corr_vars' from '/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_corr_vars.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(decode_target_class)\n",
    "reload(decode_target_utils)\n",
    "reload(drop_high_corr_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.reduce_y_var_lags(filter_vif_by_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_key_words, all_column_subsets = dec.get_subset_key_words_and_all_column_subsets_for_vif(\n",
    "            dec.y_var_lags_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 59 features are processed for VIF.\n",
      "10 out of 59 features are processed for VIF.\n",
      "20 out of 59 features are processed for VIF.\n",
      "30 out of 59 features are processed for VIF.\n",
      "40 out of 59 features are processed for VIF.\n",
      "50 out of 59 features are processed for VIF.\n",
      "0 out of 129 features are processed for VIF.\n",
      "10 out of 129 features are processed for VIF.\n",
      "20 out of 129 features are processed for VIF.\n",
      "30 out of 129 features are processed for VIF.\n",
      "40 out of 129 features are processed for VIF.\n",
      "50 out of 129 features are processed for VIF.\n",
      "60 out of 129 features are processed for VIF.\n",
      "70 out of 129 features are processed for VIF.\n",
      "80 out of 129 features are processed for VIF.\n",
      "90 out of 129 features are processed for VIF.\n",
      "100 out of 129 features are processed for VIF.\n",
      "110 out of 129 features are processed for VIF.\n",
      "120 out of 129 features are processed for VIF.\n"
     ]
    }
   ],
   "source": [
    "vif_df_dict = {}\n",
    "for i, column_subset in enumerate(all_column_subsets):\n",
    "    vif_df_dict[subset_key_words[i]] = drop_high_vif_vars.get_vif_df(df[column_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop',\n",
       " 'speed_OR_ddv_OR_dw_OR_delta_OR_traj',\n",
       " 'LD_or_RD_or_gaze_or_view',\n",
       " 'distance',\n",
       " 'angle',\n",
       " 'frozen',\n",
       " 'dummy',\n",
       " 'num_or_any_or_rate']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'speed_OR_ddv_OR_dw_OR_delta_OR_traj' \n",
    "change to\n",
    "'speeddummy_OR_monkey_dw_OR_delta_OR_traj'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'LD_or_RD_or_gaze_or_view'\n",
    "exclude: gave_mky_view_x and y\n",
    "'LD_or_RD_or_gave_mky_view_angle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get rid of \n",
    "frozen\n",
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_visible_ff_5</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_visible_ff_-5</td>\n",
       "      <td>5.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_alive_ff_5</td>\n",
       "      <td>5.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any_ff_visible_5</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>any_ff_visible_-5</td>\n",
       "      <td>2.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature     vif\n",
       "3   num_visible_ff_5 6.00000\n",
       "0  num_visible_ff_-5 5.70000\n",
       "2     num_alive_ff_5 5.60000\n",
       "4   any_ff_visible_5 3.00000\n",
       "1  any_ff_visible_-5 2.50000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = vif_df_dict['num_or_any_or_rate']\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================Dropping lags of features with high correlation for each feature====================\n",
      "Processing feature 1/59\n",
      "10 columns of *monkey_y* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *time_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *time_since_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *monkey_y_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "8 columns of *target_angle* dropped: [-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_last_seen_angle_to_boundary* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_last_seen_distance* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_x* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "Processing feature 11/59\n",
      "9 columns of *traj_curv* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "10 columns of *time_since_last_capture* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *min_abs_visible_ff_angle* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *target_rel_x* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *min_abs_visible_ff_angle_boundary* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "10 columns of *num_alive_ff* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "Processing feature 21/59\n",
      "10 columns of *point_index* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *monkey_speeddummy* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *min_visible_ff_distance* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *any_ff_visible* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *target_rel_y* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "8 columns of *target_angle_to_boundary* dropped: [-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "Processing feature 31/59\n",
      "10 columns of *monkey_angle* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *distance_from_monkey_pos_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *min_ff_distance* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *target_last_seen_angle* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "Processing feature 41/59\n",
      "9 columns of *valid_view_point_l* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "8 columns of *target_opt_arc_dheading* dropped: [-4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *d_heading_since_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *min_abs_ff_angle* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "10 columns of *min_abs_ff_angle_boundary* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "10 columns of *monkey_x* dropped: [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *target_index* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "Processing feature 51/59\n",
      "9 columns of *num_visible_ff* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "9 columns of *monkey_x_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *cum_distance_since_target_last_seen* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_y* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *target_distance* dropped: [-5, -4, -3, -2, -1, 1, 2, 3, 4]\n",
      "9 columns of *valid_view_point_r* dropped: [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
      "\n",
      "Dropped 337 out of 632 columns (53.32%) after removing lags of features with high correlation.\n",
      "Dropped columns: ['min_visible_ff_distance_1', 'valid_view_point_l_-1', 'valid_view_point_r_1', 'target_last_seen_angle_-4', 'monkey_x_target_last_seen_-2', 'point_index_-2', 'target_last_seen_angle_to_boundary_-5', 'num_alive_ff_2', 'min_abs_ff_angle_boundary_1', 'target_angle_to_boundary_4', 'time_target_last_seen_1', 'min_abs_visible_ff_angle_boundary_2', 'time_since_last_capture_-1', 'traj_curv_2', 'num_alive_ff_3', 'time_target_last_seen_-3', 'target_y_1', 'target_distance_-5', 'num_alive_ff_4', 'd_heading_since_target_last_seen_2', 'target_angle_-3', 'min_abs_ff_angle_0', 'num_visible_ff_-2', 'target_distance_3', 'any_ff_visible_4', 'monkey_speeddummy_2', 'monkey_speeddummy_-3', 'monkey_x_3', 'target_last_seen_angle_to_boundary_-1', 'target_rel_x_-1', 'monkey_y_3', 'min_visible_ff_distance_3', 'min_abs_visible_ff_angle_2', 'min_abs_ff_angle_boundary_-1', 'time_since_target_last_seen_-1', 'target_distance_-3', 'target_opt_arc_dheading_1', 'target_last_seen_angle_to_boundary_3', 'monkey_y_-3', 'min_ff_distance_-3', 'any_ff_visible_0', 'cum_distance_since_target_last_seen_-3', 'min_abs_visible_ff_angle_boundary_1', 'target_opt_arc_dheading_-2', 'monkey_speeddummy_-4', 'num_alive_ff_0', 'num_visible_ff_3', 'min_abs_ff_angle_3', 'valid_view_point_r_0', 'min_abs_ff_angle_-2', 'monkey_y_4', 'monkey_y_2', 'd_heading_since_target_last_seen_1', 'monkey_x_-5', 'min_ff_distance_4', 'num_alive_ff_-2', 'target_rel_y_-2', 'min_ff_distance_0', 'time_target_last_seen_3', 'monkey_x_target_last_seen_1', 'point_index_-5', 'target_last_seen_angle_-3', 'any_ff_visible_-1', 'target_last_seen_angle_to_boundary_4', 'min_abs_visible_ff_angle_-3', 'valid_view_point_l_-3', 'target_x_-2', 'min_visible_ff_distance_0', 'traj_curv_-3', 'time_target_last_seen_-5', 'target_last_seen_angle_to_boundary_-2', 'target_distance_4', 'target_x_4', 'monkey_x_target_last_seen_2', 'target_last_seen_angle_to_boundary_-3', 'distance_from_monkey_pos_target_last_seen_3', 'target_y_-3', 'target_rel_x_-3', 'target_opt_arc_dheading_-3', 'target_opt_arc_dheading_-4', 'monkey_y_target_last_seen_1', 'target_last_seen_distance_1', 'any_ff_visible_-2', 'min_ff_distance_1', 'num_alive_ff_-5', 'traj_curv_-4', 'target_angle_to_boundary_-4', 'time_target_last_seen_4', 'target_x_2', 'point_index_-3', 'distance_from_monkey_pos_target_last_seen_-5', 'target_index_2', 'min_abs_visible_ff_angle_4', 'target_last_seen_angle_4', 'valid_view_point_l_-2', 'time_target_last_seen_-1', 'min_abs_ff_angle_4', 'cum_distance_since_target_last_seen_4', 'min_ff_distance_2', 'monkey_angle_4', 'traj_curv_-1', 'target_rel_y_-3', 'monkey_speeddummy_4', 'monkey_x_2', 'min_abs_visible_ff_angle_boundary_3', 'num_alive_ff_1', 'monkey_x_target_last_seen_-4', 'min_ff_distance_-2', 'target_last_seen_distance_-2', 'target_x_1', 'min_abs_ff_angle_boundary_0', 'valid_view_point_l_4', 'time_since_last_capture_1', 'monkey_angle_2', 'monkey_speeddummy_3', 'num_visible_ff_0', 'target_opt_arc_dheading_3', 'target_y_3', 'cum_distance_since_target_last_seen_2', 'distance_from_monkey_pos_target_last_seen_-1', 'target_last_seen_distance_-5', 'monkey_x_-4', 'target_rel_y_-1', 'target_distance_2', 'time_since_last_capture_3', 'target_last_seen_angle_3', 'target_last_seen_distance_-4', 'time_target_last_seen_-2', 'target_index_4', 'monkey_y_-5', 'target_last_seen_distance_-1', 'target_last_seen_angle_-2', 'monkey_y_target_last_seen_-5', 'target_angle_to_boundary_-3', 'min_abs_ff_angle_1', 'target_y_-1', 'monkey_speeddummy_0', 'target_x_-4', 'min_abs_ff_angle_boundary_3', 'target_rel_x_-2', 'target_x_3', 'target_y_-4', 'target_angle_1', 'valid_view_point_r_2', 'distance_from_monkey_pos_target_last_seen_2', 'cum_distance_since_target_last_seen_3', 'monkey_x_0', 'target_angle_2', 'target_angle_to_boundary_1', 'monkey_x_-3', 'point_index_-1', 'target_opt_arc_dheading_2', 'monkey_angle_0', 'traj_curv_3', 'monkey_y_target_last_seen_-4', 'cum_distance_since_target_last_seen_1', 'target_angle_-1', 'valid_view_point_l_1', 'min_abs_visible_ff_angle_boundary_0', 'min_abs_visible_ff_angle_-4', 'cum_distance_since_target_last_seen_-4', 'traj_curv_4', 'target_rel_y_4', 'num_visible_ff_-3', 'valid_view_point_l_0', 'time_since_target_last_seen_2', 'target_distance_-2', 'target_rel_x_2', 'target_rel_x_3', 'monkey_y_target_last_seen_-2', 'target_x_-1', 'cum_distance_since_target_last_seen_-2', 'valid_view_point_r_4', 'min_ff_distance_3', 'monkey_y_0', 'target_last_seen_angle_to_boundary_2', 'target_last_seen_angle_-1', 'time_since_last_capture_2', 'min_abs_ff_angle_-1', 'min_abs_ff_angle_-3', 'target_last_seen_distance_2', 'target_opt_arc_dheading_4', 'monkey_y_target_last_seen_4', 'min_abs_ff_angle_boundary_2', 'target_last_seen_angle_-5', 'target_index_3', 'target_index_-2', 'min_abs_visible_ff_angle_-2', 'cum_distance_since_target_last_seen_-5', 'monkey_angle_-2', 'monkey_x_target_last_seen_3', 'target_last_seen_angle_1', 'min_abs_ff_angle_boundary_-5', 'time_since_target_last_seen_-3', 'target_last_seen_angle_to_boundary_1', 'min_abs_visible_ff_angle_boundary_-1', 'monkey_x_target_last_seen_-1', 'min_visible_ff_distance_4', 'time_since_last_capture_0', 'num_visible_ff_-4', 'num_visible_ff_4', 'time_since_target_last_seen_3', 'd_heading_since_target_last_seen_-5', 'valid_view_point_l_3', 'monkey_angle_3', 'target_angle_-4', 'min_abs_visible_ff_angle_0', 'point_index_-4', 'target_index_1', 'target_rel_y_-4', 'target_x_-3', 'any_ff_visible_-3', 'monkey_y_target_last_seen_-3', 'monkey_x_target_last_seen_-5', 'monkey_y_1', 'target_angle_to_boundary_-2', 'target_rel_y_2', 'any_ff_visible_-4', 'monkey_x_4', 'target_y_2', 'min_ff_distance_-1', 'valid_view_point_l_-4', 'min_abs_ff_angle_-4', 'distance_from_monkey_pos_target_last_seen_-4', 'd_heading_since_target_last_seen_4', 'min_abs_visible_ff_angle_boundary_-2', 'target_y_4', 'min_abs_visible_ff_angle_boundary_-4', 'num_alive_ff_-4', 'num_visible_ff_1', 'distance_from_monkey_pos_target_last_seen_1', 'num_visible_ff_2', 'target_last_seen_distance_3', 'valid_view_point_r_-4', 'num_alive_ff_-1', 'time_target_last_seen_-4', 'target_rel_x_1', 'time_since_last_capture_-2', 'monkey_y_-1', 'target_rel_x_-4', 'monkey_x_-1', 'num_alive_ff_-3', 'target_last_seen_distance_-3', 'any_ff_visible_3', 'target_y_-2', 'min_abs_visible_ff_angle_3', 'd_heading_since_target_last_seen_-2', 'traj_curv_-2', 'cum_distance_since_target_last_seen_-1', 'monkey_y_target_last_seen_3', 'time_since_target_last_seen_4', 'num_visible_ff_-1', 'min_abs_ff_angle_boundary_-2', 'target_distance_1', 'min_visible_ff_distance_-1', 'point_index_1', 'distance_from_monkey_pos_target_last_seen_-2', 'point_index_3', 'target_angle_to_boundary_-1', 'target_angle_-2', 'monkey_y_-2', 'target_rel_x_-5', 'monkey_x_target_last_seen_4', 'target_angle_3', 'traj_curv_0', 'target_index_-3', 'min_visible_ff_distance_-4', 'any_ff_visible_2', 'monkey_angle_-4', 'monkey_y_-4', 'target_rel_y_-5', 'distance_from_monkey_pos_target_last_seen_-3', 'monkey_angle_-1', 'distance_from_monkey_pos_target_last_seen_4', 'any_ff_visible_1', 'time_target_last_seen_2', 'time_since_target_last_seen_-5', 'time_since_target_last_seen_-2', 'd_heading_since_target_last_seen_-4', 'target_index_-4', 'monkey_x_1', 'min_abs_ff_angle_boundary_-4', 'target_index_-5', 'min_abs_visible_ff_angle_boundary_4', 'valid_view_point_r_3', 'target_angle_to_boundary_2', 'monkey_angle_1', 'time_since_target_last_seen_1', 'd_heading_since_target_last_seen_-1', 'target_rel_y_3', 'target_rel_y_1', 'min_abs_ff_angle_boundary_-3', 'target_last_seen_angle_to_boundary_-4', 'target_y_-5', 'd_heading_since_target_last_seen_-3', 'valid_view_point_r_-3', 'min_abs_ff_angle_2', 'time_since_last_capture_-5', 'point_index_0', 'monkey_y_target_last_seen_-1', 'monkey_speeddummy_1', 'target_last_seen_angle_2', 'monkey_angle_-5', 'monkey_speeddummy_-1', 'target_angle_to_boundary_3', 'valid_view_point_r_-1', 'valid_view_point_l_2', 'valid_view_point_r_-2', 'time_since_last_capture_-3', 'target_rel_x_4', 'time_since_last_capture_4', 'target_index_-1', 'target_angle_4', 'target_distance_-4', 'min_abs_visible_ff_angle_-1', 'min_ff_distance_-4', 'monkey_y_target_last_seen_2', 'min_abs_ff_angle_boundary_4', 'min_abs_visible_ff_angle_boundary_-3', 'min_abs_visible_ff_angle_1', 'min_visible_ff_distance_-2', 'point_index_2', 'time_since_last_capture_-4', 'd_heading_since_target_last_seen_3', 'monkey_speeddummy_-2', 'min_visible_ff_distance_2', 'traj_curv_1', 'monkey_x_target_last_seen_-3', 'min_visible_ff_distance_-3', 'point_index_4', 'monkey_angle_-3', 'monkey_x_-2', 'time_since_target_last_seen_-4', 'target_x_-5', 'target_distance_-1', 'target_last_seen_distance_4', 'target_opt_arc_dheading_-1']\n",
      "====================Dropping lags of features with high correlation in specific subsets of features====================\n",
      "Processing subset 1 of 7 with features that contain \"_x\", 48 features in total.\n",
      "2 columns out of 48 dropped: ['monkey_x_target_last_seen_5', 'monkey_x_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 2 of 7 with features that contain \"_y\", 48 features in total.\n",
      "2 columns out of 48 dropped: ['monkey_y_5', 'monkey_y_target_last_seen_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 3 of 7 with features that contain \"angle\", 36 features in total.\n",
      "3 columns out of 36 dropped: ['min_abs_visible_ff_angle_-5', 'min_abs_ff_angle_5', 'min_abs_visible_ff_angle_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 4 of 7 with features that contain \"distance\", 19 features in total.\n",
      "1 columns out of 19 dropped: ['distance_from_monkey_pos_target_last_seen_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 5 of 7 with features that contain \"ff_or_target\", 50 features in total.\n",
      "10 columns out of 50 dropped: ['target_index', 'min_abs_ff_angle_5', 'time_target_last_seen_5', 'monkey_y_target_last_seen_5', 'min_abs_visible_ff_angle_5', 'time_since_target_last_seen_5', 'min_abs_visible_ff_angle_-5', 'monkey_x_target_last_seen_5', 'target_distance_5', 'distance_from_monkey_pos_target_last_seen_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 6 of 7 with features that contain \"speed_OR_ddv_OR_dw_OR_delta_OR_traj\", 70 features in total.\n",
      "11 columns out of 70 dropped: ['monkey_speed_5', 'monkey_speed_-1', 'monkey_speed_-3', 'monkey_speed_-2', 'monkey_speed_1', 'monkey_speed_0', 'monkey_speed_4', 'monkey_speed_3', 'monkey_speed_2', 'monkey_speed_-5', 'monkey_speed_-4']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 7 of 7 with features that contain \"LD_or_RD_or_gaze_or_view\", 158 features in total.\n",
      "29 columns out of 158 dropped: ['RDy_-1', 'RDy_0', 'LDy_-3', 'RDy_1', 'gaze_mky_view_y_r_5', 'LDy_4', 'RDy_2', 'RDy_-2', 'LDy_-2', 'gaze_mky_view_y_r_3', 'gaze_mky_view_y_r_0', 'LDy_3', 'LDy_0', 'RDy_5', 'gaze_mky_view_y_r_4', 'LDy_-4', 'LDy_5', 'RDy_3', 'RDy_-3', 'LDy_1', 'gaze_mky_view_y_r_2', 'gaze_mky_view_y_r_1', 'LDy_2', 'LDy_-5', 'LDy_-1', 'RDy_-4', 'RDy_4', 'gaze_mky_view_y_r_-1', 'RDy_-5']\n",
      "\n",
      "58 out of 295 (19.66%) are dropped after dropping lags of features with high correlation in subsets of features\n",
      "====================Dropping lags of features with high correlation in all columns====================\n",
      "Processing subset 1 of 1, 243 features in total.\n",
      "2 columns out of 243 dropped: ['point_index_5', 'bin']\n",
      "\n",
      "2 out of 243 (0.82%) are dropped after dropping lags of features with high correlation in subsets of features\n",
      "\n",
      "** Summary: 391 out of 632 (61.87%) are dropped after calling drop_columns_with_high_corr. 241 features are left. **\n",
      "\n",
      "====================Dropping lags of features with high VIF for each feature====================\n",
      "Processing feature 1/46\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_angle_l_2 with VIF 4.5\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is eye_world_speed_0 with VIF 2.7\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_angle_-5 with VIF 2.8\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_last_seen_angle_to_boundary_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_last_seen_distance_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_x_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is traj_curv_5 with VIF 2.3\n",
      "Iter 1: Dropped gaze_mky_view_angle_r_-4 (VIF: 6.6)\n",
      "Iter 2: Dropped gaze_mky_view_angle_r_-2 (VIF: 6.6)\n",
      "Iter 3: Dropped gaze_mky_view_angle_r_0 (VIF: 6.2)\n",
      "Iter 4: Dropped gaze_mky_view_angle_r_2 (VIF: 5.3)\n",
      "Iter 5: Dropped gaze_mky_view_angle_r_4 (VIF: 5.2)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_angle_r_-3 with VIF 2.8\n",
      "5 columns of *gaze_mky_view_angle_r* dropped: [-4, -2, 0, 2, 4]\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is time_since_last_capture_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_rel_x_5 with VIF 0\n",
      "Processing feature 11/46\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is RDz_-4 with VIF 4.7\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is min_abs_visible_ff_angle_boundary_-5 with VIF 1.5\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is num_alive_ff_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_x_r_-3 with VIF 1.6\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is monkey_speeddummy_-5 with VIF 3.9\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_y_r_-5 with VIF 1.2\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is whether_new_distinct_stop_0 with VIF 1.0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is LDz_2 with VIF 3.2\n",
      "Iter 1: Dropped min_visible_ff_distance_5 (VIF: 5.4)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is min_visible_ff_distance_-5 with VIF 0\n",
      "1 columns of *min_visible_ff_distance* dropped: [5]\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_world_y_r_-5 with VIF 1.6\n",
      "Processing feature 21/46\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is any_ff_visible_-5 with VIF 1.8\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_rel_y_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_angle_to_boundary_-5 with VIF 1.6\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is monkey_angle_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is monkey_ddv_4 with VIF 1.3\n",
      "Iter 1: Dropped delta_distance_0 (VIF: 8.2)\n",
      "Iter 2: Dropped delta_distance_2 (VIF: 7.4)\n",
      "Iter 3: Dropped delta_distance_-1 (VIF: 7.1)\n",
      "Iter 4: Dropped delta_distance_-2 (VIF: 6.4)\n",
      "Iter 5: Dropped delta_distance_1 (VIF: 6.1)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is delta_distance_3 with VIF 4.2\n",
      "5 columns of *delta_distance* dropped: [-2, -1, 0, 1, 2]\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_world_x_r_-5 with VIF 2.6\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is catching_ff_-1 with VIF 1.0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_world_y_l_0 with VIF 1.1\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_x_l_-2 with VIF 1.0\n",
      "Processing feature 31/46\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is min_ff_distance_-5 with VIF 2.8\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_last_seen_angle_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is valid_view_point_l_5 with VIF 4.2\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_opt_arc_dheading_5 with VIF 1.6\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is d_heading_since_target_last_seen_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_world_x_l_-3 with VIF 1.1\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is monkey_dw_-2 with VIF 4.7\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is min_abs_ff_angle_-5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is min_abs_ff_angle_boundary_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_index_5 with VIF 0\n",
      "Processing feature 41/46\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is monkey_ddw_-1 with VIF 1.1\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is num_visible_ff_5 with VIF 4.2\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_y_l_2 with VIF 1.0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is cum_distance_since_target_last_seen_5 with VIF 0\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_y_5 with VIF 0\n",
      "Iter 1: Dropped valid_view_point_r_5 (VIF: 7.5)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is valid_view_point_r_-5 with VIF 0\n",
      "1 columns of *valid_view_point_r* dropped: [5]\n",
      "\n",
      "Dropped 12 out of 241 columns (4.98%) after removing lags of features with high VIF.\n",
      "Dropped columns: ['gaze_mky_view_angle_r_0', 'delta_distance_0', 'delta_distance_1', 'min_visible_ff_distance_5', 'delta_distance_-1', 'gaze_mky_view_angle_r_2', 'gaze_mky_view_angle_r_-2', 'valid_view_point_r_5', 'gaze_mky_view_angle_r_4', 'delta_distance_-2', 'gaze_mky_view_angle_r_-4', 'delta_distance_2']\n",
      "\n",
      "====================Dropping lags with high VIF in subsets of features in an iterative manner====================\n",
      "Processing subset 1 of 7 with features that contain \"_x\", 46 features in total.\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_x_r_3 with VIF 3.4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 2 of 7 with features that contain \"_y\", 39 features in total.\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is target_y_5 with VIF 2.9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 3 of 7 with features that contain \"angle\", 28 features in total.\n",
      "Iter 1: Dropped min_abs_ff_angle_-5 (VIF: 12.1)\n",
      "Iter 2: Dropped target_angle_5 (VIF: 6.4)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is gaze_mky_view_angle_l_2 with VIF 4.9\n",
      "Dropped columns:  ['min_abs_ff_angle_-5' 'target_angle_5']\n",
      "Kept columns:  ['gaze_mky_view_angle_l_0' 'gaze_mky_view_angle_l_-1'\n",
      " 'gaze_mky_view_angle_r_-1' 'gaze_mky_view_angle_l_1'\n",
      " 'gaze_mky_view_angle_r_1' 'gaze_mky_view_angle_l_-2'\n",
      " 'gaze_mky_view_angle_l_2' 'gaze_mky_view_angle_l_-3'\n",
      " 'gaze_mky_view_angle_r_-3' 'gaze_mky_view_angle_l_3'\n",
      " 'gaze_mky_view_angle_r_3' 'gaze_mky_view_angle_l_-4'\n",
      " 'gaze_mky_view_angle_l_4' 'gaze_mky_view_angle_l_-5'\n",
      " 'gaze_mky_view_angle_r_-5' 'min_abs_visible_ff_angle_boundary_-5'\n",
      " 'monkey_angle_5' 'gaze_mky_view_angle_l_5' 'gaze_mky_view_angle_r_5'\n",
      " 'min_abs_ff_angle_boundary_5' 'min_abs_visible_ff_angle_boundary_5'\n",
      " 'target_angle_-5' 'target_angle_to_boundary_-5'\n",
      " 'target_angle_to_boundary_5' 'target_last_seen_angle_5'\n",
      " 'target_last_seen_angle_to_boundary_5']\n",
      "2 columns out of 28 dropped: ['min_abs_ff_angle_-5', 'target_angle_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 4 of 7 with features that contain \"distance\", 11 features in total.\n",
      "Iter 1: Dropped target_last_seen_distance_5 (VIF: 16.0)\n",
      "Iter 2: Dropped min_ff_distance_5 (VIF: 5.4)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is delta_distance_3 with VIF 4.3\n",
      "Dropped columns:  ['target_last_seen_distance_5' 'min_ff_distance_5']\n",
      "Kept columns:  ['delta_distance_-3' 'delta_distance_3' 'delta_distance_-4'\n",
      " 'delta_distance_4' 'delta_distance_-5' 'min_ff_distance_-5'\n",
      " 'min_visible_ff_distance_-5' 'delta_distance_5'\n",
      " 'cum_distance_since_target_last_seen_5']\n",
      "2 columns out of 11 dropped: ['target_last_seen_distance_5', 'min_ff_distance_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 5 of 7 with features that contain \"ff_or_target\", 39 features in total.\n",
      "Iter 1: Dropped target_last_seen_distance_5 (VIF: 6062.5)\n",
      "Iter 2: Dropped min_abs_ff_angle_-5 (VIF: 13.2)\n",
      "Iter 3: Dropped num_alive_ff_5 (VIF: 12.0)\n",
      "Iter 4: Dropped min_ff_distance_5 (VIF: 8.5)\n",
      "Iter 5: Dropped num_visible_ff_-5 (VIF: 7.2)\n",
      "Iter 6: Dropped target_last_seen_angle_to_boundary_5 (VIF: 6.9)\n",
      "Iter 7: Dropped target_angle_5 (VIF: 6.4)\n",
      "Iter 8: Dropped num_visible_ff_5 (VIF: 5.4)\n",
      "Iter 9: Dropped min_visible_ff_distance_-5 (VIF: 5.1)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is min_ff_distance_-5 with VIF 4.6\n",
      "Dropped columns:  ['target_last_seen_distance_5' 'min_abs_ff_angle_-5' 'num_alive_ff_5'\n",
      " 'min_ff_distance_5' 'num_visible_ff_-5'\n",
      " 'target_last_seen_angle_to_boundary_5' 'target_angle_5'\n",
      " 'num_visible_ff_5' 'min_visible_ff_distance_-5']\n",
      "Kept columns:  ['catching_ff_0' 'catching_ff_-1' 'catching_ff_1' 'catching_ff_-2'\n",
      " 'catching_ff_2' 'catching_ff_-3' 'catching_ff_3' 'catching_ff_-4'\n",
      " 'catching_ff_4' 'min_ff_distance_-5'\n",
      " 'min_abs_visible_ff_angle_boundary_-5' 'catching_ff_-5'\n",
      " 'any_ff_visible_-5' 'min_abs_ff_angle_boundary_5'\n",
      " 'min_abs_visible_ff_angle_boundary_5' 'catching_ff_5' 'any_ff_visible_5'\n",
      " 'target_angle_-5' 'target_angle_to_boundary_-5'\n",
      " 'target_opt_arc_dheading_-5' 'target_angle_to_boundary_5'\n",
      " 'target_rel_x_5' 'target_rel_y_5' 'target_last_seen_angle_5'\n",
      " 'target_opt_arc_dheading_5' 'cum_distance_since_target_last_seen_5'\n",
      " 'd_heading_since_target_last_seen_5' 'target_index_5' 'target_x_5'\n",
      " 'target_y_5']\n",
      "9 columns out of 39 dropped: ['target_last_seen_distance_5', 'min_abs_ff_angle_-5', 'min_visible_ff_distance_-5', 'min_ff_distance_5', 'num_alive_ff_5', 'num_visible_ff_-5', 'target_angle_5', 'num_visible_ff_5', 'target_last_seen_angle_to_boundary_5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 6 of 7 with features that contain \"speed_OR_ddv_OR_dw_OR_delta_OR_traj\", 54 features in total.\n",
      "0 out of 54 features are processed for VIF.\n",
      "10 out of 54 features are processed for VIF.\n",
      "20 out of 54 features are processed for VIF.\n",
      "30 out of 54 features are processed for VIF.\n",
      "40 out of 54 features are processed for VIF.\n",
      "50 out of 54 features are processed for VIF.\n",
      "Iter 1: Dropped monkey_speeddummy_5 (VIF: 13.2)\n",
      "0 out of 53 features are processed for VIF.\n",
      "10 out of 53 features are processed for VIF.\n",
      "20 out of 53 features are processed for VIF.\n",
      "30 out of 53 features are processed for VIF.\n",
      "40 out of 53 features are processed for VIF.\n",
      "50 out of 53 features are processed for VIF.\n",
      "Iter 2: Dropped monkey_speeddummy_-5 (VIF: 9.4)\n",
      "0 out of 52 features are processed for VIF.\n",
      "10 out of 52 features are processed for VIF.\n",
      "20 out of 52 features are processed for VIF.\n",
      "30 out of 52 features are processed for VIF.\n",
      "40 out of 52 features are processed for VIF.\n",
      "50 out of 52 features are processed for VIF.\n",
      "Iter 3: Dropped monkey_dw_0 (VIF: 9.2)\n",
      "0 out of 51 features are processed for VIF.\n",
      "10 out of 51 features are processed for VIF.\n",
      "20 out of 51 features are processed for VIF.\n",
      "30 out of 51 features are processed for VIF.\n",
      "40 out of 51 features are processed for VIF.\n",
      "50 out of 51 features are processed for VIF.\n",
      "Iter 4: Dropped traj_curv_5 (VIF: 8.5)\n",
      "Iter 5: Dropped monkey_dw_1 (VIF: 8.4)\n",
      "Iter 6: Dropped monkey_dw_-2 (VIF: 7.9)\n",
      "Iter 7: Dropped monkey_dw_-3 (VIF: 7.6)\n",
      "Iter 8: Dropped monkey_dw_2 (VIF: 6.5)\n",
      "Iter 9: Dropped delta_distance_3 (VIF: 6.0)\n",
      "Iter 10: Dropped delta_distance_-3 (VIF: 5.8)\n",
      "Iter 11: Dropped monkey_dw_3 (VIF: 5.7)\n",
      "After iterative dropping, the column with the highest VIF of the dataframe or subset is monkey_dw_-1 with VIF 4.9\n",
      "Dropped columns:  ['monkey_speeddummy_5' 'monkey_speeddummy_-5' 'monkey_dw_0' 'traj_curv_5'\n",
      " 'monkey_dw_1' 'monkey_dw_-2' 'monkey_dw_-3' 'monkey_dw_2'\n",
      " 'delta_distance_3' 'delta_distance_-3' 'monkey_dw_3']\n",
      "Kept columns:  ['monkey_ddw_0' 'monkey_ddv_0' 'eye_world_speed_0' 'monkey_dw_-1'\n",
      " 'monkey_ddw_-1' 'monkey_ddv_-1' 'eye_world_speed_-1' 'monkey_ddw_1'\n",
      " 'monkey_ddv_1' 'eye_world_speed_1' 'monkey_ddw_-2' 'monkey_ddv_-2'\n",
      " 'eye_world_speed_-2' 'monkey_ddw_2' 'monkey_ddv_2' 'eye_world_speed_2'\n",
      " 'monkey_ddw_-3' 'monkey_ddv_-3' 'eye_world_speed_-3' 'monkey_ddw_3'\n",
      " 'monkey_ddv_3' 'eye_world_speed_3' 'monkey_dw_-4' 'monkey_ddw_-4'\n",
      " 'monkey_ddv_-4' 'delta_distance_-4' 'eye_world_speed_-4' 'monkey_dw_4'\n",
      " 'monkey_ddw_4' 'monkey_ddv_4' 'delta_distance_4' 'eye_world_speed_4'\n",
      " 'monkey_dw_-5' 'monkey_ddw_-5' 'monkey_ddv_-5' 'delta_distance_-5'\n",
      " 'eye_world_speed_-5' 'traj_curv_-5' 'monkey_dw_5' 'monkey_ddw_5'\n",
      " 'monkey_ddv_5' 'delta_distance_5' 'eye_world_speed_5']\n",
      "11 columns out of 54 dropped: ['monkey_speeddummy_5', 'traj_curv_5', 'monkey_dw_-3', 'monkey_dw_0', 'monkey_dw_1', 'delta_distance_3', 'delta_distance_-3', 'monkey_dw_2', 'monkey_dw_3', 'monkey_dw_-2', 'monkey_speeddummy_-5']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing subset 7 of 7 with features that contain \"LD_or_RD_or_gaze_or_view\", 123 features in total.\n",
      "0 out of 123 features are processed for VIF.\n",
      "10 out of 123 features are processed for VIF.\n",
      "20 out of 123 features are processed for VIF.\n",
      "30 out of 123 features are processed for VIF.\n",
      "40 out of 123 features are processed for VIF.\n",
      "50 out of 123 features are processed for VIF.\n",
      "60 out of 123 features are processed for VIF.\n",
      "70 out of 123 features are processed for VIF.\n",
      "80 out of 123 features are processed for VIF.\n",
      "90 out of 123 features are processed for VIF.\n",
      "100 out of 123 features are processed for VIF.\n",
      "110 out of 123 features are processed for VIF.\n",
      "120 out of 123 features are processed for VIF.\n",
      "Iter 1: Dropped gaze_mky_view_angle_l_-4 (VIF: 29.1)\n",
      "0 out of 122 features are processed for VIF.\n",
      "10 out of 122 features are processed for VIF.\n",
      "20 out of 122 features are processed for VIF.\n",
      "30 out of 122 features are processed for VIF.\n",
      "40 out of 122 features are processed for VIF.\n",
      "50 out of 122 features are processed for VIF.\n",
      "60 out of 122 features are processed for VIF.\n",
      "70 out of 122 features are processed for VIF.\n",
      "80 out of 122 features are processed for VIF.\n",
      "90 out of 122 features are processed for VIF.\n",
      "100 out of 122 features are processed for VIF.\n",
      "110 out of 122 features are processed for VIF.\n",
      "120 out of 122 features are processed for VIF.\n",
      "Iter 2: Dropped gaze_mky_view_angle_l_2 (VIF: 26.2)\n",
      "0 out of 121 features are processed for VIF.\n",
      "10 out of 121 features are processed for VIF.\n",
      "20 out of 121 features are processed for VIF.\n",
      "30 out of 121 features are processed for VIF.\n",
      "40 out of 121 features are processed for VIF.\n",
      "50 out of 121 features are processed for VIF.\n",
      "60 out of 121 features are processed for VIF.\n",
      "70 out of 121 features are processed for VIF.\n",
      "80 out of 121 features are processed for VIF.\n",
      "90 out of 121 features are processed for VIF.\n",
      "100 out of 121 features are processed for VIF.\n",
      "110 out of 121 features are processed for VIF.\n",
      "120 out of 121 features are processed for VIF.\n",
      "Iter 3: Dropped gaze_mky_view_angle_l_4 (VIF: 23.7)\n",
      "0 out of 120 features are processed for VIF.\n",
      "10 out of 120 features are processed for VIF.\n",
      "20 out of 120 features are processed for VIF.\n",
      "30 out of 120 features are processed for VIF.\n",
      "40 out of 120 features are processed for VIF.\n",
      "50 out of 120 features are processed for VIF.\n",
      "60 out of 120 features are processed for VIF.\n",
      "70 out of 120 features are processed for VIF.\n",
      "80 out of 120 features are processed for VIF.\n",
      "90 out of 120 features are processed for VIF.\n",
      "100 out of 120 features are processed for VIF.\n",
      "110 out of 120 features are processed for VIF.\n",
      "Iter 4: Dropped gaze_mky_view_angle_l_-1 (VIF: 21.4)\n",
      "0 out of 119 features are processed for VIF.\n",
      "10 out of 119 features are processed for VIF.\n",
      "20 out of 119 features are processed for VIF.\n",
      "30 out of 119 features are processed for VIF.\n",
      "40 out of 119 features are processed for VIF.\n",
      "50 out of 119 features are processed for VIF.\n",
      "60 out of 119 features are processed for VIF.\n",
      "70 out of 119 features are processed for VIF.\n",
      "80 out of 119 features are processed for VIF.\n",
      "90 out of 119 features are processed for VIF.\n",
      "100 out of 119 features are processed for VIF.\n",
      "110 out of 119 features are processed for VIF.\n",
      "Iter 5: Dropped gaze_mky_view_angle_l_-3 (VIF: 19.7)\n",
      "0 out of 118 features are processed for VIF.\n",
      "10 out of 118 features are processed for VIF.\n",
      "20 out of 118 features are processed for VIF.\n",
      "30 out of 118 features are processed for VIF.\n",
      "40 out of 118 features are processed for VIF.\n",
      "50 out of 118 features are processed for VIF.\n",
      "60 out of 118 features are processed for VIF.\n",
      "70 out of 118 features are processed for VIF.\n",
      "80 out of 118 features are processed for VIF.\n",
      "90 out of 118 features are processed for VIF.\n",
      "100 out of 118 features are processed for VIF.\n",
      "110 out of 118 features are processed for VIF.\n",
      "Iter 6: Dropped gaze_mky_view_angle_l_1 (VIF: 18.2)\n",
      "0 out of 117 features are processed for VIF.\n",
      "10 out of 117 features are processed for VIF.\n",
      "20 out of 117 features are processed for VIF.\n",
      "30 out of 117 features are processed for VIF.\n",
      "40 out of 117 features are processed for VIF.\n",
      "50 out of 117 features are processed for VIF.\n",
      "60 out of 117 features are processed for VIF.\n",
      "70 out of 117 features are processed for VIF.\n",
      "80 out of 117 features are processed for VIF.\n",
      "90 out of 117 features are processed for VIF.\n",
      "100 out of 117 features are processed for VIF.\n",
      "110 out of 117 features are processed for VIF.\n",
      "Iter 7: Dropped LDz_-2 (VIF: 14.8)\n",
      "0 out of 116 features are processed for VIF.\n",
      "10 out of 116 features are processed for VIF.\n",
      "20 out of 116 features are processed for VIF.\n",
      "30 out of 116 features are processed for VIF.\n",
      "40 out of 116 features are processed for VIF.\n",
      "50 out of 116 features are processed for VIF.\n",
      "60 out of 116 features are processed for VIF.\n",
      "70 out of 116 features are processed for VIF.\n",
      "80 out of 116 features are processed for VIF.\n",
      "90 out of 116 features are processed for VIF.\n",
      "100 out of 116 features are processed for VIF.\n",
      "110 out of 116 features are processed for VIF.\n",
      "Iter 8: Dropped gaze_mky_view_angle_l_3 (VIF: 13.5)\n",
      "0 out of 115 features are processed for VIF.\n",
      "10 out of 115 features are processed for VIF.\n",
      "20 out of 115 features are processed for VIF.\n",
      "30 out of 115 features are processed for VIF.\n",
      "40 out of 115 features are processed for VIF.\n",
      "50 out of 115 features are processed for VIF.\n",
      "60 out of 115 features are processed for VIF.\n",
      "70 out of 115 features are processed for VIF.\n",
      "80 out of 115 features are processed for VIF.\n",
      "90 out of 115 features are processed for VIF.\n",
      "100 out of 115 features are processed for VIF.\n",
      "110 out of 115 features are processed for VIF.\n",
      "Iter 9: Dropped LDz_0 (VIF: 10.9)\n",
      "0 out of 114 features are processed for VIF.\n",
      "10 out of 114 features are processed for VIF.\n",
      "20 out of 114 features are processed for VIF.\n",
      "30 out of 114 features are processed for VIF.\n",
      "40 out of 114 features are processed for VIF.\n",
      "50 out of 114 features are processed for VIF.\n",
      "60 out of 114 features are processed for VIF.\n",
      "70 out of 114 features are processed for VIF.\n",
      "80 out of 114 features are processed for VIF.\n",
      "90 out of 114 features are processed for VIF.\n",
      "100 out of 114 features are processed for VIF.\n",
      "110 out of 114 features are processed for VIF.\n",
      "Iter 10: Dropped gaze_mky_view_angle_r_1 (VIF: 10.3)\n",
      "0 out of 113 features are processed for VIF.\n",
      "10 out of 113 features are processed for VIF.\n",
      "20 out of 113 features are processed for VIF.\n",
      "30 out of 113 features are processed for VIF.\n",
      "40 out of 113 features are processed for VIF.\n",
      "50 out of 113 features are processed for VIF.\n",
      "60 out of 113 features are processed for VIF.\n",
      "70 out of 113 features are processed for VIF.\n",
      "80 out of 113 features are processed for VIF.\n",
      "90 out of 113 features are processed for VIF.\n",
      "100 out of 113 features are processed for VIF.\n",
      "110 out of 113 features are processed for VIF.\n",
      "Iter 11: Dropped valid_view_point_r_-5 (VIF: 10.0)\n",
      "0 out of 112 features are processed for VIF.\n",
      "10 out of 112 features are processed for VIF.\n",
      "20 out of 112 features are processed for VIF.\n",
      "30 out of 112 features are processed for VIF.\n",
      "40 out of 112 features are processed for VIF.\n",
      "50 out of 112 features are processed for VIF.\n",
      "60 out of 112 features are processed for VIF.\n",
      "70 out of 112 features are processed for VIF.\n",
      "80 out of 112 features are processed for VIF.\n",
      "90 out of 112 features are processed for VIF.\n",
      "100 out of 112 features are processed for VIF.\n",
      "110 out of 112 features are processed for VIF.\n",
      "Iter 12: Dropped gaze_mky_view_angle_r_-3 (VIF: 8.7)\n",
      "0 out of 111 features are processed for VIF.\n",
      "10 out of 111 features are processed for VIF.\n",
      "20 out of 111 features are processed for VIF.\n",
      "30 out of 111 features are processed for VIF.\n",
      "40 out of 111 features are processed for VIF.\n",
      "50 out of 111 features are processed for VIF.\n",
      "60 out of 111 features are processed for VIF.\n",
      "70 out of 111 features are processed for VIF.\n",
      "80 out of 111 features are processed for VIF.\n",
      "90 out of 111 features are processed for VIF.\n",
      "100 out of 111 features are processed for VIF.\n",
      "110 out of 111 features are processed for VIF.\n",
      "Iter 13: Dropped gaze_mky_view_angle_l_-5 (VIF: 8.5)\n",
      "0 out of 110 features are processed for VIF.\n",
      "10 out of 110 features are processed for VIF.\n",
      "20 out of 110 features are processed for VIF.\n",
      "30 out of 110 features are processed for VIF.\n",
      "40 out of 110 features are processed for VIF.\n",
      "50 out of 110 features are processed for VIF.\n",
      "60 out of 110 features are processed for VIF.\n",
      "70 out of 110 features are processed for VIF.\n",
      "80 out of 110 features are processed for VIF.\n",
      "90 out of 110 features are processed for VIF.\n",
      "100 out of 110 features are processed for VIF.\n",
      "Iter 14: Dropped gaze_mky_view_angle_r_3 (VIF: 8.2)\n",
      "0 out of 109 features are processed for VIF.\n",
      "10 out of 109 features are processed for VIF.\n",
      "20 out of 109 features are processed for VIF.\n",
      "30 out of 109 features are processed for VIF.\n",
      "40 out of 109 features are processed for VIF.\n",
      "50 out of 109 features are processed for VIF.\n",
      "60 out of 109 features are processed for VIF.\n",
      "70 out of 109 features are processed for VIF.\n",
      "80 out of 109 features are processed for VIF.\n",
      "90 out of 109 features are processed for VIF.\n",
      "100 out of 109 features are processed for VIF.\n",
      "Iter 15: Dropped gaze_world_x_r_-1 (VIF: 7.8)\n",
      "0 out of 108 features are processed for VIF.\n",
      "10 out of 108 features are processed for VIF.\n",
      "20 out of 108 features are processed for VIF.\n",
      "30 out of 108 features are processed for VIF.\n",
      "40 out of 108 features are processed for VIF.\n",
      "50 out of 108 features are processed for VIF.\n",
      "60 out of 108 features are processed for VIF.\n",
      "70 out of 108 features are processed for VIF.\n",
      "80 out of 108 features are processed for VIF.\n",
      "90 out of 108 features are processed for VIF.\n",
      "100 out of 108 features are processed for VIF.\n",
      "Iter 16: Dropped RDz_-1 (VIF: 6.7)\n",
      "0 out of 107 features are processed for VIF.\n",
      "10 out of 107 features are processed for VIF.\n",
      "20 out of 107 features are processed for VIF.\n",
      "30 out of 107 features are processed for VIF.\n",
      "40 out of 107 features are processed for VIF.\n",
      "50 out of 107 features are processed for VIF.\n",
      "60 out of 107 features are processed for VIF.\n",
      "70 out of 107 features are processed for VIF.\n",
      "80 out of 107 features are processed for VIF.\n",
      "90 out of 107 features are processed for VIF.\n",
      "100 out of 107 features are processed for VIF.\n",
      "Iter 17: Dropped gaze_world_x_r_0 (VIF: 6.6)\n",
      "0 out of 106 features are processed for VIF.\n",
      "10 out of 106 features are processed for VIF.\n",
      "20 out of 106 features are processed for VIF.\n",
      "30 out of 106 features are processed for VIF.\n",
      "40 out of 106 features are processed for VIF.\n",
      "50 out of 106 features are processed for VIF.\n",
      "60 out of 106 features are processed for VIF.\n",
      "70 out of 106 features are processed for VIF.\n",
      "80 out of 106 features are processed for VIF.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# dec.reduce_x_var_lags()  # currently not needed bc of the low correlations between neural clusters\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_y_var_lags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_vif_by_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/decode_targets/decode_target_class.py:161\u001b[39m, in \u001b[36mDecodeTargetClass.reduce_y_var_lags\u001b[39m\u001b[34m(self, corr_threshold_for_lags_of_a_feature, vif_threshold_for_initial_subset, vif_threshold, verbose, filter_corr_by_feature, filter_corr_by_subsets, filter_corr_by_all_columns, filter_vif_by_feature, filter_vif_by_subsets, filter_vif_by_all_columns)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce_y_var_lags\u001b[39m(\u001b[38;5;28mself\u001b[39m, corr_threshold_for_lags_of_a_feature=\u001b[32m0.85\u001b[39m,\n\u001b[32m    150\u001b[39m                       vif_threshold_for_initial_subset=\u001b[32m5\u001b[39m,\n\u001b[32m    151\u001b[39m                       vif_threshold=\u001b[32m5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m                       filter_vif_by_all_columns=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    159\u001b[39m                       ):\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_y_var_lags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorr_threshold_for_lags_of_a_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorr_threshold_for_lags_of_a_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mvif_threshold_for_initial_subset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold_for_initial_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfilter_corr_by_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_corr_by_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfilter_corr_by_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_corr_by_subsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfilter_corr_by_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_corr_by_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfilter_vif_by_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfilter_vif_by_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_subsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfilter_vif_by_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_all_columns\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/neural_vs_behavioral/neural_vs_behavioral_class.py:130\u001b[39m, in \u001b[36mNeuralVsBehavioralClass.reduce_y_var_lags\u001b[39m\u001b[34m(self, corr_threshold_for_lags_of_a_feature, vif_threshold_for_initial_subset, vif_threshold, verbose, filter_corr_by_feature, filter_corr_by_subsets, filter_corr_by_all_columns, filter_vif_by_feature, filter_vif_by_subsets, filter_vif_by_all_columns)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce_y_var_lags\u001b[39m(\u001b[38;5;28mself\u001b[39m, corr_threshold_for_lags_of_a_feature=\u001b[32m0.85\u001b[39m,\n\u001b[32m    112\u001b[39m                       vif_threshold_for_initial_subset=\u001b[32m5\u001b[39m, vif_threshold=\u001b[32m5\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    113\u001b[39m                       filter_corr_by_feature=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# Call the function to iteratively drop lags with high correlation for each feature\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28mself\u001b[39m.y_var_lags_reduced_corr = drop_high_corr_vars.drop_columns_with_high_corr(\u001b[38;5;28mself\u001b[39m.y_var_lags,\n\u001b[32m    123\u001b[39m                                                                                    corr_threshold_for_lags=corr_threshold_for_lags_of_a_feature,\n\u001b[32m    124\u001b[39m                                                                                    verbose=verbose,\n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m                                                                                    filter_by_all_columns=filter_corr_by_all_columns,\n\u001b[32m    128\u001b[39m                                                                                    get_column_subsets_func=\u001b[38;5;28mself\u001b[39m.get_subset_key_words_and_all_column_subsets)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28mself\u001b[39m.y_var_lags_reduced = \u001b[43mdrop_high_vif_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop_columns_with_high_vif\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_var_lags_reduced_corr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mvif_threshold_for_initial_subset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold_for_initial_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mfilter_by_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mfilter_by_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_subsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mfilter_by_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_vif_by_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mget_column_subsets_func\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_subset_key_words_and_all_column_subsets\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:53\u001b[39m, in \u001b[36mdrop_columns_with_high_vif\u001b[39m\u001b[34m(y_var_lags, vif_threshold, vif_threshold_for_initial_subset, verbose, filter_by_feature, filter_by_subsets, filter_by_all_columns, get_column_subsets_func)\u001b[39m\n\u001b[32m     51\u001b[39m         subset_key_words = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     52\u001b[39m         all_column_subsets = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     y_var_lags_reduced, columns_dropped = \u001b[43mfilter_specific_subset_of_y_var_lags_by_vif\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_var_lags_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_column_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_column_subsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filter_by_all_columns:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m====================Dropping columns with the highest VIF in an iterative manner====================\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:203\u001b[39m, in \u001b[36mfilter_specific_subset_of_y_var_lags_by_vif\u001b[39m\u001b[34m(y_var_lags, vif_threshold, verbose, subset_key_words, all_column_subsets)\u001b[39m\n\u001b[32m    185\u001b[39m     subset_key_words = [\u001b[33m'\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mspeed_or_ddv\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLD_or_RD_or_gaze\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    186\u001b[39m                         \u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mangle\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfrozen\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdummy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnum_or_any_or_rate\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    188\u001b[39m     all_column_subsets = [\n\u001b[32m    189\u001b[39m         [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m y_var_lags.columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col],\n\u001b[32m    190\u001b[39m         [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m y_var_lags.columns \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33many\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mrate\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col)],\n\u001b[32m    201\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m df_reduced, columns_dropped = \u001b[43mdrop_high_corr_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter_subsets_of_var_df_lags_by_corr_or_vif\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_var_lags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_vif_instead_of_corr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_key_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mall_column_subsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_column_subsets\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df_reduced, columns_dropped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_corr_vars.py:214\u001b[39m, in \u001b[36mfilter_subsets_of_var_df_lags_by_corr_or_vif\u001b[39m\u001b[34m(var_df_lags, use_vif_instead_of_corr, corr_threshold, vif_threshold, verbose, subset_key_words, all_column_subsets)\u001b[39m\n\u001b[32m    212\u001b[39m     temp_columns_to_drop = high_corr_pair_df[\u001b[33m'\u001b[39m\u001b[33mvar_1\u001b[39m\u001b[33m'\u001b[39m].values.tolist()\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     _, temp_columns_to_drop, _ = \u001b[43mdrop_high_vif_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43miteratively_drop_column_w_highest_vif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_df_lags\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_subset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m                                                                                          \u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvif_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp_columns_to_drop) > \u001b[32m0\u001b[39m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# get unique columns dropped\u001b[39;00m\n\u001b[32m    219\u001b[39m     temp_columns_to_drop = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(temp_columns_to_drop))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:133\u001b[39m, in \u001b[36miteratively_drop_column_w_highest_vif\u001b[39m\u001b[34m(df, vif_threshold, verbose)\u001b[39m\n\u001b[32m    131\u001b[39m     df.drop(columns=column_to_drop, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    132\u001b[39m     columns_dropped.append(column_to_drop)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     vif_df = \u001b[43mget_vif_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m final_vif_df = vif_df\n\u001b[32m    135\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    136\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAfter iterative dropping, the column with the highest VIF of the dataframe or subset is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvif_df[\u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m].values[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with VIF \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvif_df[\u001b[33m\"\u001b[39m\u001b[33mvif\u001b[39m\u001b[33m\"\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/model_neural_data/drop_high_vif_vars.py:83\u001b[39m, in \u001b[36mget_vif_df\u001b[39m\u001b[34m(var_df, verbose)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(var_df.shape[\u001b[32m1\u001b[39m]):\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# check for RuntimeWarning; print the column name that causes the warning\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         vif_values.append(\u001b[43mvariance_inflation_factor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvar_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     86\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRuntimeWarning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:196\u001b[39m, in \u001b[36mvariance_inflation_factor\u001b[39m\u001b[34m(exog, exog_idx)\u001b[39m\n\u001b[32m    194\u001b[39m mask = np.arange(k_vars) != exog_idx\n\u001b[32m    195\u001b[39m x_noti = exog[:, mask]\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m r_squared_i = \u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_noti\u001b[49m\u001b[43m)\u001b[49m.fit().rsquared\n\u001b[32m    197\u001b[39m vif = \u001b[32m1.\u001b[39m / (\u001b[32m1.\u001b[39m - r_squared_i)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vif\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:921\u001b[39m, in \u001b[36mOLS.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    919\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mAn exception will be raised in the next version.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    920\u001b[39m     warnings.warn(msg, ValueWarning)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_keys:\n\u001b[32m    924\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_keys.remove(\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:746\u001b[39m, in \u001b[36mWLS.__init__\u001b[39m\u001b[34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     weights = weights.squeeze()\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m nobs = \u001b[38;5;28mself\u001b[39m.exog.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    749\u001b[39m weights = \u001b[38;5;28mself\u001b[39m.weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:200\u001b[39m, in \u001b[36mRegressionModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mself\u001b[39m.pinv_wexog: Float64Array | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_attr.extend([\u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwendog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/model.py:270\u001b[39m, in \u001b[36mLikelihoodModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/model.py:95\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m missing = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     94\u001b[39m hasconst = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mhasconst\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                              \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[38;5;28mself\u001b[39m.data.k_constant\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m.exog = \u001b[38;5;28mself\u001b[39m.data.exog\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/model.py:135\u001b[39m, in \u001b[36mModel._handle_data\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     data = \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/data.py:675\u001b[39m, in \u001b[36mhandle_data\u001b[39m\u001b[34m(endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    672\u001b[39m     exog = np.asarray(exog)\n\u001b[32m    674\u001b[39m klass = handle_data_class_factory(endog, exog)\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m             \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/data.py:88\u001b[39m, in \u001b[36mModelData.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.const_idx = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m._check_integrity()\n\u001b[32m     90\u001b[39m \u001b[38;5;28mself\u001b[39m._cache = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/statsmodels/base/data.py:178\u001b[39m, in \u001b[36mModelData._handle_constant\u001b[39m\u001b[34m(self, hasconst)\u001b[39m\n\u001b[32m    175\u001b[39m augmented_exog = np.column_stack(\n\u001b[32m    176\u001b[39m             (np.ones(\u001b[38;5;28mself\u001b[39m.exog.shape[\u001b[32m0\u001b[39m]), \u001b[38;5;28mself\u001b[39m.exog))\n\u001b[32m    177\u001b[39m rank_augm = np.linalg.matrix_rank(augmented_exog)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m rank_orig = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[38;5;28mint\u001b[39m(rank_orig == rank_augm)\n\u001b[32m    180\u001b[39m \u001b[38;5;28mself\u001b[39m.const_idx = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/numpy/linalg/linalg.py:1922\u001b[39m, in \u001b[36mmatrix_rank\u001b[39m\u001b[34m(A, tol, hermitian)\u001b[39m\n\u001b[32m   1920\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.ndim < \u001b[32m2\u001b[39m:\n\u001b[32m   1921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(A==\u001b[32m0\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1922\u001b[39m S = \u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhermitian\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhermitian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1924\u001b[39m     tol = S.max(axis=-\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m) * \u001b[38;5;28mmax\u001b[39m(A.shape[-\u001b[32m2\u001b[39m:]) * finfo(S.dtype).eps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/ff_venv2/lib/python3.11/site-packages/numpy/linalg/linalg.py:1693\u001b[39m, in \u001b[36msvd\u001b[39m\u001b[34m(a, full_matrices, compute_uv, hermitian)\u001b[39m\n\u001b[32m   1690\u001b[39m     gufunc = _umath_linalg.svd_n\n\u001b[32m   1692\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mD->d\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33md->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1693\u001b[39m s = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1694\u001b[39m s = s.astype(_realType(result_t), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m s\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# dec.reduce_x_var_lags()  # currently not needed bc of the low correlations between neural clusters\n",
    "dec.reduce_y_var_lags(filter_vif_by_subsets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 220 features are processed for VIF.\n",
      "10 out of 220 features are processed for VIF.\n",
      "20 out of 220 features are processed for VIF.\n",
      "30 out of 220 features are processed for VIF.\n",
      "40 out of 220 features are processed for VIF.\n",
      "50 out of 220 features are processed for VIF.\n",
      "60 out of 220 features are processed for VIF.\n",
      "70 out of 220 features are processed for VIF.\n",
      "80 out of 220 features are processed for VIF.\n",
      "90 out of 220 features are processed for VIF.\n",
      "100 out of 220 features are processed for VIF.\n",
      "110 out of 220 features are processed for VIF.\n",
      "120 out of 220 features are processed for VIF.\n",
      "130 out of 220 features are processed for VIF.\n",
      "140 out of 220 features are processed for VIF.\n",
      "150 out of 220 features are processed for VIF.\n",
      "160 out of 220 features are processed for VIF.\n",
      "170 out of 220 features are processed for VIF.\n",
      "180 out of 220 features are processed for VIF.\n",
      "190 out of 220 features are processed for VIF.\n",
      "200 out of 220 features are processed for VIF.\n",
      "210 out of 220 features are processed for VIF.\n"
     ]
    }
   ],
   "source": [
    "vif_df = drop_high_vif_vars.get_vif_df(dec.y_var_lags_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>vif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>gaze_mky_view_angle_l_-4</td>\n",
       "      <td>29.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>monkey_speeddummy_5</td>\n",
       "      <td>26.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>gaze_mky_view_angle_l_2</td>\n",
       "      <td>26.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>gaze_mky_view_angle_l_3</td>\n",
       "      <td>25.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>LDz_-4</td>\n",
       "      <td>24.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>catching_ff_1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>catching_ff_5</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>catching_ff_4</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>catching_ff_2</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>catching_ff_3</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature      vif\n",
       "129  gaze_mky_view_angle_l_-4 29.40000\n",
       "185       monkey_speeddummy_5 26.80000\n",
       "75    gaze_mky_view_angle_l_2 26.40000\n",
       "111   gaze_mky_view_angle_l_3 25.50000\n",
       "125                    LDz_-4 24.40000\n",
       "..                        ...      ...\n",
       "45              catching_ff_1  1.00000\n",
       "199             catching_ff_5  1.00000\n",
       "150             catching_ff_4  1.00000\n",
       "78              catching_ff_2  1.00000\n",
       "115             catching_ff_3  1.00000\n",
       "\n",
       "[220 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# behav features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find set difference between dec.behav_data_all.columns and dec.behav_data.columns\n",
    "diff_columns = set(dec.behav_data_all.columns) - set(dec.behav_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bin_end_time',\n",
       " 'bin_start_time',\n",
       " 'crossing_boundary',\n",
       " 'cum_distance_when_target_last_seen',\n",
       " 'current_target_caught_time',\n",
       " 'dt',\n",
       " 'gaze_mky_view_angle',\n",
       " 'gaze_mky_view_x',\n",
       " 'gaze_mky_view_y',\n",
       " 'gaze_world_x',\n",
       " 'gaze_world_y',\n",
       " 'last_target_caught_time',\n",
       " 'monkey_angle_target_last_seen',\n",
       " 'monkey_dw_smr',\n",
       " 'monkey_speed_smr',\n",
       " 'monkey_x_smr',\n",
       " 'monkey_x_target_last_seen',\n",
       " 'monkey_y_smr',\n",
       " 'monkey_y_target_last_seen',\n",
       " 'target_has_disappeared_for_last_time_dummy',\n",
       " 'target_visible_dummy',\n",
       " 'trial',\n",
       " 'turning_right',\n",
       " 'valid_view_point'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check result of reducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also check correlations between x vars without lags\n",
    "high_corr_pair_df, top_n_corr_df = drop_high_corr_vars.get_pairs_of_columns_w_high_corr(\n",
    "            dec.x_var, corr_threshold=0.8)\n",
    "top_n_corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression (didn't modify yet)\n",
    "\n",
    "Regressing the behavioral variables individually (as y_var) against all neural activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## put results in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec.make_or_retrieve_y_var_lr_resault_df(exists_ok=True)\n",
    "dec.y_var_lr_result_df = neural_data_modeling.get_y_var_lr_result_df(\n",
    "                dec.x_var_lags_reduced, dec.y_var)\n",
    "dec.y_var_lr_result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  plot all neural clusters vs one behavioral var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop existing columns involving bin (most likely there's only one or zero after being reduced, because different lags of bins can have very high correlations)\n",
    "bin_cols = [col for col in dec.y_var_lags_reduced.columns if 'bin' in col]\n",
    "dec.y_var_lags_reduced.drop(columns=bin_cols, inplace=True)\n",
    "\n",
    "# then we add the variable bin (so that only the 0 lag is used)\n",
    "dec.y_var_lags_reduced['bin'] = dec.y_var_lags['bin_0'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# conduct linear regression on X and y\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "bins_to_plot = dec.y_var_lags_reduced['bin'].values\n",
    "for i, column in enumerate(dec.y_var_lags_reduced.columns):\n",
    "\n",
    "    plot_neural_data.plot_regression(dec.y_var_lags_reduced, column, dec.x_var_lags_reduced, bins_to_plot=bins_to_plot, min_r_squared_to_plot=0.3)\n",
    "    # if i == 3:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  plot one neural cluster vs one behavioral var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one neural cluster against one behavioral variable\n",
    "cluster_num, behavioral_column = 6, 'monkey_speed'\n",
    "bins_to_plot = range(1000, 1200)\n",
    "x_values = dec.binned_spikes_df.loc[bins_to_plot, f'unit_{cluster_num}'].values\n",
    "y_values = dec.pursuit_data[behavioral_column][bins_to_plot]\n",
    "reg = LinearRegression().fit(x_values.reshape(-1, 1), y_values)\n",
    "\n",
    "plt.scatter(x_values, y_values, color='blue', s=1)\n",
    "plt.plot(x_values, reg.predict(x_values.reshape(-1, 1)), color='red', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA\n",
    "\n",
    "https://medium.com/@pozdrawiamzuzanna/canonical-correlation-analysis-simple-explanation-and-python-example-a5b8e97648d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No lagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_no_lag = cca_class.CCAclass(X1=dec.x_var, X2=dec.y_var_reduced, lagging_included=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_no_lag.conduct_cca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_lags = cca_class.CCAclass(X1=dec.x_var_lags, X2=dec.y_var_lags_reduced, lagging_included=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var_lags_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_lags.conduct_cca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare lag vs no lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canon_df = pd.DataFrame(cca_no_lag.canon_corr, columns = ['no_lag'])\n",
    "canon_df[f'lag_{dec.max_lag_number}'] = cca_lags.canon_corr\n",
    "canon_df['component'] = [f'CC {i+1}' for i in range(cca_lags.n_components)]\n",
    "# convert canon_df to long format\n",
    "canon_df_long = pd.melt(canon_df, id_vars=['component'], var_name='lag', value_name='canon_coeff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sns bar plot on canon_df_long\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='component', y='canon_coeff', data=canon_df_long, hue='lag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cca_inst (choose one between lags and no lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose lags\n",
    "cca_inst = cca_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose no lag\n",
    "cca_inst = cca_no_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X1', squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X2', squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## squared loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_loadings(X1_or_X2='X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## abs weights ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights(X1_or_X2='X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot real weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights(abs_value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_ranked_weights(X1_or_X2='X2', abs_value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distribution of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.X2_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_sc_df = pd.DataFrame(cca_inst.X2_sc, columns = cca_inst.X2.columns)\n",
    "X2_sc_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X2_sc_df.columns:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    sns.boxplot(X2_sc_df[column], orient='h')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heatmap of weights\n",
    "raw canonical coefficients are interpreted in a manner analogous to interpreting regression coefficients. For example: a one unit increase in reading leads to a .0446 decrease in the first canonical variate of set 2 when all of the other variables are held constant (in some other data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_df = cca_inst.X2_weight_df.copy()\n",
    "weight_df = weight_df.set_index('feature').drop(columns='feature_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 25))\n",
    "sns.heatmap(weight_df.iloc[:20, :10], cmap='coolwarm', annot=True, linewidths=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, test1, train2, test2 = train_test_split(cca_inst.X1_sc, cca_inst.X2_sc, test_size=0.3, random_state=42)\n",
    "# use training and testing set\n",
    "nComponents = 10\n",
    "cca2 = rcca.CCA(kernelcca = False, reg = 0., numCC = nComponents)\n",
    "cca2.train([train1, train2])\n",
    "testcorrs = cca2.validate([test1, test2])\n",
    "testcorrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca2.compute_ev([test1, test2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_cca = CanCorr(cca_inst.X1_sc, cca_inst.X2_sc)\n",
    "print(stats_cca.corr_test().summary())\n",
    "neural_data_modeling.print_weights('X', stats_cca.x_cancoef)\n",
    "neural_data_modeling.print_weights('Z', stats_cca.y_cancoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGAM (unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorize variables\n",
    "dec.y_var_reduced.columns\n",
    "temporal_vars = ['time_rel_to_stop',\n",
    " 'time_when_nxt_ff_first_seen_rel_to_stop',\n",
    " 'time_when_cur_ff_first_seen_rel_to_stop',\n",
    " 'time_when_nxt_ff_last_seen_rel_to_stop',\n",
    " 'time_when_cur_ff_last_seen_rel_to_stop',\n",
    " ]\n",
    "\n",
    "spatial_vars = [x for x in dec.y_var_reduced.columns if x not in temporal_vars]\n",
    "spatial_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sparsity of neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.binned_spikes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect neural data\n",
    "\n",
    "bins = dec.binned_spikes_df\n",
    "\n",
    "# Calculate percentage of non-zero rows for each column\n",
    "non_zero_percentages = (bins != 0).mean() * 100\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "non_zero_df = pd.DataFrame({\n",
    "    'Column': non_zero_percentages.index,\n",
    "    'Percent_Non_Zero': non_zero_percentages.values\n",
    "})\n",
    "\n",
    "# Sort by percentage in descending order\n",
    "non_zero_df = non_zero_df.sort_values('Percent_Non_Zero', ascending=False)\n",
    "\n",
    "print(\"Percentage of non-zero values in each column:\")\n",
    "print(non_zero_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins.drop(columns='bin').mean(axis=1).describe()\n",
    "\n",
    "# plot the percentile of values of mean firing rates across neurons at each time bin\n",
    "mean_rates = bins.drop(columns='bin').mean(axis=1)\n",
    "\n",
    "# Calculate percentiles from 0 to 100\n",
    "percentiles = np.arange(0, 101, 1)\n",
    "percentile_values = np.percentile(mean_rates, percentiles)\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(percentiles, percentile_values)\n",
    "plt.xlabel('Percentile')\n",
    "plt.ylabel('Mean Firing Rate')\n",
    "plt.title('Distribution of Mean Firing Rates Across Neurons')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y var (behavioral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var_vif = drop_high_vif_vars.get_vif_df(dec.y_var)\n",
    "print(y_var_vif.head(8))\n",
    "\n",
    "# calculate the correlation coefficient among the columns with VIF > 5\n",
    "# specific_columns = vif_df[vif_df['vif'] > 5].feature.values\n",
    "specific_columns = y_var_vif.feature.values[:10]\n",
    "corr_coeff = dec.y_var[specific_columns].corr()\n",
    "#plt.figure(figsize = (6, 6))\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.heatmap(corr_coeff, cmap='coolwarm', annot=True, linewidths=1, vmin=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try y_var_reduced\n",
    "\n",
    "y_var_vif = drop_high_vif_vars.get_vif_df(dec.y_var_reduced)\n",
    "print(y_var_vif.head(8))\n",
    "\n",
    "# calculate the correlation coefficient among the columns with VIF > 5\n",
    "# specific_columns = vif_df[vif_df['vif'] > 5].feature.values\n",
    "specific_columns = y_var_vif.feature.values[:10]\n",
    "corr_coeff = dec.y_var[specific_columns].corr()\n",
    "#plt.figure(figsize = (6, 6))\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.heatmap(corr_coeff, cmap='coolwarm', annot=True, linewidths=1, vmin=-1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot trial segments in pursuit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.matplotlib_tools import plot_trials,\n",
    "dec.make_PlotTrials_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]                     \n",
    "\n",
    "max_plot_to_make = 2\n",
    "plot_counter = 0\n",
    "\n",
    "for index, row in dec.single_vis_target_df.iloc[2:].iterrows():\n",
    "\n",
    "    duration = [row['last_vis_time'], row['ff_caught_time']]\n",
    "\n",
    "    returned_info = plot_trials.PlotTrials(\n",
    "                duration, \n",
    "                *dec.PlotTrials_args,  \n",
    "                adjust_xy_limits=True,       \n",
    "                minimal_margin=50,\n",
    "                show_reward_boundary=True,\n",
    "                show_alive_fireflies=False,\n",
    "                show_visible_fireflies=True,\n",
    "                show_in_memory_fireflies=True,\n",
    "                show_believed_target_positions=True,\n",
    "                )\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plot_counter += 1\n",
    "    if plot_counter >= max_plot_to_make:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check target_rel_x and y\n",
    "(The look correct after checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pursuit_sub = dec.pursuit_data.loc[dec.pursuit_data['target_index']==65].copy()\n",
    "pursuit_sub['target_angle_deg'] = pursuit_sub['target_angle'] * 180/pi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pursuit_sub[['point_index', 'target_angle_deg', 'target_distance', 'target_rel_x', 'target_rel_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows, na_cols = general_utils.find_rows_with_na(dec.y_var)\n",
    "duplicate_rows = general_utils.find_duplicate_rows(dec.y_var, column_subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See sizes of biggest variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "\n",
    "sizes = []\n",
    "for attr in dir(dec):\n",
    "    if attr.startswith('__') and attr.endswith('__'):\n",
    "        continue  # skip dunder attributes\n",
    "    try:\n",
    "        val = getattr(dec, attr)\n",
    "        size = asizeof.asizeof(val)\n",
    "        sizes.append((attr, size))\n",
    "    except Exception:\n",
    "        pass  # ignore any errors\n",
    "\n",
    "# Sort and display largest attributes in MB\n",
    "for name, size in sorted(sizes, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{name}: {size / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import warnings\n",
    "from pympler import asizeof\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "filtered = {\n",
    "    k: v for k, v in globals().items()\n",
    "    if not isinstance(v, types.ModuleType)\n",
    "}\n",
    "\n",
    "sizes = []\n",
    "for name, val in filtered.items():\n",
    "    try:\n",
    "        sizes.append((name, asizeof.asizeof(val)))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for name, size in sorted(sizes, key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(f\"{name}: {size / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more columns (possibly get in the future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get also get: (but to be honest, it doesn't make that much sense to get them....so let's skip for now.)\n",
    "'distance traversed since target last visible',\n",
    "'d angle since target last visible', 'target_at_right',\n",
    "'time_till_capture', 'time from last visible to capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there might be multicollinearity. For example, duration from last visible to capture = time since target last visible + time till capture\n",
    "\n",
    "Similarly, target angle = target angle last seen frozen - d angle since target last visible\n",
    "\n",
    "(For distance it's not exactly the same because of the difference between distance and distance traversed, but it's still similar)\n",
    "\n",
    "The multicollinearity is fine in linear regression (when each feature here is a y var), but need to be dealt with in cca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should i actually align each section, as if they are trials???\n",
    "maybe i can try both that and continuous time... both can shed light on different behavioral variables\n",
    "but for aligning trials, it may require alignment or warping since trial durations vary.\n",
    "\n",
    "btw, what does it mean stitch data?\n",
    "\n",
    "also, what does it look like to use RNN to model it?\n",
    "I thought about the paper that Noah presented on\n",
    "\n",
    "\n",
    "btw.......IME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why ratio of bin/target_index approaches constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_lengths = dec.pursuit_data[['target_index', 'bin']].groupby('target_index').count()\n",
    "trial_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = dec.y_var_reduced[['time', 'bin', 'target_index']]\n",
    "sub['factor'] = dec.y_var_reduced['bin']/dec.y_var_reduced['target_index']\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.diff(dec.ff_caught_T_sorted), bins=30)\n",
    "plt.xlabel('Time difference')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of time differences between caught events')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.ff_caught_T_sorted/np.arange(len(dec.ff_caught_T_sorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compared with neural_data_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = neural_vs_behavioral_class.NeuralVsBehavioralClass(raw_data_folder_path=raw_data_folder_path)\n",
    "dec.streamline_preparing_neural_and_behavioral_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.final_behavioral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.y_var_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in dec.y_var.columns if col not in dec.y_var_reduced.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in dec.y_var_reduced.columns if col not in dec.y_var.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check gpfa's binned spikes vs my own binned spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_segs_df = fit_gpfa_utils.make_spike_segs_df(dec.spike_df, dec.single_vis_target_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get binned spikes (seqs) from gpfa_utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_index = 9\n",
    "cluster_index = 12\n",
    "seg = dec.spiketrain_corr_segs[seg_index]\n",
    "cluster = dec.spike_segs_df.cluster.unique()[cluster_index]\n",
    "\n",
    "spiketrain = dec.spiketrains[seg_index][cluster_index]\n",
    "seqs = gpfa_util.get_seqs([spiketrain], dec.bin_width_w_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take out my own binned spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sub = dec.pursuit_data_all[dec.pursuit_data_all['segment']==seg]\n",
    "binned_spikes_sub = dec.binned_spikes_df[dec.binned_spikes_df['bin'].isin(p_sub['bin'])].copy()\n",
    "binned_spikes_sub['bin'] = binned_spikes_sub.index\n",
    "binned_spikes_sub2 = binned_spikes_sub.merge(p_sub[['bin', 'time']], on='bin', how='left')\n",
    "binned_spikes_sub3 = binned_spikes_sub2[['bin', 'time', f'unit_{cluster}']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_length = len(binned_spikes_sub3)\n",
    "if dec.align_at_beginning:\n",
    "    binned_spikes_sub3['gpfa'] = seqs[0][1][0][trial_length:]\n",
    "else:\n",
    "    binned_spikes_sub3['gpfa'] = seqs[0][1][0][-trial_length:] # when getting latent dimension for neural data, [-trial_length:] was also used\n",
    "binned_spikes_sub3['same'] = binned_spikes_sub3[f'unit_{cluster}'] == binned_spikes_sub3['gpfa']\n",
    "binned_spikes_sub3[binned_spikes_sub3['same']!=True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find out why there are rows of NA in dec.y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows, na_cols = general_utils.find_rows_with_na(dec.y_var)\n",
    "duplicate_rows = general_utils.find_duplicate_rows(dec.y_var, column_subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.behav_data_all.loc[118189:118195, ['bin', 'time', 'target_rel_x', 'target_rel_y','time_since_target_last_seen', 'target_last_seen_distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare old and new target df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df_ori = pd.read_csv('/Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/patterns_and_features/monkey_Schro/data_0416/target_df_ori.csv')\n",
    "df = target_df_ori[['target_index', 'point_index', 'time']].copy()\n",
    "for col in ['target_distance', 'time_since_target_last_seen']:\n",
    "    df[f'old_{col}'] = target_df_ori[col]   \n",
    "    df[f'new_{col}'] = dec.target_df[col]  \n",
    "\n",
    "df['old_target_last_seen_distance'] = target_df_ori['target_last_seen_distance_frozen']\n",
    "df['new_target_last_seen_distance'] = dec.target_df['target_last_seen_distance']\n",
    "\n",
    "df2 = df.loc[10068:]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[df2['point_index']>= 139910]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "139913"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
