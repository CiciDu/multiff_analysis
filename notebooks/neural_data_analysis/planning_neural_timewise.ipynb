{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "if Path.cwd().parts[-1] != 'Multifirefly-Project':\n",
    "    if Path.cwd().parts[-1] != 'notebooks':\n",
    "        os.chdir('..')\n",
    "    from add_path import find_path\n",
    "    current_path = find_path()\n",
    "    os.chdir(current_path)\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.neural_analysis_by_topic.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.neural_analysis_by_topic.planning_and_neural import planning_neural_class, planning_neural_utils, planning_neural_helper_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from machine_learning.ml_methods import regression_utils, regression_utils2, ml_methods_class, classification_utils, ml_plotting_utils\n",
    "\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0416\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_y_var_lags = True\n",
    "planning_data_by_point_exists_ok = True\n",
    "y_data_exists_ok = True\n",
    "\n",
    "ref_point_mode='time after cur ff visible'\n",
    "ref_point_value=0.1\n",
    "normalize = False\n",
    "eliminate_outliers = False\n",
    "use_curv_to_ff_center = False\n",
    "curv_of_traj_mode = 'distance'\n",
    "window_for_curv_of_traj=[-25, 25]\n",
    "truncate_curv_of_traj_by_time_of_capture = True\n",
    "\n",
    "pn = planning_neural_class.PlanningAndNeural(raw_data_folder_path=raw_data_folder_path)\n",
    "pn.prep_data_to_analyze_planning(planning_data_by_point_exists_ok=planning_data_by_point_exists_ok)\n",
    "pn.planning_data_by_point, cols_to_drop = general_utils.drop_columns_with_many_nans(\n",
    "    pn.planning_data_by_point)\n",
    "pn.get_x_and_y_data_for_modeling(exists_ok=y_data_exists_ok, reduce_y_var_lags=reduce_y_var_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare dist of every var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pn.y_var[pn.y_var['whether_test'] == 1]\n",
    "ctr_data = pn.y_var[pn.y_var['whether_test'] == 0]\n",
    "\n",
    "for col in test_data.columns:\n",
    "#for col in ['target_index']:\n",
    "    # compare the distribution through histplot (by percentage) of the column in test_data and ctr_data\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(test_data[col].values, label='test', alpha=0.5, stat='percent', kde=True, bins=100)\n",
    "    sns.histplot(ctr_data[col].values, label='ctr', alpha=0.5, stat='percent', kde=True, bins=100)\n",
    "    plt.title(f'{col}', fontsize=14)\n",
    "    plt.xlabel(f'{col}', fontsize=12)\n",
    "    plt.ylabel('Percentage', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_utils.check_na_in_df(pn.planning_data_by_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## var's corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt_cols = [col for col in pn.y_var.columns if 'nxt' in col]\n",
    "corr_df = pn.y_var.corr()[nxt_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_plotting_utils.plot_correlation_heatmap(corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR: on all data together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just nxt ff vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['whether_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [col for col in pn.y_var.columns if 'nxt' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_or_control = 'control'\n",
    "\n",
    "if test_or_control == 'test':\n",
    "    x_var = pn.test_x_var_lags_reduced\n",
    "    y_var = pn.test_y_var\n",
    "elif test_or_control == 'control':\n",
    "    x_var = pn.control_x_var_lags_reduced\n",
    "    y_var = pn.control_y_var\n",
    "\n",
    "y_var_sub = y_var[columns_of_interest]\n",
    "# With x var lags\n",
    "y_var_lr_df = neural_data_modeling.get_y_var_lr_df(\n",
    "    x_var, y_var_sub, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot features from y_var_lr_df\n",
    "max_plot_number = 10\n",
    "count = 0\n",
    "bins_to_plot = range(len(y_var))\n",
    "\n",
    "for i, column in enumerate(y_var_lr_df.feature.values): # so that features are plotted in the order of correlation\n",
    "    if i >= max_plot_number:\n",
    "        break\n",
    "    plot_neural_data.plot_regression(y_var, column, x_var, bins_to_plot=None, min_r_squared_to_plot=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR: train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['whether_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(regression_utils2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_or_control = None\n",
    "\n",
    "if test_or_control == 'test':\n",
    "    x_var = pn.test_x_var_lags_reduced\n",
    "    y_var = pn.test_y_var\n",
    "elif test_or_control == 'control':\n",
    "    x_var = pn.control_x_var_lags_reduced\n",
    "    y_var = pn.control_y_var\n",
    "else:\n",
    "    x_var = pn.x_var_lags_reduced\n",
    "    y_var = pn.y_var\n",
    "\n",
    "X_train, X_test, y_train, y_test = planning_neural_utils.train_test_split_based_on_targets(x_var, y_var)\n",
    "\n",
    "# Basic usage with comprehensive metrics\n",
    "for y_var_column in columns_of_interest:\n",
    "    print('y_var_column:', y_var_column)\n",
    "    y_train_var =  y_train[y_var_column]   \n",
    "    y_test_var = y_test[y_var_column]\n",
    "\n",
    "    results, results_df, y_pred_train, y_pred_test = regression_utils2.regularized_regression(\n",
    "        X_train, y_train_var, X_test, y_test_var, method='ridge', alpha=1.0\n",
    "    )\n",
    "    print(results_df)\n",
    "\n",
    "    # # Create comprehensive report\n",
    "    report = regression_utils2.regression_metrics_report(\n",
    "        y_test_var, y_pred_test, model_name=\"Ridge Regression\", show_plots=True\n",
    "    )\n",
    "        \n",
    "    results, results_df = regression_utils2.compare_regularized_models(X_train, y_train_var, X_test, y_test_var, verbose=True, show_plots=False)\n",
    "    regression_utils2.print_model_comparison_summary(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split based on targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 'random_dummy'\n",
    "pn.y_var = planning_neural_utils.randomly_assign_random_dummy_based_on_targets(pn.y_var)\n",
    "columns_of_interest = ['random_dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['whether_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all nxt_ff variables\n",
    "columns_of_interest = [col for col in pn.y_var.columns if 'nxt' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all cur_ff variables\n",
    "columns_of_interest = [col for col in pn.y_var.columns if 'cur' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_or_control = None\n",
    "\n",
    "if test_or_control == 'test':\n",
    "    x_var = pn.test_x_var_lags_reduced\n",
    "    y_var = pn.test_y_var\n",
    "elif test_or_control == 'control':\n",
    "    x_var = pn.control_x_var_lags_reduced\n",
    "    y_var = pn.control_y_var\n",
    "else:\n",
    "    x_var = pn.x_var_lags_reduced\n",
    "    y_var = pn.y_var\n",
    "\n",
    "X_train, X_test, y_train, y_test = planning_neural_utils.train_test_split_based_on_targets(x_var, y_var)\n",
    "for y_var_column in columns_of_interest:\n",
    "    print('y_var_column:', y_var_column)\n",
    "    # if y_var_column is a dummy variable, use logistic regression\n",
    "    if y_train[y_var_column].nunique() == 1:\n",
    "        raise ValueError(f\"y_var_column {y_var_column} has only one unique value\")\n",
    "    elif y_train[y_var_column].nunique() == 2:\n",
    "        conf_matrix = classification_utils._use_logistic_regression(X_train , X_test, y_train[y_var_column], y_test[y_var_column])\n",
    "    else:\n",
    "        summary_df, y_pred, results, r2_test = regression_utils.use_linear_regression(\n",
    "            X_train, X_test, y_train[y_var_column], y_test[y_var_column], show_plot=True, y_var_name=y_var_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_or_control = 'test'\n",
    "\n",
    "if test_or_control == 'test':\n",
    "    x_var = pn.test_x_var_lags_reduced\n",
    "    y_var = pn.test_y_var\n",
    "elif test_or_control == 'control':\n",
    "    x_var = pn.control_x_var_lags_reduced\n",
    "    y_var = pn.control_y_var\n",
    "\n",
    "columns_of_interest = [col for col in pn.y_var.columns if 'nxt' in col]\n",
    "\n",
    "ml_inst = ml_methods_class.MlMethods()\n",
    "for y_var_column in columns_of_interest:\n",
    "    print('y_var_column:', y_var_column)\n",
    "    ml_inst.split_and_use_linear_regression(pn.x_var_lags_reduced, pn.y_var[[y_var_column]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA\n",
    "\n",
    "https://medium.com/@pozdrawiamzuzanna/canonical-correlation-analysis-simple-explanation-and-python-example-a5b8e97648d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conduct cca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_no_lag = cca_class.CCAclass(X1=pn.x_var_reduced, X2=pn.y_var_reduced, lagging_included=False)\n",
    "cca_no_lag.conduct_cca()\n",
    "\n",
    "cca_lags = cca_class.CCAclass(X1=pn.x_var_lags_reduced.drop(columns='bin', errors='ignore'), X2=pn.y_var_lags_reduced, lagging_included=True)\n",
    "# for all columns that end with _0, rename them to the column name without the _0\n",
    "cca_lags.X2.columns = cca_lags.X2.columns.str.replace('_0', '')\n",
    "cca_lags.conduct_cca()\n",
    "\n",
    "\n",
    "print(f'pn.x_var_lags.shape: {pn.x_var_lags.shape}')\n",
    "print(f'pn.y_var_lags_reduced.shape: {pn.y_var_lags_reduced.shape}')\n",
    "\n",
    "cca_inst = cca_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare lag vs no lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_load_df = pd.DataFrame(cca_no_lag.canon_corr, columns = ['no_lag'])\n",
    "can_load_df[f'with_lags'] = cca_lags.canon_corr\n",
    "can_load_df['component'] = [f'CC {i+1}' for i in range(cca_lags.n_components)]\n",
    "# convert can_load_df to long format\n",
    "can_load_df_long = pd.melt(can_load_df, id_vars=['component'], var_name='lag', value_name='canon_coeff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sns bar plot on can_load_df_long\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='component', y='canon_coeff', data=can_load_df_long, hue='lag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cca_inst (choose one between lags and no lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose no lag\n",
    "cca_inst = cca_no_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose lags\n",
    "cca_inst = cca_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.test_for_p_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap of loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X1 loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cca_inst.plot_X1_loadings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X2 loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ml_plotting_utils)\n",
    "reload(cca_plotting)\n",
    "reload(cca_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.y_var_lags_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_inst.plot_X2_loadings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical Variate scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components=range(1, 5)\n",
    "cca_plotting.plot_cca_component_scatter(cca_inst.X1_c, cca_inst.X2_c, components=components, show_y_eq_x=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform vars (e.g. use basis functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_no_lag.X2_tf_df = transform_vars.transform_behav_data(cca_no_lag.X2)\n",
    "cca_lags.X2_tf_df = transform_vars.transform_behav_data(cca_lags.X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If need to use the data\n",
    "cca_inst = cca_lags\n",
    "X1_df = cca_inst.X1_sc_df\n",
    "X2_df = cca_inst.X2_tf_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lags vs no lag & train vs test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cross_view_df, combined_can_load_df = cca_cv_utils.combine_cv_results(cca_no_lag, cca_lags, n_components=7, reg=0.1, n_splits=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-view X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'X1'\n",
    "# cross_view_sub = combined_cross_view_df[combined_cross_view_df['dataset'] == dataset_name]\n",
    "# cca_plot_lag_vs_no_lag.plot_cca_lag_vs_nolag_and_train_vs_test(cross_view_sub, dataset_name, mode='lag_offset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-view X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'X2'\n",
    "cross_view_sub = combined_cross_view_df[combined_cross_view_df['dataset'] == dataset_name]\n",
    "cca_plot_lag_vs_no_lag.plot_cca_lag_vs_nolag_and_train_vs_test(cross_view_sub, dataset_name, mode='lag_offset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just train vs test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-view X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_significant = True\n",
    "# sort_by_significance = True\n",
    "# significance_threshold = 4\n",
    "# whether_lag = 'lag'\n",
    "\n",
    "# combined_cross_view_df_sub = combined_cross_view_df[combined_cross_view_df['whether_lag'] == whether_lag]\n",
    "\n",
    "# # X1\n",
    "# cca_plot_cv.plot_cca_cv_results(combined_cross_view_df_sub, data_type='X1',\n",
    "#                                     filter_significant=filter_significant, sort_by_significance=sort_by_significance, significance_threshold=significance_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-view X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_significant = True\n",
    "sort_by_significance = True\n",
    "significance_threshold = 1\n",
    "whether_lag = 'lag'\n",
    "\n",
    "combined_cross_view_df_sub = combined_cross_view_df[combined_cross_view_df['whether_lag'] == whether_lag]\n",
    "\n",
    "# X2\n",
    "cca_plot_cv.plot_cca_cv_results(combined_cross_view_df_sub, data_type='X2',\n",
    "                                    filter_significant=filter_significant, sort_by_significance=sort_by_significance, significance_threshold=significance_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce y_var only by vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.reduce_y_var(save_data=True,\n",
    "                     corr_threshold_for_lags_of_a_feature=0.97,\n",
    "                     vif_threshold_for_initial_subset=5, vif_threshold=5, verbose=True,\n",
    "                     filter_corr_by_all_columns=False,\n",
    "                     filter_vif_by_subsets=False,\n",
    "                     filter_vif_by_all_columns=True,\n",
    "                     exists_ok=False,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check final VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = drop_high_vif_vars.get_vif_df(pn.y_var_reduced)\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = drop_high_vif_vars.get_vif_df(pn.y_var_lags_reduced)\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check correlations in y_var_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort pn.y_var_lags by column str a to z\n",
    "pn.y_var_lags2 = pn.y_var_lags.reindex(sorted(pn.y_var_lags.columns), axis=1)\n",
    "\n",
    "# # sort pn.y_var_lags by column str z to a\n",
    "# pn.y_var_lags_reduced = pn.y_var_lags_reduced.reindex(sorted(pn.y_var_lags_reduced.columns, reverse=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.y_var_lags2.iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.y_var_lags2.iloc[:, :10].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check high corr within feature's lagged columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_lags = pn.y_var_lags2.copy()\n",
    "num_original_columns = len(df_with_lags.columns)\n",
    "base_features = drop_high_corr_vars.get_base_feature_names(df_with_lags)\n",
    "columns_dropped = []\n",
    "top_values_by_feature = pd.DataFrame()\n",
    "for i, feature in enumerate(base_features):\n",
    "    df_with_lags_sub = drop_high_corr_vars._find_subset_of_df_with_lags_for_current_feature(\n",
    "        df_with_lags, feature)\n",
    "    # temp_columns_to_drop, top_values_of_feature = drop_high_corr_vars._drop_lags_for_feature(\n",
    "    #     df_with_lags, feature, corr_threshold, vif_threshold, use_vif_instead_of_corr, drop_lag_0_last_in_vif)\n",
    "    if df_with_lags_sub.corr().iloc[1,2] == 1:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare columns in behav_data (target_decoder) and final_behavioral_data (neural_vs_behavioral_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.get_behav_data(exists_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item = neural_vs_behavioral_class.NeuralVsBehavioralClass(raw_data_folder_path=raw_data_folder_path)\n",
    "data_item.streamline_preparing_neural_and_behavioral_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in pn.behav_data_all but not in data_item.final_behavioral_data\n",
    "only_in_pn = set(pn.behav_data_all.columns) - set(data_item.final_behavioral_data.columns)\n",
    "print(\"Columns only in pn.behav_data_all:\")\n",
    "only_in_pn = np.array(sorted(only_in_pn))\n",
    "print(only_in_pn)\n",
    "print('\\n \\n')\n",
    "\n",
    "# Columns in data_item.final_behavioral_data but not in pn.behav_data_all\n",
    "final_behavioral_data_columns = data_item.final_behavioral_data.columns\n",
    "# remove all 'avg_bin_' prefix\n",
    "final_behavioral_data_columns = [col.replace('avg_bin_', '') for col in final_behavioral_data_columns]\n",
    "only_in_data_item = set(final_behavioral_data_columns) - set(pn.behav_data_all.columns)\n",
    "print(\"Columns only in data_item.final_behavioral_data:\")\n",
    "only_in_data_item = np.array(sorted(only_in_data_item))\n",
    "print(only_in_data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.cur_and_nxt_ff_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.test_plan_data_inst.df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just get planning_timestep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_data_by_point_exists_ok = False\n",
    "\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330\"\n",
    "ref_point_mode='time after cur ff visible'\n",
    "ref_point_value=0.1\n",
    "normalize = False\n",
    "eliminate_outliers = False\n",
    "use_curv_to_ff_center = False\n",
    "curv_of_traj_mode = 'distance'\n",
    "window_for_curv_of_traj=[-25, 25]\n",
    "truncate_curv_of_traj_by_time_of_capture = True\n",
    "\n",
    "bin_width=0.02\n",
    "window_width=0.25\n",
    "one_behav_idx_per_bin=True\n",
    "\n",
    "        # get behavioral_data\n",
    "ph = planning_neural_helper_class.PlanningAndNeuralHelper(raw_data_folder_path=raw_data_folder_path,\n",
    "                                                                               bin_width=bin_width,\n",
    "                                                                               window_width=window_width,\n",
    "                                                                               one_behav_idx_per_bin=one_behav_idx_per_bin)\n",
    "\n",
    "ph.load_raw_data(raw_data_folder_path)\n",
    "ph.prep_behav_data_to_analyze_planning(ref_point_mode=ref_point_mode,\n",
    "                                                            ref_point_value=ref_point_value,\n",
    "                                                            curv_of_traj_mode=curv_of_traj_mode,\n",
    "                                                            window_for_curv_of_traj=window_for_curv_of_traj,\n",
    "                                                            truncate_curv_of_traj_by_time_of_capture=truncate_curv_of_traj_by_time_of_capture,\n",
    "                                                            use_curv_to_ff_center=use_curv_to_ff_center,\n",
    "                                                            eliminate_outliers=eliminate_outliers,\n",
    "                                                            planning_data_by_point_exists_ok=planning_data_by_point_exists_ok\n",
    "                                                            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
