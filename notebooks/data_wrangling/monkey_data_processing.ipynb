{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 72808,
     "status": "ok",
     "timestamp": 1684766983549,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "37EL1grMQ4rw",
    "outputId": "877d1089-bdf1-44c9-84c8-07cb03ca70bd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive # import drive from google colab\n",
    "drive.mount(\"/content/drive\") \n",
    "!pip install neo\n",
    "!pip install matplotlib_scalebar\n",
    "!pip install ffmpeg\n",
    "!pip install Ipython --upgrade\n",
    "!pip3 install setuptools==65.5.0\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /content/drive/MyDrive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D7ubA2G0ql0K"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25075,
     "status": "ok",
     "timestamp": 1684767008616,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "3klBkPC-Q4rw",
    "outputId": "4873525c-7578-4c2c-8ec9-51c5b3f7e682",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "if Path.cwd().parts[-1] != 'Multifirefly-Project':\n",
    "    %cd ..\n",
    "    from add_path import find_path\n",
    "    current_path = find_path()\n",
    "    %cd $current_path\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from data_wrangling import process_raw_data, monkey_data_classes, basic_func, combine_info_utils\n",
    "from pattern_discovery import pattern_by_points, pattern_by_points\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "from importlib import reload\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = []\n",
    "for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data/individual_monkey_data'):\n",
    "    for file in files:\n",
    "        if not (file.endswith('.log')) and not (file.endswith('.txt')):\n",
    "            unique_df.append(file)\n",
    "unique_df = list(set(unique_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bruno_dist_150',\n",
       " 'Bruno_dist_50',\n",
       " 'Schro_dist_100',\n",
       " 'phy.apps.base._get_mean_waveforms.pkl',\n",
       " 'waveForms.mat',\n",
       " 'all_stop_and_alt_lr_df',\n",
       " 'state.json',\n",
       " 'target_cluster_df.csv',\n",
       " 'stop_0_1_window_-50cm_0cm',\n",
       " 'channel_map.npy',\n",
       " 'Schro_dist_50',\n",
       " 'ff_flash_sorted.npz',\n",
       " 'phy.apps.base.get_mean_spike_template_amplitudes.pkl',\n",
       " 'spike_clusters.npy',\n",
       " 'phy.apps.base._get_template_waveforms.pkl',\n",
       " 'Bruno_stop_0_1',\n",
       " 'phy.apps.base.get_template_counts.pkl',\n",
       " 'params.py',\n",
       " 'GUAT_w_ff_df.csv',\n",
       " 'Schro_stop_0_1',\n",
       " 'phy.apps.template.gui.get_best_channels.pkl',\n",
       " 'phy.apps.base.get_cluster_amplitude.pkl',\n",
       " 'cluster_KSLabel.tsv',\n",
       " 'templates_ind.npy',\n",
       " 'similar_templates.npy',\n",
       " 'QualityMetr.mat',\n",
       " 'dist_150_window_-50cm_0cm',\n",
       " 'ff_basic_info.npz',\n",
       " 'templates.npy',\n",
       " 'cluster_ContamPct.tsv',\n",
       " 'stop_0_0_window_-50cm_0cm',\n",
       " 'Schro_dist_150',\n",
       " 'pc_feature_ind.npy',\n",
       " 'monkey_information.csv',\n",
       " 'shared_stops_near_ff_df.csv',\n",
       " 'dist_50_window_-50cm_0cm',\n",
       " 'spike_templates.npy',\n",
       " 'm53c0355.smr',\n",
       " 'cluster_Amplitude.tsv',\n",
       " 'cluster_info.tsv',\n",
       " 'func_code.py',\n",
       " 'template_feature_ind.npy',\n",
       " '.DS_Store',\n",
       " 'amplitudes.npy',\n",
       " 'start_and_end_of_juice_timestamps.csv',\n",
       " 'TAFT_x_df.csv',\n",
       " 'spike_times.npy',\n",
       " 'output.pkl',\n",
       " 'Schro_stop_0_0',\n",
       " 'Bruno_dist_150.csv',\n",
       " 'whitening_mat_inv.npy',\n",
       " 'planning_hyperparameters_df.csv',\n",
       " 'phy.apps.base.get_template_for_cluster.pkl',\n",
       " 'dist_100_window_-50cm_0cm',\n",
       " 'whitening_mat.npy',\n",
       " 'GUAT_x_df.csv',\n",
       " 'channel_positions.npy',\n",
       " 'phy.apps.base.get_mean_firing_rate.pkl',\n",
       " 'phy.apps.template.gui.get_template_amplitude.pkl',\n",
       " 'phy.apps.base.get_channel_shank.pkl',\n",
       " 'phy.apps.base.get_probe_depth.pkl',\n",
       " 'm53c0356.smr',\n",
       " 'phy.apps.base.peak_channel_similarity.pkl',\n",
       " 'pc_features.npy',\n",
       " 'template_features.npy',\n",
       " 'Bruno_dist_100',\n",
       " 'cluster_group.tsv',\n",
       " 'new_cluster_id.json',\n",
       " 'phy.apps.base.get_best_channel.pkl',\n",
       " 'rez.mat',\n",
       " 'metadata.json',\n",
       " 'Bruno_stop_0_0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0222/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0222\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0402/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0402\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0329/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0329\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0316/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0316\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0327/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0327\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0321/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0321\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0326/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0326\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0328/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0328\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0309/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0309\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0307/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0307\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0306/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0306\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0301/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0301\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0308/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0308\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0330/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0330\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0220/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0220\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0227/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0227\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0228/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0228\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0226/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0226\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0219/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0219\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0221/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0221\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0312/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0312\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0315/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0315\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0323/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0323\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0322/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0322\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0314/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0314\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0410/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0410\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0417/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0417\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0419/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0419\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0420/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0420\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0416/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0416\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0411/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0411\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0402/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0402\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0404/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0404\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/problematic data/data_0313/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/problematic data/data_0313\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0403/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0403\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0329/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0329\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0316/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0316\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0327/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0327\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0321/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0321\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0326/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0326\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0328/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0328\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0413/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0413\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0423/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0423\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0424/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0424\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0412/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0412\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0406/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0406\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0409/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0409\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0322/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0322\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0222/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0222\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0402/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0402\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0329/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0329\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0316/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0316\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0327/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0327\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0321/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0321\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0326/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0326\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0328/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0328\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0309/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0309\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0307/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0307\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0306/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0306\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0301/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0301\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0308/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0308\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0330/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0330\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0220/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0220\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0227/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0227\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0228/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0228\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0226/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0226\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0219/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0219\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0221/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0221\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0312/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0312\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0315/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0315\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0323/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0323\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0322/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0322\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0314/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0314\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0410/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0410\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0417/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0417\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0419/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0419\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0420/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0420\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0416/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0416\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0411/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0411\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0402/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0402\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0404/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0404\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/problematic data/data_0313/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/problematic data/data_0313\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0403/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0403\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0329/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0329\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0316/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0316\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0327/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0327\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0321/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0321\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0326/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0326\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0328/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0328\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0413/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0413\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0423/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0423\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0424/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0424\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0412/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0412\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0406/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0406\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0409/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0409\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0322/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0322\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0222/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0222\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0402/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0402\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0329/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0329\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0316/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0316\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0327/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0327\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0321/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0321\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0326/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0326\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0328/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0328\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0309/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0309\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0307/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0307\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0306/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0306\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0301/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0301\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0308/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0308\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0330/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0330\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0220/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0220\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0227/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0227\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0228/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0228\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0226/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0226\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0219/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0219\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0221/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0221\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0312/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0312\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0315/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0315\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0323/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0323\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0322/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0322\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/data_0314/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Bruno/data_0314\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0410/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0410\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0417/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0417\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0419/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0419\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0420/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0420\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0416/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0416\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0411/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0411\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0402/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0402\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0404/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0404\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/problematic data/data_0313/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/problematic data/data_0313\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0403/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0403\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0329/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0329\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0316/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0316\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0327/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0327\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0321/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0321\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0326/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0326\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0328/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0328\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0413/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0413\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0423/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0423\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0424/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0424\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0412/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0412\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0406/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0406\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0409/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0409\n",
      "all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Schro/data_0322/processed_data/basic_info\n",
      "new_root: all_monkey_data/processed_monkey_data/individual_monkey_data/monkey_Schro/data_0322\n"
     ]
    }
   ],
   "source": [
    "df_of_interests = ['basic_info.h5', 'ff_basic_info.npz', 'ff_flash_sorted.npz', 'monkey_information.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data/individual_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'processed_data')))\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interests = ['GUAT_x_df.csv', 'TAFT_x_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data/individual_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' not in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'decision_making')))\n",
    "                new_root = os.path.join(new_root, 'GUAT_vs_TAFT')\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interests = ['GUAT_w_ff_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data/individual_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' not in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'decision_making')))\n",
    "                new_root = os.path.join(new_root, 'GUAT_info')\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interests = ['shared_stops_near_ff_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data/individual_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' not in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'planning')))\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "df_of_interests = ['shared_stops_near_ff_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data/individual_monkey_data'):\n",
    "        for dir in dirs:\n",
    "            if dir == 'processed_data':\n",
    "                # remove the directory\n",
    "                shutil.rmtree(os.path.join(root, dir))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files from gdrive to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local use of the notebook\n",
    "%cd /Users/dusiyi/Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dusiyi/Documents/Multifirefly-Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "grFpm8umySti"
   },
   "source": [
    "# Process all monkey data\n",
    "\n",
    "Note: as of Nov 1, 2023, all ff_dataframes are being updated, but not anything after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'all_monkey_data'\n",
    "filepath = overall_folder + 'sessions_df.csv'\n",
    "if not exists(filepath):\n",
    "    sessions_df = basic_func.initialize_monkey_sessions_df(dir_name='all_monkey_data/raw_monkey_data/individual_monkey_data')\n",
    "    sessions_df.to_csv(filepath)\n",
    "else:\n",
    "    sessions_df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = basic_func.initialize_monkey_sessions_df(dir_name='all_monkey_data/raw_monkey_data/individual_monkey_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exists_ok = True\n",
    "\n",
    "from pattern_discovery import organize_patterns_and_features\n",
    "reload(organize_patterns_and_features)\n",
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "for index, row in sessions_df.iterrows():\n",
    "    if row['finished'] == True:\n",
    "        continue\n",
    "    \n",
    "    monkey_name = row['monkey_name']\n",
    "    data_name = row['data_name']\n",
    "\n",
    "    temp_raw_data_folder_path = os.path.join(dir_name, monkey_name, data_name)\n",
    "    print(temp_raw_data_folder_path)\n",
    "\n",
    "    data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "    #data_item.save_important_files(exists_ok=False)\n",
    "\n",
    "    data_item.retrieve_or_make_monkey_data(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_ff_dataframe(exists_ok=exists_ok, to_furnish_ff_dataframe=True)\n",
    "    data_item.find_patterns()\n",
    "    data_item.make_or_retrieve_all_trial_patterns(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_pattern_frequencies(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_all_trial_features(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_feature_statistics(exists_ok=exists_ok)\n",
    "\n",
    "    current_session_info = ((sessions_df['monkey_name'] == monkey_name) & (sessions_df['data_name'] == data_name))\n",
    "    sessions_df.loc[current_session_info, 'finished'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_EnP6_v8Awc",
    "outputId": "c021cdf6-a2bf-4c92-cea6-415502b6480f"
   },
   "outputs": [],
   "source": [
    "# dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "# num_trials = 3\n",
    "# #for monkey_name in os.listdir(dir_name):\n",
    "# for monkey_name in ['monkey_Bruno', 'monkey_Schro', 'monkey_Quigley']:\n",
    "#     monkey_path = os.path.join(dir_name, monkey_name)\n",
    "#     for data_name in os.listdir(monkey_path):\n",
    "#         temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "#         print(temp_raw_data_folder_path)\n",
    "#         data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "#         data_item.save_important_files(exists_ok=False)\n",
    "\n",
    "#         # data_item.retrieve_or_make_monkey_data()\n",
    "#         # data_item.make_or_retrieve_ff_dataframe(exists_ok=False)\n",
    "#         # data_item.find_patterns()\n",
    "#         # data_item.make_or_retrieve_all_trial_patterns(exists_ok=True)\n",
    "#         # data_item.make_or_retrieve_pattern_frequencies(exists_ok=False)\n",
    "#         # data_item.make_or_retrieve_all_trial_features(exists_ok=True)\n",
    "#         # data_item.make_or_retrieve_feature_statistics(exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RXCGV_-BBmC3"
   },
   "source": [
    "# Store csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "95tkM06Xl1In"
   },
   "source": [
    "## Get valid time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r2FTUc6l3-V"
   },
   "outputs": [],
   "source": [
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(dir_name):\n",
    "for monkey_name in ['monkey_Quigley', 'monkey_Schro', 'monkey_Bruno']:\n",
    "    monkey_path = os.path.join(dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        if data_name[0] == 'd':\n",
    "            print(temp_raw_data_folder_path)\n",
    "            data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "            data_item.retrieve_or_make_monkey_data()\n",
    "            accurate_start_time = data_item.accurate_start_time\n",
    "            accurate_end_time = data_item.accurate_end_time\n",
    "            print(accurate_start_time)\n",
    "            print(accurate_end_time)\n",
    "            # Create the pandas DataFrame\n",
    "            data = [accurate_start_time, accurate_end_time]\n",
    "            juice_timestamps = pd.DataFrame(data, columns=['time'])\n",
    "            filepath = temp_raw_data_folder_path + '/start_and_end_of_juice_timestamps.csv'\n",
    "            juice_timestamps.to_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2QCbRBkoBHwS"
   },
   "source": [
    "## Store monkey_information.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1983254,
     "status": "ok",
     "timestamp": 1684769571178,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "hA7SjB4rBJ9r",
    "outputId": "6e787758-a7e9-4b46-8436-d61af14769b9"
   },
   "outputs": [],
   "source": [
    "# the below can be replaced by:\n",
    "# data_item.retrieve_or_make_monkey_data(exists_ok=False)\n",
    "\n",
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Quigley', 'monkey_Schro']:\n",
    "    monkey_path = os.path.join(dir_name, monkey_name)\n",
    "    interocular_dist = 4 if monkey_name=='monkey_Bruno' else 3\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        print(temp_raw_data_folder_path)\n",
    "\n",
    "        monkey_information, ff_caught_T_sorted, ff_index_sorted, ff_real_position_sorted, ff_believed_position_sorted, ff_life_sorted, ff_flash_sorted, ff_flash_end_sorted \\\n",
    "                = process_raw_data.log_extractor(raw_data_folder_path = temp_raw_data_folder_path).extract_data(\n",
    "                    monkey_information_exists_OK = False, interocular_dist=interocular_dist)\n",
    "\n",
    "\n",
    "        monkey_information_small = monkey_information[['monkey_t', 'monkey_x', 'monkey_y', 'monkey_speed', 'monkey_angles', 'monkey_dw', 'LDy', 'LDz', 'RDy', 'RDz']]\n",
    "        monkey_information_path = os.path.join(temp_raw_data_folder_path, 'monkey_information.csv')\n",
    "        if not exists(monkey_information_path):\n",
    "            monkey_information_small.to_csv(monkey_information_path)\n",
    "            print(\"Stored new monkey_information_small at \", monkey_information_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change juice_timestamps for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(dir_name):\n",
    "for monkey_name in ['monkey_Bruno']:\n",
    "    monkey_path = os.path.join(dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        if data_name[0] == 'd':\n",
    "            print(temp_raw_data_folder_path)\n",
    "            data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "            data_item.retrieve_or_make_monkey_data()\n",
    "            accurate_start_time = data_item.accurate_start_time\n",
    "            accurate_end_time = data_item.accurate_end_time\n",
    "            print(accurate_start_time)\n",
    "            print(accurate_end_time)\n",
    "            # Create the pandas DataFrame\n",
    "            data = [accurate_start_time, accurate_end_time]\n",
    "            juice_timestamps = pd.DataFrame(data, columns=['time'])\n",
    "            filepath = temp_raw_data_folder_path + '/start_and_end_of_juice_timestamps.csv'\n",
    "            juice_timestamps.to_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0BezbyX1F4OC"
   },
   "source": [
    "# Save plots/animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1683998806036,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "rvJ9IvJGcbnh",
    "outputId": "0770eb17-8cdc-482a-e1da-ca79622604e4"
   },
   "outputs": [],
   "source": [
    "\n",
    "additional_kwargs = {'show_connect_path_ff_memory': True,\n",
    "                     'show_connect_path_ff_except_targets': True,\n",
    "                     'show_path_when_target_visible': True,\n",
    "                     'show_connect_path_eye_positions': False}\n",
    "\n",
    "\n",
    "\n",
    "trial_total_num = 10\n",
    "PLAYER = \"monkey\"\n",
    "\n",
    "classic_plot_kwargs = {'player': PLAYER,\n",
    "                       'show_stops': True,\n",
    "                       'show_believed_target_positions': True,\n",
    "                       'show_reward_boundary': True,\n",
    "                       'show_scale_bar': True,\n",
    "                       'show_eye_positions': True,\n",
    "                       'show_eye_positions_on_the_right': True,\n",
    "                       'show_connect_path_eye_positions': True,\n",
    "                       #=== below is different from animation_plot_kwargs\n",
    "                       'hitting_arena_edge_ok': False,\n",
    "                       'trial_too_short_ok': False}\n",
    "\n",
    "combined_plot_kwargs = {'player': PLAYER,\n",
    "                        'combined_plot': True,\n",
    "                        'show_alive_fireflies': False,\n",
    "                        'show_title': False,\n",
    "                        'show_start': False}\n",
    "\n",
    "print(\"player is\", PLAYER)\n",
    "\n",
    "animation_plot_kwargs = classic_plot_kwargs\n",
    "animation_plot_kwargs['as_part_of_animation'] = True\n",
    "animation_plot_kwargs['show_eye_positions_on_the_right'] = False   \n",
    "animation_plot_kwargs['hitting_arena_edge_ok'] = True\n",
    "animation_plot_kwargs['trial_too_short_ok'] = True\n",
    "animation_plot_kwargs['images_dir'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gd6sO_z_JJlG"
   },
   "outputs": [],
   "source": [
    "Bruno_data = [\n",
    " 'data_0326',\n",
    " 'data_0328',\n",
    " 'data_0329',\n",
    " 'data_0327',\n",
    " 'data_0402',\n",
    " 'data_0322',\n",
    " 'data_0323'\n",
    " 'data_0321',\n",
    " 'data_0308',\n",
    " 'data_0315',\n",
    " 'data_0312',\n",
    " 'data_0314',\n",
    " 'data_0316',\n",
    " 'data_0222',\n",
    " 'data_0226',\n",
    " 'data_0307',\n",
    " 'data_0330',\n",
    " 'data_0228',\n",
    " 'data_0221',\n",
    " 'data_0309',\n",
    " 'data_0219',\n",
    " 'data_0220',\n",
    " 'data_0306',\n",
    " 'data_0227',\n",
    " 'data_0301',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1RDJ5JG_AT14OBIPUHfooTDalyx-6Qah5"
    },
    "executionInfo": {
     "elapsed": 519068,
     "status": "error",
     "timestamp": 1684010500805,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "uepIrsliHgv1",
    "outputId": "64c309c7-a2d4-4be3-b3dc-0c1b4e598dc6"
   },
   "outputs": [],
   "source": [
    "chunk_numbers = range(30, 40)\n",
    "\n",
    "# Make a function to iterate through all the folders\n",
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Schro']: # 'monkey_Quigley'\n",
    "    monkey_path = os.path.join(dir_name, monkey_name)\n",
    "    #for data_name in os.listdir(monkey_path):\n",
    "    for data_name in Bruno_data:\n",
    "        monkey_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        print('monkey_name:', monkey_name)\n",
    "        print('data_name:', data_name)\n",
    "\n",
    "        data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=monkey_data_folder_path)\n",
    "        data_item.retrieve_or_make_monkey_data()\n",
    "        data_item.make_or_retrieve_ff_dataframe(exists_ok=True)\n",
    "        data_item.find_patterns()\n",
    "        data_item.make_PlotTrials_args(classic_plot_kwargs, combined_plot_kwargs, animation_plot_kwargs)\n",
    "        \n",
    "        ## To save animation from a category across all folders\n",
    "        # data_item.make_animation_from_a_category(\"give_up_after_trying\", max_trial_to_plot=5, \n",
    "        #                                                         num_trials=2, sampling_frame_ratio = 5, exists_ok=True)\n",
    "\n",
    "        # To save animation from chunks with more than 2 ff across all folders\n",
    "        points_w_more_than_2_ff = pattern_by_points.find_points_w_more_than_n_ff(data_item.ff_dataframe, data_item.monkey_information, data_item.ff_caught_T_sorted)\n",
    "        points_w_more_than_2_ff = pattern_by_points.decrease_overlaps_between_chunks(points_w_more_than_2_ff, data_item.monkey_information, min_interval_between_chunks=10)\n",
    "        data_item.make_animation_of_chunks(points_w_more_than_2_ff, data_item.monkey_information, chunk_numbers = chunk_numbers, \\\n",
    "                                               sampling_frame_ratio = 3, additional_kwargs=additional_kwargs, exists_ok=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "num_trials = 3\n",
    "k = 3\n",
    "#for monkey_name in os.listdir(dir_name):\n",
    "for monkey_name in ['monkey_Quigley']: #'monkey_Schro', 'monkey_Bruno']:\n",
    "    monkey_path = os.path.join(dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "        print(temp_raw_data_folder_path)\n",
    "        \n",
    "        animation_folder_name = os.path.join('animation', monkey_name, data_name)\n",
    "\n",
    "        if not exists(animation_folder_name):\n",
    "            os.makedirs(animation_folder_name, exist_ok = True)   \n",
    "\n",
    "        if len(os.listdir(animation_folder_name)) < 8: \n",
    "            # Then we need to save some more animations;\n",
    "            # We use this condition so as not to repeat what we've already done\n",
    "            data_item.retrieve_or_make_monkey_data()\n",
    "            data_item.make_or_retrieve_ff_dataframe()\n",
    "            # Prepare for animatoin\n",
    "            sampled_trials = np.round(np.linspace(num_trials, len(data_item.ff_caught_T_sorted)-1, 7)).astype('int')\n",
    "            for currentTrial in sampled_trials:\n",
    "                data_item.set_animation_parameters(currentTrial, num_trials, k)\n",
    "                data_item.call_animation_function(margin=100, save_video=False)\n",
    "                \n",
    "                # Save the animation\n",
    "                writervideo = animation.FFMpegWriter(fps=int(62/k))\n",
    "                filename = \"trial_\" + str(currentTrial-data_item.new_num_trials+1) + \"_to_\" + str(currentTrial)\n",
    "                data_item.anim.save(f\"{animation_folder_name}/{filename}.mp4\", writer=writervideo)\n",
    "                print(f\"Saved {animation_folder_name}/{filename}.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move all ipynb notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.ipynb'):\n",
    "            if 'appendix' in file:\n",
    "                continue\n",
    "            old_path = os.path.join(root, file)\n",
    "            original_path = old_path\n",
    "            print(old_path)\n",
    "            # find the part of path that is methods\n",
    "            if 'methods' not in old_path:\n",
    "                continue\n",
    "            while os.path.basename(os.path.dirname(old_path)) != 'methods':\n",
    "                old_path = os.path.dirname(old_path)\n",
    "                \n",
    "            new_path = old_path.replace('methods', 'notebooks')\n",
    "            os.makedirs(new_path, exist_ok=True)\n",
    "            new_path = os.path.join(new_path, file)\n",
    "\n",
    "            # now, move the file from old path to new path\n",
    "            os.rename(original_path, new_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove empty folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty folders in path = '/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis'\n",
    "import os\n",
    "import shutil\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for d in dirs:\n",
    "        if not os.listdir(os.path.join(root, d)):\n",
    "            os.rmdir(os.path.join(root, d))\n",
    "            print('removed:', os.path.join(root, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remake df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = basic_func.initialize_monkey_sessions_df(dir_name='all_monkey_data/raw_monkey_data/individual_monkey_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pattern_discovery import organize_patterns_and_features\n",
    "reload(organize_patterns_and_features)\n",
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "for index, row in sessions_df.iterrows():\n",
    "    if row['finished'] == True:\n",
    "        continue\n",
    "    \n",
    "    monkey_name = row['monkey_name']\n",
    "    data_name = row['data_name']\n",
    "\n",
    "    temp_raw_data_folder_path = os.path.join(dir_name, monkey_name, data_name)\n",
    "    print(temp_raw_data_folder_path)\n",
    "\n",
    "    data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "    #data_item.save_important_files(exists_ok=False)\n",
    "\n",
    "    data_item.retrieve_or_make_monkey_data(exists_ok=False)\n",
    "    data_item.make_or_retrieve_ff_dataframe(exists_ok=False, to_furnish_ff_dataframe=True)\n",
    "    data_item.find_patterns()\n",
    "    data_item.make_or_retrieve_all_trial_patterns(exists_ok=False)\n",
    "    data_item.make_or_retrieve_pattern_frequencies(exists_ok=False)\n",
    "    data_item.make_or_retrieve_all_trial_features(exists_ok=False)\n",
    "    data_item.make_or_retrieve_feature_statistics(exists_ok=False)\n",
    "\n",
    "    current_session_info = ((sessions_df['monkey_name'] == monkey_name) & (sessions_df['data_name'] == data_name))\n",
    "    sessions_df.loc[current_session_info, 'finished'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After changing cost params of agents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NpF0uM9HR288"
   },
   "source": [
    "## Rename folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models/all_agents/env1_relu'\n",
    "\n",
    "# for every subdirectory in path, if the name begins with 'time0_' or 'time10_', then remove it from the name\n",
    "for subdir0 in os.listdir(path):\n",
    "    if 'ff' in subdir0:\n",
    "        for subdir in os.listdir(os.path.join(path, subdir0)):\n",
    "            if subdir.startswith('time0_'):\n",
    "                new_subdir = subdir[6:]\n",
    "                print(new_subdir)\n",
    "                os.rename(os.path.join(path, subdir0, subdir), os.path.join(path, subdir0, new_subdir))\n",
    "\n",
    "\n",
    "        # for every subdirectory in path, if the name begins with 'time0_' or 'time10_', then remove it from the name\n",
    "        for subdir in os.listdir(os.path.join(path, subdir0)):\n",
    "            if subdir.startswith('time10_'):\n",
    "                new_subdir = subdir[7:]\n",
    "                print(new_subdir)\n",
    "                os.rename(os.path.join(path, subdir0, subdir), os.path.join(path, subdir0, new_subdir))\n",
    "\n",
    "\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models/all_agents/env1_relu'\n",
    "\n",
    "# for every subdirectory in path, if the name begins with 'time0_' or 'time10_', then remove it from the name\n",
    "for subdir0 in os.listdir(path):\n",
    "    if 'ff' in subdir0:\n",
    "        for subdir in os.listdir(os.path.join(path, subdir0)):\n",
    "            if subdir.startswith('dv10_dw10_w10'):\n",
    "                # then replace that with dv10_dw10_w10\n",
    "                new_subdir = subdir.replace('dv10_dw10_w10', 'dv10_dw10_w10')\n",
    "                os.rename(os.path.join(path, subdir0, subdir), os.path.join(path, subdir0, new_subdir))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove time cost from all env_params.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def process_env_params(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file == 'env_params.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    env_params = json.load(f)\n",
    "                \n",
    "                # Pop out 'time cost' if it exists\n",
    "                if 'time_cost' in env_params:\n",
    "                    print(f\"Removing 'time cost' from {file_path}\")\n",
    "                    # Remove the key from the dictionary\n",
    "                    env_params.pop('time_cost')\n",
    "                \n",
    "                # Save the dictionary back to the file\n",
    "                with open(file_path, 'w') as f:\n",
    "                    json.dump(env_params, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "process_env_params(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the other costs from all env_params.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "costs = ['dv_cost_factor', 'dw_cost_factor', 'w_cost_factor']\n",
    "def process_env_params(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file == 'env_params.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    env_params = json.load(f)\n",
    "                \n",
    "                # Pop out 'time cost' if it exists\n",
    "                for cost in costs:\n",
    "                    if env_params[cost] == 50:\n",
    "                        env_params[cost] = 10\n",
    "                        print(f\"Changed {cost} from 50 to 10\")\n",
    "                \n",
    "                # Save the dictionary back to the file\n",
    "                with open(file_path, 'w') as f:\n",
    "                    json.dump(env_params, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "process_env_params(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "k11SZ7xzCa4r"
   },
   "source": [
    "## Rename monkey folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEquTsVpCc6G"
   },
   "outputs": [],
   "source": [
    "# # Rename all the data folders so that they start with 'monkey_' instead of numbers \n",
    "# dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "# for data_name in os.listdir(dir_name):\n",
    "#     if data_name[0:2] == 'mo':\n",
    "#         new_data_name = 'monkey' + data_name[7:]\n",
    "#         new_path_name = os.path.join(dir_name, new_data_name)\n",
    "#         old_path_name = os.path.join(dir_name, data_name)\n",
    "#         print(\"old_path_name\", old_path_name)\n",
    "#         print(\"new_path_name\", new_path_name)\n",
    "#         # Rename the file\n",
    "#         os.rename(old_path_name, new_path_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "h-TgMOcuCWjV"
   },
   "source": [
    "## Rename data folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmn-C4ezSi-a"
   },
   "outputs": [],
   "source": [
    "# # Rename all the data folders so that they start with 'monkey_' instead of numbers \n",
    "# dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "# for monkey_name in os.listdir(dir_name):\n",
    "#     monkey_path = os.path.join(dir_name, monkey_name)\n",
    "#     for data_name in os.listdir(monkey_path):\n",
    "#         old_path_name = os.path.join(monkey_name, data_name)\n",
    "#         # if the folder name does not start with m\n",
    "#         if data_name[0] == 'd':\n",
    "#             new_data_name = 'data_' + data_name[-3:]\n",
    "#             new_path_name = os.path.join(monkey_path, new_data_name)\n",
    "#             old_path_name = os.path.join(monkey_path, data_name)\n",
    "#             print(\"old_path_name\", old_path_name)\n",
    "#             print(\"new_path_name\", new_path_name)\n",
    "#             # Rename the file\n",
    "#             os.rename(old_path_name, new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename basic_info.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all files in 'all_monkey_data/processed_monkey_data' including in the sub-directory\n",
    "# if the name is basic_info.h5, then rename it to be ff_dataframe.h5\n",
    "dir_name = 'all_monkey_data/processed_data'\n",
    "for root, dirs, files in os.walk(dir_name):\n",
    "    for file in files:\n",
    "        if file == 'basic_info.h5':\n",
    "            new_file = 'ff_dataframe.h5'\n",
    "            os.rename(os.path.join(root, file), os.path.join(root, new_file))\n",
    "            print(f'{file} is renamed to {new_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy data from gdrive to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move monkey_Schro etc\n",
    "\n",
    "# # if copy witin gdrive\n",
    "# dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "# dir_name_des = 'all_monkey_data/generated_monkey_data'\n",
    "\n",
    "\n",
    "# if copy from gdrive to local\n",
    "%cd /Users/dusiyi\n",
    "gdrive_root_dir = 'Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project'\n",
    "local_root_dir = 'Documents/Multifirefly-Project'\n",
    "dir_name = os.path.join(gdrive_root_dir, 'all_monkey_data/raw_monkey_data/individual_monkey_data')\n",
    "dir_name_des = os.path.join(local_root_dir, 'all_monkey_data/raw_monkey_data/individual_monkey_data')\n",
    "\n",
    "\n",
    "#for monkey_name in os.listdir(dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Quigley', 'monkey_Schro']:\n",
    "    source_dir = os.path.join(dir_name, monkey_name)\n",
    "    destination_dir = os.path.join(dir_name_des, monkey_name)\n",
    "    if exists(source_dir):\n",
    "        if exists(destination_dir):\n",
    "            continue\n",
    "            # shutil.rmtree(destination_dir)\n",
    "        print(source_dir)\n",
    "        print(\"destination_dir\", destination_dir)\n",
    "        print('\\n')\n",
    "        shutil.copytree(source_dir, destination_dir)\n",
    "%cd /Users/dusiyi/Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data_0330 etc\n",
    "\n",
    "# # if copy witin gdrive\n",
    "# dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "# dir_name_des = 'all_monkey_data/generated_monkey_data'\n",
    "\n",
    "\n",
    "# if copy from gdrive to local\n",
    "%cd /Users/dusiyi\n",
    "gdrive_root_dir = 'Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project'\n",
    "local_root_dir = 'Documents/Multifirefly-Project'\n",
    "dir_name = os.path.join(gdrive_root_dir, 'all_monkey_data/raw_monkey_data/individual_monkey_data')\n",
    "dir_name_des = os.path.join(local_root_dir, 'all_monkey_data/raw_monkey_data/individual_monkey_data')\n",
    "\n",
    "\n",
    "#for monkey_name in os.listdir(dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Quigley', 'monkey_Schro']:\n",
    "    monkey_path = os.path.join(dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        if data_name[0] == 'd':\n",
    "            source_dir = os.path.join(monkey_path, data_name)\n",
    "            destination_dir = os.path.join(dir_name_des, monkey_name, data_name)\n",
    "            if exists(source_dir):\n",
    "                if exists(destination_dir):\n",
    "                    continue\n",
    "                    # shutil.rmtree(destination_dir)\n",
    "                print(source_dir)\n",
    "                print(\"destination_dir\", destination_dir)\n",
    "                print('\\n')\n",
    "                shutil.copytree(source_dir, destination_dir)\n",
    "%cd /Users/dusiyi/Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete planning_info_except shared_stops_near_ff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete everything in planning_info_except shared_stops_near_ff_df\n",
    "import shutil\n",
    "for monkey_name in ['monkey_Bruno']:\n",
    "    dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data'\n",
    "    sessions_df_for_one_monkey = combine_info_utils.make_sessions_df_for_one_monkey(dir_name, monkey_name)\n",
    "    for index, row in sessions_df_for_one_monkey.iterrows():\n",
    "        raw_data_folder_path = os.path.join(dir_name, row['monkey_name'], row['data_name'])\n",
    "        data_item = monkey_data_classes.ProcessMonkeyData(raw_data_folder_path=raw_data_folder_path)\n",
    "        # delete folder in planning_info_except shared_stops_near_ff_df\n",
    "        for file in os.listdir(data_item.planning_data_folder_path):\n",
    "            # if it is a folder\n",
    "            if os.path.isdir(os.path.join(data_item.planning_data_folder_path, file)):\n",
    "                if file != 'shared_stops_near_ff_df':\n",
    "                    old_file_path = os.path.join(data_item.planning_data_folder_path, file)\n",
    "                    if exists(old_file_path):\n",
    "                        shutil.rmtree(old_file_path)\n",
    "                        print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## planning info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno'\n",
    "for data_name in os.listdir(dir_name):\n",
    "    if data_name[:5] == 'data_':\n",
    "        data_path_name = os.path.join(dir_name, data_name)\n",
    "        if exists(data_item.planning_data_folder_path):\n",
    "            # for directory:\n",
    "            shutil.rmtree(data_item.planning_data_folder_path)\n",
    "            print(\"Removed\", data_item.planning_data_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUAT info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "dir_name = 'all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno'\n",
    "for data_name in os.listdir(dir_name):\n",
    "    if data_name[:5] == 'data_':\n",
    "        data_path_name = os.path.join(dir_name, data_name)\n",
    "        if exists(data_item.planning_data_folder_path):\n",
    "            # for directory:\n",
    "            shutil.rmtree(data_item.planning_data_folder_path)\n",
    "            print(\"Removed\", data_item.planning_data_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all agent data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for dir in dirs:\n",
    "        if (dir == 'collected_data') | (dir == 'overall_variations_df'):\n",
    "            # remove the directory\n",
    "            shutil.rmtree(os.path.join(root, dir))\n",
    "            print('Removed:', os.path.join(root, dir))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all planning info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for dir in dirs:\n",
    "        if (dir == 'planning_info') | (dir == 'combd_planning_info'):\n",
    "            # remove the directory\n",
    "            shutil.rmtree(os.path.join(root, dir))\n",
    "            print('Removed:', os.path.join(root, dir))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take df out of h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def take_out_df_from_h5_store(path, new_folder_name='combd_rel_angle_slope'):\n",
    "    if not exists(path):\n",
    "        print(f'file does not exist: {path}')\n",
    "        return\n",
    "    with pd.HDFStore(path) as current_h5_store:\n",
    "        new_path_way = os.path.join(os.path.dirname(path), new_folder_name)\n",
    "        os.makedirs(new_path_way, exist_ok=True)\n",
    "        # for each df in current_h5_store, save it in new_path_way\n",
    "        for key in current_h5_store.keys():\n",
    "            print(key)\n",
    "            current_h5_store[key].to_csv(os.path.join(new_path_way, key.lstrip('/')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'all_monkey_data/aggregate_monkey_data/stop_and_alt/data/data_for_ml/plan_factors.h5'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    print(f'file does not exist: {path}')\n",
    "else:\n",
    "    with pd.HDFStore(path) as current_h5_store:\n",
    "        # Define the base directory for saving the CSV files\n",
    "        base_dir = os.path.join(os.path.dirname(os.path.dirname(path)), 'plan_factors')\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "        # Create separate directories for plan_x and plan_y\n",
    "        plan_x_dir = os.path.join(base_dir, 'plan_factors_x')\n",
    "        plan_y_dir = os.path.join(base_dir, 'plan_factors_y')\n",
    "        os.makedirs(plan_x_dir, exist_ok=True)\n",
    "        os.makedirs(plan_y_dir, exist_ok=True)\n",
    "\n",
    "        # For each df in current_h5_store, save it in the appropriate directory\n",
    "        for key in current_h5_store.keys():\n",
    "            print(key)\n",
    "            # Determine the directory based on the key\n",
    "            if 'plan_x' in key:\n",
    "                save_dir = plan_x_dir\n",
    "            elif 'plan_y' in key:\n",
    "                save_dir = plan_y_dir\n",
    "            else:\n",
    "                continue  # Skip keys that do not match plan_x or plan_y\n",
    "\n",
    "            new_key = key.lstrip('/').replace('combd_plan_y_both_', '').replace('combd_plan_x_both_', '')\n",
    "            # Save the DataFrame to the appropriate directory\n",
    "            current_h5_store[key].to_csv(os.path.join(save_dir, new_key.lstrip('/')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/combd_planning_info/only_stop_ff/data/combd_only_stop_ff_df.h5'\n",
    "take_out_df_from_h5_store(path, new_folder_name='combd_only_stop_ff_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To fix the bug caused by the extra \"+ '.csv'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to strip .csv extension from file names in a directory\n",
    "def strip_csv_extension(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            new_filename = filename[:-4]  # Remove the last 4 characters ('.csv')\n",
    "            old_file_path = os.path.join(directory, filename)\n",
    "            new_file_path = os.path.join(directory, new_filename)\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f'Renamed: {old_file_path} to {new_file_path}')\n",
    "\n",
    "\n",
    "base_dir = 'all_monkey_data/raw_monkey_data/individual_monkey_data/monkey_Bruno/combd_planning_info/stop_and_alt/data/data_for_ml'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    print(f'file does not exist: {base_dir}')\n",
    "else:\n",
    "    # Create separate directories for plan_x and plan_y\n",
    "    plan_x_dir = os.path.join(base_dir, 'plan_factors_x')\n",
    "    plan_y_dir = os.path.join(base_dir, 'plan_factors_y')\n",
    "    # Strip .csv extension from files in plan_x_dir and plan_y_dir\n",
    "    strip_csv_extension(plan_x_dir)\n",
    "    strip_csv_extension(plan_y_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ASJATEaNST9A"
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "641tYB4XC3yC"
   },
   "outputs": [],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1682826959386,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "X1PHDflbCvrC",
    "outputId": "b6423fa0-9eaf-4f57-def6-a10ae8549aeb"
   },
   "outputs": [],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4863,
     "status": "ok",
     "timestamp": 1682824912397,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "ANEoQJdmSVSr",
    "outputId": "f6c15160-39a5-49d9-8026-f6b2d9e63b84"
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq ipdb\n",
    "import ipdb\n",
    "%pdb on"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "162-xByx3iTk35YJ06VcUmsXt23wEm77H",
     "timestamp": 1680881588909
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
