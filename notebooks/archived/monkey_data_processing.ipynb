{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D7ubA2G0ql0K"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25075,
     "status": "ok",
     "timestamp": 1684767008616,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "3klBkPC-Q4rw",
    "outputId": "4873525c-7578-4c2c-8ec9-51c5b3f7e682",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed the directory to 'Multifirefly-Project'.\n",
      "Added /Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis/methods to the path.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import os\n",
    "if Path.cwd().parts[-1] != 'Multifirefly-Project':\n",
    "    if Path.cwd().parts[-1] != 'notebooks':\n",
    "        os.chdir('..')\n",
    "    from add_path import find_path\n",
    "    current_path = find_path()\n",
    "    os.chdir(current_path)\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "from data_wrangling import process_raw_data, basic_func, combine_info_utils\n",
    "from pattern_discovery import pattern_by_points, pattern_by_points\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "from importlib import reload\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = []\n",
    "for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data'):\n",
    "    for file in files:\n",
    "        if not (file.endswith('.log')) and not (file.endswith('.txt')):\n",
    "            unique_df.append(file)\n",
    "unique_df = list(set(unique_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interests = ['basic_info.h5', 'ff_basic_info.npz', 'ff_flash_sorted.npz', 'monkey_information.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'processed_data')))\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interests = ['GUAT_x_df.csv', 'TAFT_x_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' not in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'decision_making')))\n",
    "                new_root = os.path.join(new_root, 'GUAT_vs_TAFT')\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interests = ['GUAT_w_ff_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' not in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'decision_making')))\n",
    "                new_root = os.path.join(new_root, 'GUAT_info')\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interests = ['shared_stops_near_ff_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data'):\n",
    "        for file in files:\n",
    "            if file == df:\n",
    "                print(root)\n",
    "                if 'processed_data' not in root:\n",
    "                    continue # since we don't want to move the files that are already moved\n",
    "                new_root = os.path.dirname(os.path.dirname(root.replace('raw_monkey_data', 'planning')))\n",
    "                print('new_root:', new_root)\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_path = os.path.join(new_root, file)\n",
    "                os.makedirs(new_root, exist_ok=True)\n",
    "                # # move the file from old_path to new_path\n",
    "                os.rename(old_path, new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "df_of_interests = ['shared_stops_near_ff_df.csv']\n",
    "for df in df_of_interests:\n",
    "    for root, dirs, files in os.walk('all_monkey_data/raw_monkey_data'):\n",
    "        for dir in dirs:\n",
    "            if dir == 'processed_data':\n",
    "                # remove the directory\n",
    "                shutil.rmtree(os.path.join(root, dir))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files from gdrive to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local use of the notebook\n",
    "%cd /Users/dusiyi/Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dusiyi/Documents/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monkey_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0222/start_and_end_of_juice_timestamps.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dusiyi/Documents/Multifirefly-Project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monkey_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonkey_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno'"
     ]
    }
   ],
   "source": [
    "os.listdir(monkey_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0322'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0222/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0222/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0402/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0402/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0329/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0329/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0316/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0316/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0327/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0327/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0321/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0321/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0326/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0326/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0328/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0309/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0309/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0307/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0307/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0306/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0306/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0301/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0301/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0308/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0308/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0330/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0330/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0220/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0220/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0227/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0227/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0228/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0228/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0226/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0226/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0219/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0219/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0221/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0221/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0312/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0312/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0315/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0315/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0323/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0323/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0322/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0322/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno/data_0314/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Bruno/data_0314/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0410/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0410/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0417/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0417/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0419/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0419/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0420/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0420/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0416/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0416/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0411/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0411/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0402/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0402/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0404/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0404/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0403/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0403/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0329/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0329/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0316/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0316/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0327/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0327/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0321/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0321/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0326/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0326/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0328/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0328/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0413/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0413/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0423/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0423/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0424/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0424/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0412/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0412/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0406/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0406/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0409/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0409/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n",
      "source_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Schro/data_0322/start_and_end_of_juice_timestamps.csv\n",
      "destination_dir /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data/monkey_Schro/data_0322/start_and_end_of_juice_timestamps.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data'\n",
    "file_name = 'start_and_end_of_juice_timestamps.csv'\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Schro']:\n",
    "    monkey_path = os.path.join(root_dir, monkey_name)\n",
    "\n",
    "    #monkey_path = '/Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/raw_monkey_data/monkey_Bruno'\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        if data_name[0] == 'd':\n",
    "            source_dir = os.path.join(monkey_path, data_name, file_name)\n",
    "            destination_dir = source_dir.replace('raw_monkey_data', 'processed_data')\n",
    "            if exists(source_dir):\n",
    "                if exists(destination_dir):\n",
    "                    continue\n",
    "                    # shutil.rmtree(destination_dir)\n",
    "                print(\"source_dir\", source_dir)\n",
    "                print(\"destination_dir\", destination_dir)\n",
    "                print('\\n')\n",
    "                # os.makedirs(destination_dir, exist_ok=True)\n",
    "                # # # move the file from old_path to new_path\n",
    "                # os.rename(source_dir, destination_dir)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "grFpm8umySti"
   },
   "source": [
    "# Process all monkey data\n",
    "\n",
    "Note: as of Nov 1, 2023, all ff_dataframes are being updated, but not anything after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'all_monkey_data'\n",
    "filepath = overall_folder + 'sessions_df.csv'\n",
    "if not exists(filepath):\n",
    "    sessions_df = basic_func.initialize_monkey_sessions_df(raw_data_dir_name='all_monkey_data/raw_monkey_data')\n",
    "    sessions_df.to_csv(filepath)\n",
    "else:\n",
    "    sessions_df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = basic_func.initialize_monkey_sessions_df(raw_data_dir_name='all_monkey_data/raw_monkey_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exists_ok = True\n",
    "\n",
    "from pattern_discovery import organize_patterns_and_features\n",
    "reload(organize_patterns_and_features)\n",
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "for index, row in sessions_df.iterrows():\n",
    "    if row['finished'] == True:\n",
    "        continue\n",
    "    \n",
    "    monkey_name = row['monkey_name']\n",
    "    data_name = row['data_name']\n",
    "\n",
    "    temp_raw_data_folder_path = os.path.join(raw_data_dir_name, monkey_name, data_name)\n",
    "    print(temp_raw_data_folder_path)\n",
    "\n",
    "    data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "    data_item.retrieve_or_make_monkey_data(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_ff_dataframe(exists_ok=exists_ok, to_furnish_ff_dataframe=True)\n",
    "    data_item.find_patterns()\n",
    "    data_item.make_or_retrieve_all_trial_patterns(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_pattern_frequencies(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_all_trial_features(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_feature_statistics(exists_ok=exists_ok)\n",
    "\n",
    "    current_session_info = ((sessions_df['monkey_name'] == monkey_name) & (sessions_df['data_name'] == data_name))\n",
    "    sessions_df.loc[current_session_info, 'finished'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename a column in all ff_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exists_ok = True\n",
    "\n",
    "from pattern_discovery import organize_patterns_and_features\n",
    "reload(organize_patterns_and_features)\n",
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "for index, row in sessions_df.iterrows():\n",
    "    if row['finished'] == True:\n",
    "        continue\n",
    "    \n",
    "    monkey_name = row['monkey_name']\n",
    "    data_name = row['data_name']\n",
    "\n",
    "    temp_raw_data_folder_path = os.path.join(raw_data_dir_name, monkey_name, data_name)\n",
    "    print(temp_raw_data_folder_path)\n",
    "\n",
    "    data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "\n",
    "    data_item.retrieve_or_make_monkey_data(exists_ok=exists_ok)\n",
    "    data_item.make_or_retrieve_ff_dataframe(exists_ok=exists_ok, to_furnish_ff_dataframe=True)\n",
    "    if 'time_since_last_visible' in data_item.ff_dataframe.columns:\n",
    "        data_item.ff_dataframe.rename(columns={'time_since_last_visible': 'time_since_last_vis'}, inplace=True)\n",
    "        print('renamed')\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RXCGV_-BBmC3"
   },
   "source": [
    "# Store csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "95tkM06Xl1In"
   },
   "source": [
    "## Get valid time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r2FTUc6l3-V"
   },
   "outputs": [],
   "source": [
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Quigley', 'monkey_Schro', 'monkey_Bruno']:\n",
    "    monkey_path = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        if data_name[0] == 'd':\n",
    "            print(temp_raw_data_folder_path)\n",
    "            data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "            data_item.retrieve_or_make_monkey_data()\n",
    "            accurate_start_time = data_item.accurate_start_time\n",
    "            accurate_end_time = data_item.accurate_end_time\n",
    "            print(accurate_start_time)\n",
    "            print(accurate_end_time)\n",
    "            # Create the pandas DataFrame\n",
    "            data = [accurate_start_time, accurate_end_time]\n",
    "            juice_timestamps = pd.DataFrame(data, columns=['time'])\n",
    "            filepath = temp_raw_data_folder_path + '/start_and_end_of_juice_timestamps.csv'\n",
    "            juice_timestamps.to_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2QCbRBkoBHwS"
   },
   "source": [
    "## Store monkey_information.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1983254,
     "status": "ok",
     "timestamp": 1684769571178,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "hA7SjB4rBJ9r",
    "outputId": "6e787758-a7e9-4b46-8436-d61af14769b9"
   },
   "outputs": [],
   "source": [
    "# the below can be replaced by:\n",
    "# data_item.retrieve_or_make_monkey_data(exists_ok=False)\n",
    "\n",
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Quigley', 'monkey_Schro']:\n",
    "    monkey_path = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    interocular_dist = 4 if monkey_name=='monkey_Bruno' else 3\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        print(temp_raw_data_folder_path)\n",
    "\n",
    "        monkey_information, ff_caught_T_new, ff_index_sorted, ff_real_position_sorted, ff_believed_position_sorted, ff_life_sorted, ff_flash_sorted, ff_flash_end_sorted \\\n",
    "                = process_raw_data.log_extractor(raw_data_folder_path = temp_raw_data_folder_path).extract_data(\n",
    "                    monkey_information_exists_OK = False, interocular_dist=interocular_dist)\n",
    "\n",
    "\n",
    "        monkey_information_small = monkey_information[['monkey_t', 'monkey_x', 'monkey_y', 'monkey_speed', 'monkey_angles', 'monkey_dw', 'LDy', 'LDz', 'RDy', 'RDz']]\n",
    "        monkey_information_path = os.path.join(temp_raw_data_folder_path, 'monkey_information.csv')\n",
    "        if not exists(monkey_information_path):\n",
    "            monkey_information_small.to_csv(monkey_information_path)\n",
    "            print(\"Stored new monkey_information_small at \", monkey_information_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change juice_timestamps for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Bruno']:\n",
    "    monkey_path = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        if data_name[0] == 'd':\n",
    "            print(temp_raw_data_folder_path)\n",
    "            data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "            data_item.retrieve_or_make_monkey_data()\n",
    "            accurate_start_time = data_item.accurate_start_time\n",
    "            accurate_end_time = data_item.accurate_end_time\n",
    "            print(accurate_start_time)\n",
    "            print(accurate_end_time)\n",
    "            # Create the pandas DataFrame\n",
    "            data = [accurate_start_time, accurate_end_time]\n",
    "            juice_timestamps = pd.DataFrame(data, columns=['time'])\n",
    "            filepath = temp_raw_data_folder_path + '/start_and_end_of_juice_timestamps.csv'\n",
    "            juice_timestamps.to_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0BezbyX1F4OC"
   },
   "source": [
    "# Save plots/animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1683998806036,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "rvJ9IvJGcbnh",
    "outputId": "0770eb17-8cdc-482a-e1da-ca79622604e4"
   },
   "outputs": [],
   "source": [
    "\n",
    "additional_kwargs = {'show_connect_path_ff_memory': True,\n",
    "                     'show_connect_path_ff_except_targets': True,\n",
    "                     'show_path_when_target_visible': True,\n",
    "                     'show_connect_path_eye_positions': False}\n",
    "\n",
    "\n",
    "\n",
    "trial_total_num = 10\n",
    "PLAYER = \"monkey\"\n",
    "\n",
    "classic_plot_kwargs = {'player': PLAYER,\n",
    "                       'show_stops': True,\n",
    "                       'show_believed_target_positions': True,\n",
    "                       'show_reward_boundary': True,\n",
    "                       'show_scale_bar': True,\n",
    "                       'show_eye_positions': True,\n",
    "                       'show_eye_positions_on_the_right': True,\n",
    "                       'show_connect_path_eye_positions': True,\n",
    "                       #=== below is different from animation_plot_kwargs\n",
    "                       'hitting_arena_edge_ok': False,\n",
    "                       'trial_too_short_ok': False}\n",
    "\n",
    "combined_plot_kwargs = {'player': PLAYER,\n",
    "                        'combined_plot': True,\n",
    "                        'show_alive_fireflies': False,\n",
    "                        'show_title': False,\n",
    "                        'show_start': False}\n",
    "\n",
    "print(\"player is\", PLAYER)\n",
    "\n",
    "animation_plot_kwargs = classic_plot_kwargs\n",
    "animation_plot_kwargs['as_part_of_animation'] = True\n",
    "animation_plot_kwargs['show_eye_positions_on_the_right'] = False   \n",
    "animation_plot_kwargs['hitting_arena_edge_ok'] = True\n",
    "animation_plot_kwargs['trial_too_short_ok'] = True\n",
    "animation_plot_kwargs['images_dir'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gd6sO_z_JJlG"
   },
   "outputs": [],
   "source": [
    "Bruno_data = [\n",
    " 'data_0326',\n",
    " 'data_0328',\n",
    " 'data_0329',\n",
    " 'data_0327',\n",
    " 'data_0402',\n",
    " 'data_0322',\n",
    " 'data_0323'\n",
    " 'data_0321',\n",
    " 'data_0308',\n",
    " 'data_0315',\n",
    " 'data_0312',\n",
    " 'data_0314',\n",
    " 'data_0316',\n",
    " 'data_0222',\n",
    " 'data_0226',\n",
    " 'data_0307',\n",
    " 'data_0330',\n",
    " 'data_0228',\n",
    " 'data_0221',\n",
    " 'data_0309',\n",
    " 'data_0219',\n",
    " 'data_0220',\n",
    " 'data_0306',\n",
    " 'data_0227',\n",
    " 'data_0301',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1RDJ5JG_AT14OBIPUHfooTDalyx-6Qah5"
    },
    "executionInfo": {
     "elapsed": 519068,
     "status": "error",
     "timestamp": 1684010500805,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "uepIrsliHgv1",
    "outputId": "64c309c7-a2d4-4be3-b3dc-0c1b4e598dc6"
   },
   "outputs": [],
   "source": [
    "chunk_numbers = range(30, 40)\n",
    "\n",
    "# Make a function to iterate through all the folders\n",
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "num_trials = 3\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Schro']: # 'monkey_Quigley'\n",
    "    monkey_path = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    #for data_name in os.listdir(monkey_path):\n",
    "    for data_name in Bruno_data:\n",
    "        raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        print('monkey_name:', monkey_name)\n",
    "        print('data_name:', data_name)\n",
    "\n",
    "        data_item = animation_class.AnimationClass(raw_data_folder_path=raw_data_folder_path)\n",
    "        data_item.retrieve_or_make_monkey_data()\n",
    "        data_item.make_or_retrieve_ff_dataframe(exists_ok=True)\n",
    "        data_item.find_patterns()\n",
    "        data_item.make_PlotTrials_args(classic_plot_kwargs, combined_plot_kwargs, animation_plot_kwargs)\n",
    "        \n",
    "        ## To save animation from a category across all folders\n",
    "        # data_item.make_animation_from_a_category(\"give_up_after_trying\", max_trial_to_plot=5, \n",
    "        #                                                         num_trials=2, sampling_frame_ratio = 5, exists_ok=True)\n",
    "\n",
    "        # To save animation from chunks with more than 2 ff across all folders\n",
    "        points_w_more_than_2_ff = pattern_by_points.find_points_w_more_than_n_ff(data_item.ff_dataframe, data_item.monkey_information, data_item.ff_caught_T_new)\n",
    "        points_w_more_than_2_ff = pattern_by_points.decrease_overlaps_between_chunks(points_w_more_than_2_ff, data_item.monkey_information, min_interval_between_chunks=10)\n",
    "        data_item.make_animation_of_chunks(points_w_more_than_2_ff, data_item.monkey_information, chunk_numbers = chunk_numbers, \\\n",
    "                                               sampling_frame_ratio = 3, additional_kwargs=additional_kwargs, exists_ok=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "num_trials = 3\n",
    "k = 3\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Quigley']: #'monkey_Schro', 'monkey_Bruno']:\n",
    "    monkey_path = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        temp_raw_data_folder_path = os.path.join(monkey_path, data_name)\n",
    "        data_item = animation_class.AnimationClass(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "        print(temp_raw_data_folder_path)\n",
    "        \n",
    "        animation_folder_name = os.path.join('animation', monkey_name, data_name)\n",
    "\n",
    "        if not exists(animation_folder_name):\n",
    "            os.makedirs(animation_folder_name, exist_ok = True)   \n",
    "\n",
    "        if len(os.listdir(animation_folder_name)) < 8: \n",
    "            # Then we need to save some more animations;\n",
    "            # We use this condition so as not to repeat what we've already done\n",
    "            data_item.retrieve_or_make_monkey_data()\n",
    "            data_item.make_or_retrieve_ff_dataframe()\n",
    "            # Prepare for animatoin\n",
    "            sampled_trials = np.round(np.linspace(num_trials, len(data_item.ff_caught_T_new)-1, 7)).astype('int')\n",
    "            for currentTrial in sampled_trials:\n",
    "                data_item.set_animation_parameters(currentTrial, num_trials, k)\n",
    "                data_item.call_animation_function(margin=100, save_video=False)\n",
    "                \n",
    "                # Save the animation\n",
    "                writervideo = animation.FFMpegWriter(fps=int(62/k))\n",
    "                filename = \"trial_\" + str(currentTrial-data_item.new_num_trials+1) + \"_to_\" + str(currentTrial)\n",
    "                data_item.anim.save(f\"{animation_folder_name}/{filename}.mp4\", writer=writervideo)\n",
    "                print(f\"Saved {animation_folder_name}/{filename}.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move all ipynb notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.ipynb'):\n",
    "            if 'appendix' in file:\n",
    "                continue\n",
    "            old_path = os.path.join(root, file)\n",
    "            original_path = old_path\n",
    "            print(old_path)\n",
    "            # find the part of path that is methods\n",
    "            if 'methods' not in old_path:\n",
    "                continue\n",
    "            while os.path.basename(os.path.dirname(old_path)) != 'methods':\n",
    "                old_path = os.path.dirname(old_path)\n",
    "                \n",
    "            new_path = old_path.replace('methods', 'notebooks')\n",
    "            os.makedirs(new_path, exist_ok=True)\n",
    "            new_path = os.path.join(new_path, file)\n",
    "\n",
    "            # now, move the file from old path to new path\n",
    "            os.rename(original_path, new_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove empty folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty folders in path = '/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis'\n",
    "import os\n",
    "import shutil\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for d in dirs:\n",
    "        if not os.listdir(os.path.join(root, d)):\n",
    "            os.rmdir(os.path.join(root, d))\n",
    "            print('removed:', os.path.join(root, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remake df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = basic_func.initialize_monkey_sessions_df(raw_data_dir_name='all_monkey_data/raw_monkey_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pattern_discovery import organize_patterns_and_features\n",
    "reload(organize_patterns_and_features)\n",
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "for index, row in sessions_df.iterrows():\n",
    "    if row['finished'] == True:\n",
    "        continue\n",
    "    \n",
    "    monkey_name = row['monkey_name']\n",
    "    data_name = row['data_name']\n",
    "\n",
    "    temp_raw_data_folder_path = os.path.join(raw_data_dir_name, monkey_name, data_name)\n",
    "    print(temp_raw_data_folder_path)\n",
    "\n",
    "    data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=temp_raw_data_folder_path)\n",
    "    data_item.retrieve_or_make_monkey_data(exists_ok=False)\n",
    "    data_item.make_or_retrieve_ff_dataframe(exists_ok=False, to_furnish_ff_dataframe=True)\n",
    "    data_item.find_patterns()\n",
    "    data_item.make_or_retrieve_all_trial_patterns(exists_ok=False)\n",
    "    data_item.make_or_retrieve_pattern_frequencies(exists_ok=False)\n",
    "    data_item.make_or_retrieve_all_trial_features(exists_ok=False)\n",
    "    data_item.make_or_retrieve_feature_statistics(exists_ok=False)\n",
    "\n",
    "    current_session_info = ((sessions_df['monkey_name'] == monkey_name) & (sessions_df['data_name'] == data_name))\n",
    "    sessions_df.loc[current_session_info, 'finished'] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After changing cost params of agents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NpF0uM9HR288"
   },
   "source": [
    "## Rename folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models/all_agents/env1_relu'\n",
    "\n",
    "# for every subdirectory in path, if the name begins with 'time0_' or 'time10_', then remove it from the name\n",
    "for subdir0 in os.listdir(path):\n",
    "    if 'ff' in subdir0:\n",
    "        for subdir in os.listdir(os.path.join(path, subdir0)):\n",
    "            if subdir.startswith('time0_'):\n",
    "                new_subdir = subdir[6:]\n",
    "                print(new_subdir)\n",
    "                os.rename(os.path.join(path, subdir0, subdir), os.path.join(path, subdir0, new_subdir))\n",
    "\n",
    "\n",
    "        # for every subdirectory in path, if the name begins with 'time0_' or 'time10_', then remove it from the name\n",
    "        for subdir in os.listdir(os.path.join(path, subdir0)):\n",
    "            if subdir.startswith('time10_'):\n",
    "                new_subdir = subdir[7:]\n",
    "                print(new_subdir)\n",
    "                os.rename(os.path.join(path, subdir0, subdir), os.path.join(path, subdir0, new_subdir))\n",
    "\n",
    "\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models/all_agents/env1_relu'\n",
    "\n",
    "# for every subdirectory in path, if the name begins with 'time0_' or 'time10_', then remove it from the name\n",
    "for subdir0 in os.listdir(path):\n",
    "    if 'ff' in subdir0:\n",
    "        for subdir in os.listdir(os.path.join(path, subdir0)):\n",
    "            if subdir.startswith('dv10_dw10_w10'):\n",
    "                # then replace that with dv10_dw10_w10\n",
    "                new_subdir = subdir.replace('dv10_dw10_w10', 'dv10_dw10_w10')\n",
    "                os.rename(os.path.join(path, subdir0, subdir), os.path.join(path, subdir0, new_subdir))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove time cost from all env_params.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def process_env_params(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file == 'env_params.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    env_params = json.load(f)\n",
    "                \n",
    "                # Pop out 'time cost' if it exists\n",
    "                if 'time_cost' in env_params:\n",
    "                    print(f\"Removing 'time cost' from {file_path}\")\n",
    "                    # Remove the key from the dictionary\n",
    "                    env_params.pop('time_cost')\n",
    "                \n",
    "                # Save the dictionary back to the file\n",
    "                with open(file_path, 'w') as f:\n",
    "                    json.dump(env_params, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "process_env_params(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the other costs from all env_params.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "costs = ['dv_cost_factor', 'dw_cost_factor', 'w_cost_factor']\n",
    "def process_env_params(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file == 'env_params.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    env_params = json.load(f)\n",
    "                \n",
    "                # Pop out 'time cost' if it exists\n",
    "                for cost in costs:\n",
    "                    if env_params[cost] == 50:\n",
    "                        env_params[cost] = 10\n",
    "                        print(f\"Changed {cost} from 50 to 10\")\n",
    "                \n",
    "                # Save the dictionary back to the file\n",
    "                with open(file_path, 'w') as f:\n",
    "                    json.dump(env_params, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "process_env_params(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "k11SZ7xzCa4r"
   },
   "source": [
    "## Rename monkey folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEquTsVpCc6G"
   },
   "outputs": [],
   "source": [
    "# # Rename all the data folders so that they start with 'monkey_' instead of numbers \n",
    "# raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "# for data_name in os.listdir(raw_data_dir_name):\n",
    "#     if data_name[0:2] == 'mo':\n",
    "#         new_data_name = 'monkey' + data_name[7:]\n",
    "#         new_path_name = os.path.join(raw_data_dir_name, new_data_name)\n",
    "#         old_path_name = os.path.join(raw_data_dir_name, data_name)\n",
    "#         print(\"old_path_name\", old_path_name)\n",
    "#         print(\"new_path_name\", new_path_name)\n",
    "#         # Rename the file\n",
    "#         os.rename(old_path_name, new_path_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "h-TgMOcuCWjV"
   },
   "source": [
    "## Rename data folder names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmn-C4ezSi-a"
   },
   "outputs": [],
   "source": [
    "# # Rename all the data folders so that they start with 'monkey_' instead of numbers \n",
    "# raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "# for monkey_name in os.listdir(raw_data_dir_name):\n",
    "#     monkey_path = os.path.join(raw_data_dir_name, monkey_name)\n",
    "#     for data_name in os.listdir(monkey_path):\n",
    "#         old_path_name = os.path.join(monkey_name, data_name)\n",
    "#         # if the folder name does not start with m\n",
    "#         if data_name[0] == 'd':\n",
    "#             new_data_name = 'data_' + data_name[-3:]\n",
    "#             new_path_name = os.path.join(monkey_path, new_data_name)\n",
    "#             old_path_name = os.path.join(monkey_path, data_name)\n",
    "#             print(\"old_path_name\", old_path_name)\n",
    "#             print(\"new_path_name\", new_path_name)\n",
    "#             # Rename the file\n",
    "#             os.rename(old_path_name, new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename basic_info.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through all files in 'all_monkey_data/processed_monkey_data' including in the sub-directory\n",
    "# if the name is basic_info.h5, then rename it to be ff_dataframe.h5\n",
    "raw_data_dir_name = 'all_monkey_data/processed_data'\n",
    "for root, dirs, files in os.walk(raw_data_dir_name):\n",
    "    for file in files:\n",
    "        if file == 'basic_info.h5':\n",
    "            new_file = 'ff_dataframe.h5'\n",
    "            os.rename(os.path.join(root, file), os.path.join(root, new_file))\n",
    "            print(f'{file} is renamed to {new_file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From gdrive to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move monkey_Schro etc\n",
    "\n",
    "# # if copy witin gdrive\n",
    "# raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "# raw_data_dir_name_destination = 'all_monkey_data/generated_monkey_data'\n",
    "\n",
    "\n",
    "# if copy from gdrive to local\n",
    "%cd /Users/dusiyi\n",
    "gdrive_root_dir = 'Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project'\n",
    "local_root_dir = 'Documents/Multifirefly-Project'\n",
    "raw_data_dir_name = os.path.join(gdrive_root_dir, 'all_monkey_data/raw_monkey_data')\n",
    "raw_data_dir_name_destination = os.path.join(local_root_dir, 'all_monkey_data/raw_monkey_data')\n",
    "\n",
    "\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Quigley', 'monkey_Schro']:\n",
    "    source_dir = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    destination_dir = os.path.join(raw_data_dir_name_destination, monkey_name)\n",
    "    if exists(source_dir):\n",
    "        if exists(destination_dir):\n",
    "            continue\n",
    "            # shutil.rmtree(destination_dir)\n",
    "        print(source_dir)\n",
    "        print(\"destination_dir\", destination_dir)\n",
    "        print('\\n')\n",
    "        shutil.copytree(source_dir, destination_dir)\n",
    "%cd /Users/dusiyi/Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data_0330 etc\n",
    "\n",
    "# # if copy witin gdrive\n",
    "# raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "# raw_data_dir_name_destination = 'all_monkey_data/generated_monkey_data'\n",
    "\n",
    "\n",
    "# if copy from gdrive to local\n",
    "%cd /Users/dusiyi\n",
    "gdrive_root_dir = 'Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project'\n",
    "local_root_dir = 'Documents/Multifirefly-Project'\n",
    "raw_data_dir_name = os.path.join(gdrive_root_dir, 'all_monkey_data/raw_monkey_data')\n",
    "raw_data_dir_name_destination = os.path.join(local_root_dir, 'all_monkey_data/raw_monkey_data')\n",
    "\n",
    "\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Quigley', 'monkey_Schro']:\n",
    "    monkey_path = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    for data_name in os.listdir(monkey_path):\n",
    "        if data_name[0] == 'd':\n",
    "            source_dir = os.path.join(monkey_path, data_name)\n",
    "            destination_dir = os.path.join(raw_data_dir_name_destination, monkey_name, data_name)\n",
    "            if exists(source_dir):\n",
    "                if exists(destination_dir):\n",
    "                    continue\n",
    "                    # shutil.rmtree(destination_dir)\n",
    "                print(source_dir)\n",
    "                print(\"destination_dir\", destination_dir)\n",
    "                print('\\n')\n",
    "                shutil.copytree(source_dir, destination_dir)\n",
    "%cd /Users/dusiyi/Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if copy from gdrive to local\n",
    "%cd /Users/dusiyi\n",
    "gdrive_root_dir = 'Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project'\n",
    "local_root_dir = 'Documents/Multifirefly-Project'\n",
    "raw_data_dir_name = os.path.join(gdrive_root_dir, 'all_monkey_data/raw_monkey_data')\n",
    "raw_data_dir_name_destination = os.path.join(local_root_dir, 'all_monkey_data/raw_monkey_data')\n",
    "\n",
    "\n",
    "#for monkey_name in os.listdir(raw_data_dir_name):\n",
    "for monkey_name in ['monkey_Bruno', 'monkey_Quigley', 'monkey_Schro']:\n",
    "    source_dir = os.path.join(raw_data_dir_name, monkey_name)\n",
    "    destination_dir = os.path.join(raw_data_dir_name_destination, monkey_name)\n",
    "    if exists(source_dir):\n",
    "        if exists(destination_dir):\n",
    "            continue\n",
    "            # shutil.rmtree(destination_dir)\n",
    "        print(source_dir)\n",
    "        print(\"destination_dir\", destination_dir)\n",
    "        print('\\n')\n",
    "        shutil.copytree(source_dir, destination_dir)\n",
    "%cd /Users/dusiyi/Library/CloudStorage/GoogleDrive-sd80@rice.edu/My Drive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From hard drive to local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bruno neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = pd.read_csv('/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/get_neural_data/bruno_mapping_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_path</th>\n",
       "      <th>hdrive_path</th>\n",
       "      <th>hdrive_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dusiyi/Documents/Multifirefly-Project/a...</td>\n",
       "      <td>/Volumes/Elements/multiff/Bruno/U-probe/7a/Feb...</td>\n",
       "      <td>/Volumes/Elements/multiff/Bruno/U-probe/7a/Feb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dusiyi/Documents/Multifirefly-Project/a...</td>\n",
       "      <td>/Volumes/Elements/multiff/Bruno/U-probe/7a/Apr...</td>\n",
       "      <td>/Volumes/Elements/multiff/Bruno/U-probe/7a/Apr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          local_path  \\\n",
       "0  /Users/dusiyi/Documents/Multifirefly-Project/a...   \n",
       "1  /Users/dusiyi/Documents/Multifirefly-Project/a...   \n",
       "\n",
       "                                         hdrive_path  \\\n",
       "0  /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb...   \n",
       "1  /Volumes/Elements/multiff/Bruno/U-probe/7a/Apr...   \n",
       "\n",
       "                                       hdrive_folder  \n",
       "0  /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb...  \n",
       "1  /Volumes/Elements/multiff/Bruno/U-probe/7a/Apr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_table.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb 22 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0222/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Apr 02 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0402/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 29 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0329/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 16 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0316/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 27 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0327/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 21 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0321/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 26 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0326/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 28 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0328/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 09 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0309/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 07 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0307/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 01 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0301/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 08 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0308/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 30 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0330/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb 20 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0220/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb 27 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0227/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb 26 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0226/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb 19 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0219/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Feb 21 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0221/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 12 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0312/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 15 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0315/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 23 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0323/Sorted\n",
      "source_dir: /Volumes/Elements/multiff/Bruno/U-probe/7a/Mar 14 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Bruno/data_0314/Sorted\n"
     ]
    }
   ],
   "source": [
    "for index, row in mapping_table.iterrows():\n",
    "    source_dir = os.path.join(row['hdrive_folder'], 'Sorted')\n",
    "    destination_dir = os.path.join(row['local_path'], 'Sorted')\n",
    "    if exists(source_dir):\n",
    "        print('source_dir:', source_dir)\n",
    "        print(\"destination_dir:\", destination_dir)\n",
    "        !cp -r \"{source_dir}\" \"{destination_dir}\"\n",
    "        #shutil.copytree(source_dir, destination_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change column names in time_offset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  timestamp     time\n",
      "0     16     126412  3.16030\n",
      "1      1     132299  3.30748\n",
      "2      4     628661 15.71653\n",
      "   label  timestamp     time\n",
      "0     16     309716  7.74290\n",
      "1      1     315603  7.89008\n",
      "2      4    1062672 26.56680\n",
      "   label  timestamp     time\n",
      "0     16     184953  4.62383\n",
      "1      1     190760  4.76900\n",
      "2      4    1250536 31.26340\n",
      "   label  timestamp     time\n",
      "0     16     176669  4.41672\n",
      "1      1     182559  4.56398\n",
      "2      4    1368878 34.22195\n",
      "   label  timestamp     time\n",
      "0     16     255825  6.39562\n",
      "1      1     261712  6.54280\n",
      "2      4    3182455 79.56137\n",
      "   label  timestamp     time\n",
      "0     16     169809  4.24522\n",
      "1      1     175696  4.39240\n",
      "2      4     959495 23.98738\n",
      "   label  timestamp     time\n",
      "0     16      95277  2.38192\n",
      "1      1     101164  2.52910\n",
      "2      4    1230809 30.77022\n",
      "   label  timestamp     time\n",
      "0     16     125108  3.12770\n",
      "1      1     130190  3.25475\n",
      "2      4     877832 21.94580\n",
      "   label  timestamp     time\n",
      "0     16     117305  2.93262\n",
      "1      1     123192  3.07980\n",
      "2      4     672294 16.80735\n",
      "   label  timestamp     time\n",
      "0     16     298507  7.46267\n",
      "1      1     304394  7.60985\n",
      "2      4     868028 21.70070\n",
      "   label  timestamp     time\n",
      "0     16     139586  3.48965\n",
      "1      1     145473  3.63682\n",
      "2      4    1143994 28.59985\n",
      "   label  timestamp     time\n",
      "0     16     269632  6.74080\n",
      "1      1     275519  6.88797\n",
      "2      4    1211198 30.27995\n",
      "   label  timestamp     time\n",
      "0     16     106731  2.66827\n",
      "1      1     112621  2.81553\n",
      "2      4     724589 18.11472\n",
      "   label  timestamp     time\n",
      "0     16     131536  3.28840\n",
      "1      1     137432  3.43580\n",
      "2      4    1161629 29.04072\n",
      "   label  timestamp     time\n",
      "0     16     111296  2.78240\n",
      "1      1     117179  2.92948\n",
      "2      4     728584 18.21460\n",
      "   label  timestamp     time\n",
      "0     16     264800  6.62000\n",
      "1      1     270686  6.76715\n",
      "2      4     742413 18.56032\n",
      "   label  timestamp     time\n",
      "0     16     312367  7.80917\n",
      "1      1     318254  7.95635\n",
      "2      4    1368857 34.22143\n",
      "   label  timestamp     time\n",
      "0     16     160046  4.00115\n",
      "1      1     165134  4.12835\n",
      "2      4     903494 22.58735\n",
      "   label  timestamp     time\n",
      "0     16     220424  5.51060\n",
      "1      1     226308  5.65770\n",
      "2      4     977068 24.42670\n",
      "   label  timestamp     time\n",
      "0     16     116559  2.91398\n",
      "1      1     122445  3.06113\n",
      "2      4    1346452 33.66130\n",
      "   label  timestamp     time\n",
      "0     16     283931  7.09828\n",
      "1      1     289814  7.24535\n",
      "2      4     716178 17.90445\n",
      "   label  timestamp     time\n",
      "0     16      96193  2.40483\n",
      "1      1     102082  2.55205\n",
      "2      4     775488 19.38720\n",
      "   label  timestamp     time\n",
      "0     16     192774  4.81935\n",
      "1      1     199576  4.98940\n",
      "2      4     842946 21.07365\n",
      "   label  timestamp     time\n",
      "0     16     128081  3.20202\n",
      "1      1     134109  3.35272\n",
      "2      4     613964 15.34910\n",
      "   label  timestamp     time\n",
      "0     16     118604  2.96510\n",
      "1      1     123530  3.08825\n",
      "2      4    1320252 33.00630\n"
     ]
    }
   ],
   "source": [
    "for index, row in mapping_table.iterrows():\n",
    "    time_offset = os.path.join(row['local_path'], 'time_offset.txt')\n",
    "    if exists(time_offset):\n",
    "        time_offset_df = pd.read_csv(time_offset)\n",
    "        time_offset_df.rename(columns={'sv': 'label',\n",
    "                                       'ts': 'timestamp',\n",
    "                                        'ts_s': 'time'}, inplace=True)\n",
    "        time_offset_df.to_csv(time_offset, index=False)\n",
    "        print(time_offset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>126412</td>\n",
       "      <td>3.16030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132299</td>\n",
       "      <td>3.30748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>628661</td>\n",
       "      <td>15.71653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp     time\n",
       "sv                    \n",
       "16     126412  3.16030\n",
       "1      132299  3.30748\n",
       "4      628661 15.71653"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_offset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schro neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = pd.read_csv('/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis/methods/non_behavioral_analysis/neural_data_analysis/get_neural_data/schro_mapping_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 10 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0410/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0410/Sorted/Sorted/m53s436.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0410/Sorted/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0410/Sorted/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0410/Sorted/Sorted/m53s436.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0410/Sorted/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0410/Sorted/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 17 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0417/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0417/Sorted/m53s457.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0417/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0417/Sorted/m53s457.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0417/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0417/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0417/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 19 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0419/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0419/Sorted/m53s462.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0419/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0419/Sorted/m53s462.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0419/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0419/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0419/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 20 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0420/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0420/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0420/Sorted/m53s467.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0420/Sorted/m53s467.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0420/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0420/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0420/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 16 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/m53s453.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/m53s453.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/Sorted/m53s453.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/Sorted/m53s453.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0416/Sorted/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 11 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0411/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0411/Sorted/m53s440.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0411/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0411/Sorted/m53s440.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0411/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0411/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0411/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 02 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0402/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0402/Sorted/m53s412.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0402/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0402/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0402/Sorted/m53s412.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0402/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0402/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 04 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0404/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0404/Sorted/m53s420.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0404/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0404/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0404/Sorted/m53s420.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0404/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0404/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 03 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0403/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0403/Sorted/m53s416.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0403/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0403/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0403/Sorted/m53s416.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0403/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0403/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Mar 29 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0329/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0329/Sorted/m53s398.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0329/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0329/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0329/Sorted/m53s398.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0329/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0329/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Mar 16 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0316/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0316/Sorted/m53s365.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0316/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0316/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0316/Sorted/m53s365.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0316/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0316/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Mar 27 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0327/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0327/Sorted/m53s388.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0327/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0327/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0327/Sorted/m53s388.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0327/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0327/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Mar 21 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0321/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0321/Sorted/m53s369.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0321/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0321/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0321/Sorted/m53s369.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0321/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0321/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Mar 26 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0326/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0326/Sorted/m53s384.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0326/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0326/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0326/Sorted/m53s384.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0326/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0326/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Mar 28 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0328/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0328/Sorted/m53s393.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0328/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0328/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0328/Sorted/m53s393.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0328/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0328/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 13 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0413/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0413/Sorted/m53s449.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0413/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0413/Sorted/m53s449.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0413/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0413/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0413/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 23 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0423/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0423/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0423/Sorted/m53s472.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0423/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0423/Sorted/m53s472.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0423/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0423/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 24 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0424/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0424/Sorted/m53s476.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0424/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0424/Sorted/m53s476.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0424/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0424/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0424/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 12 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0412/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0412/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0412/Sorted/m53s445.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0412/Sorted/m53s445.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0412/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0412/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0412/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 06 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0406/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0406/Sorted/m53s429.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0406/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0406/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0406/Sorted/m53s429.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0406/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0406/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Apr 09 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0409/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0409/Sorted/m53s433.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0409/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0409/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0409/Sorted/m53s433.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0409/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0409/Sorted/.phy\n",
      "source_dir: /Volumes/Elements/multiff/Schro/Utah Array/MultiFirefly/Mar 22 2018/neural data/Sorted\n",
      "destination_dir: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0322/Sorted\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0322/Sorted/m53s373.ns1\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0322/Sorted/rez.mat\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0322/Sorted/pc_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0322/Sorted/m53s373.nev\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0322/Sorted/template_features.npy\n",
      "removed: /Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/neural_data/individual_monkey_data/monkey_Schro/data_0322/Sorted/.phy\n"
     ]
    }
   ],
   "source": [
    "for index, row in mapping_table.iterrows():\n",
    "    source_dir = os.path.join(row['hdrive_folder'])\n",
    "    destination_dir = os.path.join(row['local_path'], 'Sorted')\n",
    "    if exists(source_dir):\n",
    "        if not exists(destination_dir):\n",
    "            print('source_dir:', source_dir)\n",
    "            print(\"destination_dir:\", destination_dir)\n",
    "            !cp -r \"{source_dir}\" \"{destination_dir}\"\n",
    "            # in the new directory, remove the following files: 'pc_features.npy', 'template_features.npy', 'rez.mat', and all files that contain ns1 and nev\n",
    "            for root, dirs, files in os.walk(destination_dir):\n",
    "                for file in files:\n",
    "                    if 'pc_features.npy' in file or 'template_features.npy' in file or 'rez.mat' in file or 'ns1' in file or 'nev' in file:\n",
    "                        os.remove(os.path.join(root, file))\n",
    "                        print(\"removed:\", os.path.join(root, file))\n",
    "                for dir in dirs:\n",
    "                    if '.phy' in dir:\n",
    "                        dir_path = os.path.join(root, dir)\n",
    "                        print(\"removed:\", dir_path)\n",
    "                        !rm -r \"{dir_path}\"\n",
    "    else:\n",
    "        raise ValueError(f\"{source_dir} does not exist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete planning_info_except shared_stops_near_ff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete everything in planning_info_except shared_stops_near_ff_df\n",
    "import shutil\n",
    "for monkey_name in ['monkey_Bruno']:\n",
    "    raw_data_dir_name = 'all_monkey_data/raw_monkey_data'\n",
    "    sessions_df_for_one_monkey = combine_info_utils.make_sessions_df_for_one_monkey(raw_data_dir_name, monkey_name)\n",
    "    for index, row in sessions_df_for_one_monkey.iterrows():\n",
    "        raw_data_folder_path = os.path.join(raw_data_dir_name, row['monkey_name'], row['data_name'])\n",
    "        data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=raw_data_folder_path)\n",
    "        # delete folder in planning_info_except shared_stops_near_ff_df\n",
    "        for file in os.listdir(data_item.planning_data_folder_path):\n",
    "            # if it is a folder\n",
    "            if os.path.isdir(os.path.join(data_item.planning_data_folder_path, file)):\n",
    "                if file != 'shared_stops_near_ff_df':\n",
    "                    old_file_path = os.path.join(data_item.planning_data_folder_path, file)\n",
    "                    if exists(old_file_path):\n",
    "                        shutil.rmtree(old_file_path)\n",
    "                        print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all processed_data except monkey_information.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/all_monkey_data/processed_data'\n",
    "# iterate over all subdirectories in path and delete everything except monkey_information.csv\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file != 'monkey_information.csv':\n",
    "            #os.remove(os.path.join(root, file))\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## planning info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data/monkey_Bruno'\n",
    "for data_name in os.listdir(raw_data_dir_name):\n",
    "    if data_name[:5] == 'data_':\n",
    "        data_path_name = os.path.join(raw_data_dir_name, data_name)\n",
    "        if exists(data_item.planning_data_folder_path):\n",
    "            # for directory:\n",
    "            shutil.rmtree(data_item.planning_data_folder_path)\n",
    "            print(\"Removed\", data_item.planning_data_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUAT info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "raw_data_dir_name = 'all_monkey_data/raw_monkey_data/monkey_Bruno'\n",
    "for data_name in os.listdir(raw_data_dir_name):\n",
    "    if data_name[:5] == 'data_':\n",
    "        data_path_name = os.path.join(raw_data_dir_name, data_name)\n",
    "        if exists(data_item.planning_data_folder_path):\n",
    "            # for directory:\n",
    "            shutil.rmtree(data_item.planning_data_folder_path)\n",
    "            print(\"Removed\", data_item.planning_data_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete all agent data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for dir in dirs:\n",
    "        if (dir == 'collected_data') | (dir == 'overall_variations_df'):\n",
    "            # remove the directory\n",
    "            shutil.rmtree(os.path.join(root, dir))\n",
    "            print('Removed:', os.path.join(root, dir))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all planning info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path = '/Users/dusiyi/Documents/Multifirefly-Project/RL_models/SB3_stored_models'\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for dir in dirs:\n",
    "        if (dir == 'planning_info') | (dir == 'combined_data'):\n",
    "            # remove the directory\n",
    "            shutil.rmtree(os.path.join(root, dir))\n",
    "            print('Removed:', os.path.join(root, dir))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take df out of h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def take_out_df_from_h5_store(path, new_folder_name='combd_rel_angle_slope'):\n",
    "    if not exists(path):\n",
    "        print(f'file does not exist: {path}')\n",
    "        return\n",
    "    with pd.HDFStore(path) as current_h5_store:\n",
    "        new_path_way = os.path.join(os.path.dirname(path), new_folder_name)\n",
    "        os.makedirs(new_path_way, exist_ok=True)\n",
    "        # for each df in current_h5_store, save it in new_path_way\n",
    "        for key in current_h5_store.keys():\n",
    "            print(key)\n",
    "            current_h5_store[key].to_csv(os.path.join(new_path_way, key.lstrip('/')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'all_monkey_data/aggregate_monkey_data/stop_and_alt/data/data_for_ml/plan_factors.h5'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    print(f'file does not exist: {path}')\n",
    "else:\n",
    "    with pd.HDFStore(path) as current_h5_store:\n",
    "        # Define the base directory for saving the CSV files\n",
    "        base_dir = os.path.join(os.path.dirname(os.path.dirname(path)), 'plan_factors')\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "        # Create separate directories for plan_x and plan_y\n",
    "        plan_x_dir = os.path.join(base_dir, 'plan_factors_x')\n",
    "        plan_y_dir = os.path.join(base_dir, 'plan_factors_y')\n",
    "        os.makedirs(plan_x_dir, exist_ok=True)\n",
    "        os.makedirs(plan_y_dir, exist_ok=True)\n",
    "\n",
    "        # For each df in current_h5_store, save it in the appropriate directory\n",
    "        for key in current_h5_store.keys():\n",
    "            print(key)\n",
    "            # Determine the directory based on the key\n",
    "            if 'plan_x' in key:\n",
    "                save_dir = plan_x_dir\n",
    "            elif 'plan_y' in key:\n",
    "                save_dir = plan_y_dir\n",
    "            else:\n",
    "                continue  # Skip keys that do not match plan_x or plan_y\n",
    "\n",
    "            new_key = key.lstrip('/').replace('combd_plan_y_tc_', '').replace('combd_plan_x_tc_', '')\n",
    "            # Save the DataFrame to the appropriate directory\n",
    "            current_h5_store[key].to_csv(os.path.join(save_dir, new_key.lstrip('/')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'all_monkey_data/raw_monkey_data/monkey_Bruno/combined_data/only_stop_ff/data/combd_only_stop_ff_df.h5'\n",
    "take_out_df_from_h5_store(path, new_folder_name='combd_only_stop_ff_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To fix the bug caused by the extra \"+ '.csv'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to strip .csv extension from file names in a directory\n",
    "def strip_csv_extension(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            new_filename = filename[:-4]  # Remove the last 4 characters ('.csv')\n",
    "            old_file_path = os.path.join(directory, filename)\n",
    "            new_file_path = os.path.join(directory, new_filename)\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f'Renamed: {old_file_path} to {new_file_path}')\n",
    "\n",
    "\n",
    "base_dir = 'all_monkey_data/raw_monkey_data/monkey_Bruno/combined_data/stop_and_alt/data/data_for_ml'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    print(f'file does not exist: {base_dir}')\n",
    "else:\n",
    "    # Create separate directories for plan_x and plan_y\n",
    "    plan_x_dir = os.path.join(base_dir, 'plan_factors_x')\n",
    "    plan_y_dir = os.path.join(base_dir, 'plan_factors_y')\n",
    "    # Strip .csv extension from files in plan_x_dir and plan_y_dir\n",
    "    strip_csv_extension(plan_x_dir)\n",
    "    strip_csv_extension(plan_y_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ASJATEaNST9A"
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "641tYB4XC3yC"
   },
   "outputs": [],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1682826959386,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "X1PHDflbCvrC",
    "outputId": "b6423fa0-9eaf-4f57-def6-a10ae8549aeb"
   },
   "outputs": [],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4863,
     "status": "ok",
     "timestamp": 1682824912397,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": 300
    },
    "id": "ANEoQJdmSVSr",
    "outputId": "f6c15160-39a5-49d9-8026-f6b2d9e63b84"
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq ipdb\n",
    "import ipdb\n",
    "%pdb on"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "162-xByx3iTk35YJ06VcUmsXt23wEm77H",
     "timestamp": 1680881588909
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "ff_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
