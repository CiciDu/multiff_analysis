{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive # import drive from google colab\n",
    "drive.mount(\"/content/drive\") \n",
    "!pip install neo\n",
    "!pip install matplotlib_scalebar\n",
    "!pip install ffmpeg\n",
    "!pip install Ipython --upgrade\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using google drive\n",
    "%cd /content/drive/MyDrive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "if Path.cwd().parts[-1] != 'Multifirefly-Project':\n",
    "    if Path.cwd().parts[-1] != 'notebooks':\n",
    "        os.chdir('..')\n",
    "    from add_path import find_path\n",
    "    current_path = find_path()\n",
    "    os.chdir(current_path)\n",
    "import sys\n",
    "\n",
    "\n",
    "from data_wrangling import basic_func, process_raw_data, base_processing_class, combine_info_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_points, make_ff_dataframe, ff_dataframe_utils, pattern_by_trials, pattern_by_points, cluster_analysis, organize_patterns_and_features, category_class, cluster_analysis\n",
    "from decision_making_analysis.decision_making import decision_making_class, decision_making_utils, plot_decision_making, intended_targets_classes\n",
    "from decision_making_analysis.GUAT import GUAT_helper_class, GUAT_collect_info_class, GUAT_combine_info_class, process_GUAT_trials_class, GUAT_and_TAFT\n",
    "from decision_making_analysis import free_selection, replacement, trajectory_info\n",
    "from null_behaviors import show_null_trajectory, find_best_arc, curvature_utils, curvature_class, curv_of_traj_utils\n",
    "from machine_learning import machine_learning_utils, hyperparameter_tuning_class\n",
    "from machine_learning.RL.env_related import env_for_lstm, env_utils, base_env, collect_agent_data_utils\n",
    "from machine_learning.RL.lstm import GRU_functions, LSTM_functions\n",
    "from machine_learning.RL.SB3 import interpret_neural_network, sb3_for_multiff_class, rl_for_multiff_utils, SB3_functions\n",
    "from visualization import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics, monkey_heading_functions\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from planning_analysis.test_params_for_planning import params_test_combos_class, params_utils\n",
    "from visualization.plotly_tools import plotly_for_monkey, plotly_for_scatterplot, plotly_preparation, plotly_for_correlation\n",
    "from visualization.dash_tools import dash_prep_class, dash_utils, dash_utils, dash_comparison_class, dash_params_class\n",
    "from visualization.dash_tools.dash_main_class_methods import dash_main_class\n",
    "from non_behavioral_analysis.neural_data_analysis.get_neural_data import neural_data_processing\n",
    "from non_behavioral_analysis.neural_data_analysis.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from non_behavioral_analysis.neural_data_analysis.model_neural_data import cca_class, pgam_class, neural_data_modeling, reduce_multicollinearity\n",
    "from non_behavioral_analysis.neural_data_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from non_behavioral_analysis.neural_data_analysis.planning_neural import planning_neural_class, planning_neural_utils\n",
    "from planning_analysis.plan_factors import plan_factors_utils, plan_factors_class, monkey_plan_factors_x_sess_class\n",
    "from planning_analysis.show_planning import alt_ff_utils, show_planning_class, show_planning_utils\n",
    "from planning_analysis.show_planning.get_stops_near_ff import find_stops_near_ff_class, find_stops_near_ff_utils, plot_stops_near_ff_class, plot_stops_near_ff_utils, plot_monkey_heading_helper_class, stops_near_ff_based_on_ref_class\n",
    "\n",
    "from importlib import reload\n",
    "from non_behavioral_analysis import eye_positions\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from os.path import exists\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "import gc\n",
    "from scipy.stats import rankdata\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, multilabel_confusion_matrix, fbeta_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import pi\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import warnings\n",
    "import os, sys\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.max_rows = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item = None\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNF (stops near ff) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run('snf.streamline_organizing_info()', sort='cumtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalize = False\n",
    "eliminate_outliers = False\n",
    "use_curvature_to_ff_center = False\n",
    "curv_of_traj_mode = 'distance'\n",
    "window_for_curv_of_traj=[-25, 25]\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\"\n",
    "\n",
    "#data_item_info = find_stops_near_ff_utils.extract_key_info_from_data_item_for_stops_near_ff_class(data_item)\n",
    "\n",
    "snf = stops_near_ff_based_on_ref_class.StopsNearFFBasedOnRef(raw_data_folder_path=raw_data_folder_path)\n",
    "snf.get_more_monkey_data()\n",
    "snf.traj_curv_descr = 'Traj Curv: From Current Point to Right Before Stop'\n",
    "\n",
    "\n",
    "\n",
    "snf.streamline_organizing_info(ref_point_mode='distance', ref_point_value=-150, \n",
    "                              #ref_point_mode='time after stop ff visible', ref_point_value=0.1, \n",
    "                               curv_of_traj_mode=curv_of_traj_mode, window_for_curv_of_traj=window_for_curv_of_traj, truncate_curv_of_traj_by_time_of_capture=True,\n",
    "                               use_curvature_to_ff_center=use_curvature_to_ff_center,  eliminate_outliers=eliminate_outliers,\n",
    "                               stops_near_ff_df_exists_ok=True)\n",
    "\n",
    "snf.ax_for_corr = snf.find_relationships_from_info(normalize=normalize, show_plot=True)\n",
    "snf.prepare_to_make_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_i = snf.make_individual_plots_in_matplotlib(current_i, max_num_plot_to_make = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show eye positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_plotting_kwargs={'show_connect_path_ff_specific_indices': None, 'show_ff_indices': True,\n",
    "                            'show_eye_positions':True,\n",
    "                            'show_eye_positions_for_both_eyes':True,\n",
    "                            'show_connect_path_eye_positions': True}\n",
    "current_i = snf.make_individual_plots_in_matplotlib(current_i, max_num_plot_to_make=3, \n",
    "                                      additional_plotting_kwargs=additional_plotting_kwargs,\n",
    "                                      show_position_in_scatter_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_i = 2\n",
    "snf.make_PlotTrials_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_i = snf.make_individual_plotly_plots(current_i, max_num_plot_to_make=1, \n",
    "                                             show_eye_positions_for_both_eyes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = 'all_monkey_data/raw_monkey_data/monkey_Bruno/data_0326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_or_control='test'\n",
    "\n",
    "\n",
    "ref_point_params = {'ref_point_mode': 'time after stop ff visible',\n",
    "                    'ref_point_value': 0}\n",
    "\n",
    "\n",
    "curv_of_traj_params = {'curv_of_traj_mode': 'distance',\n",
    "                        'window_for_curv_of_traj': [-25, 25],\n",
    "                        'truncate_curv_of_traj_by_time_of_capture': False}\n",
    "\n",
    "\n",
    "overall_params = {'eliminate_outliers': True,\n",
    "                  'use_curvature_to_ff_center': False,\n",
    "                  'normalize': False,\n",
    "                  'remove_i_o_modify_rows_with_big_ff_angles': True,\n",
    "                  'change_units_to_degrees_per_m': True,\n",
    "                  'heading_instead_of_curv': True}  \n",
    "\n",
    "\n",
    "scatter_plot_params = {\n",
    "    \"use_two_y_axes\": False,\n",
    "    \"show_alt_ff_curv_in_scatterplot\": True,\n",
    "    \"show_stop_ff_curv_in_scatterplot\": True,\n",
    "}\n",
    "\n",
    "monkey_plot_params = {\n",
    "    \"show_visible_fireflies\": True,\n",
    "    \"show_in_memory_fireflies\": False,\n",
    "    \"show_monkey_heading\": False,\n",
    "    \"show_visible_segments\": True,\n",
    "    \"show_traj_portion\": True,\n",
    "    \"show_null_arcs_to_ff\": True,\n",
    "    \"show_stops\": True,\n",
    "    \"show_all_eye_positions\": False,\n",
    "    \"show_current_eye_positions\": True,\n",
    "    \"show_eye_positions_for_both_eyes\": True,\n",
    "}\n",
    "     \n",
    "#data_item_info = find_stops_near_ff_utils.extract_key_info_from_data_item_for_stops_near_ff_class(data_item)                       \n",
    "dc = dash_main_class.DashMainPlots(raw_data_folder_path=raw_data_folder_path)\n",
    "\n",
    "\n",
    "dc.prepare_to_make_dash_for_main_plots(monkey_plot_params=monkey_plot_params,\n",
    "                                        scatter_plot_params=scatter_plot_params,\n",
    "                                        ref_point_params=ref_point_params,\n",
    "                                        curv_of_traj_params=curv_of_traj_params,\n",
    "                                        overall_params=overall_params,\n",
    "                                        stops_near_ff_df_exists_ok=True,\n",
    "                                        test_or_control=test_or_control)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.fig.show()\n",
    "dc.fig_scatter_combd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.get_more_monkey_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.make_dash_for_main_plots(show_trajectory_scatter_plot=True, show_shuffled_correlation_plot=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc.app.server.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Now we're done with the data, so we can delete it and run the garbage collector.\n",
    "del dc.app\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dc.stops_near_ff_df_counted.iterrows():\n",
    "    dc.stops_near_ff_row = row\n",
    "    dc.stop_point_index = row.stop_point_index\n",
    "    dc._prepare_to_make_plotly_fig_for_dash_given_stop_point_index(dc.stop_point_index)\n",
    "    dc.fig = dc._produce_fig_for_dash()\n",
    "    dc.fig.show()\n",
    "\n",
    "    if index == 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for eye positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "monkey_height = -10\n",
    "\n",
    "values = np.arange(-99, 99, 1)\n",
    "\n",
    "gaze_world_x = np.repeat(values, len(values))\n",
    "gaze_world_y = np.repeat(values.reshape([1, -1]), len(values), axis=0).reshape(-1)\n",
    "\n",
    "\n",
    "body_theta = np.random.uniform(-pi, pi, len(gaze_world_x))\n",
    "body_x = np.random.uniform(-100, 100, len(gaze_world_x))\n",
    "body_y = np.random.uniform(-100, 100, len(gaze_world_x))\n",
    "\n",
    "\n",
    "gaze_monkey_view_x = gaze_world_x - body_x\n",
    "gaze_monkey_view_y = gaze_world_y - body_y\n",
    "gaze_monkey_view_xy = np.stack((gaze_monkey_view_x, gaze_monkey_view_y), axis=1)\n",
    "gaze_monkey_view_r = LA.norm(gaze_monkey_view_xy, axis=1)\n",
    "\n",
    "theta_to_north = np.arctan((gaze_world_x - body_x) / np.sqrt(monkey_height**2 + (gaze_world_y-body_y)**2))\n",
    "to_adjust = np.where(gaze_monkey_view_y < 0)[0]\n",
    "# \n",
    "theta_to_north[to_adjust] = np.sign(theta_to_north[to_adjust]) * (pi - np.abs(theta_to_north[to_adjust]))\n",
    "\n",
    "\n",
    "hor_theta = theta_to_north\n",
    "ver_theta = np.arctan(monkey_height / gaze_monkey_view_r)\n",
    "\n",
    "gaze_monkey_view_x_recovered, gaze_monkey_view_y_recovered, _, gaze_world_x_recovered, gaze_world_y_recovered \\\n",
    "    = eye_positions.apply_formulas_to_convert_eye_position_to_ff_position(hor_theta, ver_theta, body_theta, monkey_height, body_x, body_y,\n",
    "                        interocular_dist=0, rotate_world_xy_based_on_m_angle_to_get_abs_coord=False)\n",
    "\n",
    "plt.scatter(gaze_world_x, gaze_world_x_recovered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_monkey_view_y = dc.monkey_information['gaze_monkey_view_y'].values\n",
    "gaze_monkey_view_y[gaze_monkey_view_y < 0] = 0\n",
    "gaze_monkey_view_y[gaze_monkey_view_y > 1500] = 1500\n",
    "sns.histplot(gaze_monkey_view_y, binwidth=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(theta_to_north[np.where(np.abs(ver_theta + 0.29414615) < 0.01 )], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = theta_to_north[np.where(np.abs(ver_theta + 0.29414615) < 0.01 )]\n",
    "max(ab[ab < 1.57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = theta_to_north[np.where(np.abs(ver_theta + 0.29414615) < 0.01 )]\n",
    "min(ab[ab > 1.57])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff in distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.stops_near_ff_df['d_from_stop_ff_to_alt_ff'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.make_stops_near_ff_df_test(exists_ok=True)\n",
    "dc.make_stops_near_ff_df_ctrl(exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(dc.stops_near_ff_df_test['d_from_stop_ff_to_alt_ff'], binwidth=20, stat='density', alpha=0.5, color='orange')\n",
    "sns.histplot(dc.stops_near_ff_df_ctrl['d_from_stop_ff_to_alt_ff'], binwidth=20, stat='density', alpha=0.5, color='blue')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatterplot for heading_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = False\n",
    "eliminate_outliers = False\n",
    "use_curvature_to_ff_center = False\n",
    "\n",
    "# oh...curv_of_traj doesn't matter if we're only looking at heading. \n",
    "# but we can def play around with the hyperparameters for ref_point\n",
    "curv_of_traj_mode = 'specific index'\n",
    "curv_of_traj_mode = 'distance'\n",
    "window_for_curv_of_traj = [-25, 25]\n",
    "\n",
    "# data_item_info = find_stops_near_ff_utils.extract_key_info_from_data_item_for_stops_near_ff_class(data_item)\n",
    "\n",
    "snf = stops_near_ff_based_on_ref_class.StopsNearFFBasedOnRef(raw_data_folder_path=raw_data_folder_path)\n",
    "snf.get_more_monkey_data()\n",
    "snf.traj_curv_descr = 'Traj Curv: From Current Point to Right Before Stop'\n",
    "\n",
    "snf.streamline_organizing_info(ref_point_mode='distance', ref_point_value=-150, \n",
    "                               curv_of_traj_mode=curv_of_traj_mode, window_for_curv_of_traj=window_for_curv_of_traj,\n",
    "                               truncate_curv_of_traj_by_time_of_capture=False,\n",
    "                               use_curvature_to_ff_center=use_curvature_to_ff_center,  eliminate_outliers=eliminate_outliers)\n",
    "snf.ax_for_corr = snf.find_relationships_from_info(normalize=normalize, show_plot=True)\n",
    "snf.get_null_arc_info_for_counted_points(use_fixed_arc_length=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snf._make_alt_and_stop_ff_df()\n",
    "snf._make_heading_info_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_traj, alt_stop, heading_info_df_no_na = show_planning_utils.get_alt_traj_and_alt_stop(snf.heading_info_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_traj, alt_stop, heading_info_df_no_na = show_planning_utils.get_alt_traj_and_alt_stop(dsp.combd_heading_df_x_sessions.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, fit_intercept=True)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, fit_intercept=True, omit_outliers=True)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, fit_intercept=False)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, fit_intercept=False, omit_outliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q13 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, q13_only=True, fit_intercept=True)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, q13_only=True, fit_intercept=True, omit_outliers=True)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, q13_only=True, fit_intercept=False)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, q13_only=True, fit_intercept=False, omit_outliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abs value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, use_abs_values=True, fit_intercept=True)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, use_abs_values=True, fit_intercept=True, omit_outliers=True)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, use_abs_values=True, fit_intercept=False)\n",
    "slope, intercept, r_value, p_value, results = show_planning_utils.conduct_linear_regression_to_show_planning(alt_traj, alt_stop, use_abs_values=True, fit_intercept=False, omit_outliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under-turn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 4 ff\n",
    "ref_point_mode = 'distance'\n",
    "ref_point_value = -150\n",
    "\n",
    "ps = monkey_plan_factors_x_sess_class.PlanAcrossSessions()\n",
    "ps.initialize_monkey_sessions_df_for_one_monkey()\n",
    "ps.get_combd_heading_df_x_sessions_across_sessions(\n",
    "                        ref_point_mode=ref_point_mode, \n",
    "                        ref_point_value=ref_point_value,\n",
    "                        save_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control\n",
    "(180/math.pi * (np.abs(ps.combd_heading_df_x_sessions_ctrl['stop_d_heading_of_arc']) - np.abs(ps.combd_heading_df_x_sessions_ctrl['ref_d_heading_of_traj']))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "(180/math.pi * (np.abs(ps.combd_heading_df_x_sessions_test['stop_d_heading_of_arc']) - np.abs(ps.combd_heading_df_x_sessions_test['ref_d_heading_of_traj']))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(180/math.pi * ps.combd_heading_df_x_sessions_test[['stop_d_heading_of_arc', 'ref_d_heading_of_traj']]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(180/math.pi * np.abs(ps.combd_heading_df_x_sessions_test[['stop_d_heading_of_arc', 'ref_d_heading_of_traj']])).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(180/math.pi * (np.abs(ps.combd_heading_df_x_sessions_test['stop_d_heading_of_arc']) - np.abs(ps.combd_heading_df_x_sessions_test['ref_d_heading_of_traj']))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_mismatched_signs = np.abs((np.sign(ps.combd_heading_df_x_sessions_test['stop_d_heading_of_arc']) - np.sign(ps.combd_heading_df_x_sessions_test['ref_d_heading_of_traj']))).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_mismatched_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_mismatched_signs/len(ps.combd_heading_df_x_sessions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monkey Bruno prefers to turn left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_dw = dc.monkey_information['monkey_dw'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_dw = monkey_dw*180/math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(180/math.pi * dc.monkey_information['monkey_dw']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_dw_sub = monkey_dw[np.abs(monkey_dw) < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(monkey_dw_sub)/len(monkey_dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(monkey_dw)/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many 360 circles did the monkey make?\n",
    "np.sum(monkey_dw_sub)/360"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
